This patch is the merge of dyninst 9.3.2 and Xiaozhu's jump table
slicing branch as of June 2, 2017, minus the license file rename.
Apply this patch to the 9.3.2-release tar file in distfiles.

https://github.com/dyninst/dyninst
commit 5d2ddacb273682daa014ae22f17f3575e05b411e (HEAD, tag: v9.3.2, v9.3.x)
Merge: 1575b01 2e23c95
Author: Bill Williams <wwilliam47@gmail.com>
Date:   Mon Apr 17 16:51:11 2017 -0500

    Merge pull request #362 from dyninst/wrwilliams/cleanup-for-9.3.2
    More 9.3.2 cleanup

https://github.com/mxz297/dyninst
commit ba1b3348ab9f2ecce299b65035053ead1028e95b (jump_table_multi_slices)
Author: Xiaozhu Meng <xmeng@cs.wisc.edu>
Date:   Fri Jun 2 09:53:17 2017 -0500

    1. More strict check when searching for the instruction that spills
       register to stack
    2. Add code for checking jump target for variable argument functions


diff --git a/cmake/packages.cmake b/cmake/packages.cmake
index c9fb42a..d9d323e 100644
--- a/cmake/packages.cmake
+++ b/cmake/packages.cmake
@@ -39,7 +39,7 @@ if (UNIX)
       URL http://www.paradyn.org/libdwarf/libdwarf-20130126.tar.gz
       #	GIT_REPOSITORY git://git.code.sf.net/p/libdwarf/code libdwarf-code
       #	GIT_TAG 20130126
-      CONFIGURE_COMMAND CFLAGS=-I${LIBELF_INCLUDE_DIR} LDFLAGS=-L${CMAKE_BINARY_DIR}/libelf/lib <SOURCE_DIR>/libdwarf/configure --enable-shared
+      CONFIGURE_COMMAND env CFLAGS=${CMAKE_C_FLAGS}\ -I${LIBELF_INCLUDE_DIR} LDFLAGS=-L${CMAKE_BINARY_DIR}/libelf/lib <SOURCE_DIR>/libdwarf/configure --enable-shared
       BUILD_COMMAND make
       INSTALL_DIR ${CMAKE_BINARY_DIR}/libdwarf
       INSTALL_COMMAND mkdir -p <INSTALL_DIR>/include && mkdir -p <INSTALL_DIR>/lib && install <SOURCE_DIR>/libdwarf/libdwarf.h <INSTALL_DIR>/include && install <SOURCE_DIR>/libdwarf/dwarf.h <INSTALL_DIR>/include && install <BINARY_DIR>/libdwarf.so <INSTALL_DIR>/lib
@@ -56,6 +56,9 @@ if (UNIX)
   add_library(libdwarf_imp SHARED IMPORTED)
   set_property(TARGET libdwarf_imp 
     PROPERTY IMPORTED_LOCATION ${LIBDWARF_LIBRARIES})
+  if(NOT LIBDWARF_FOUND)
+    add_dependencies(libdwarf_imp LibDwarf)
+  endif()
 
   if (NOT USE_GNU_DEMANGLER)
     find_package (LibIberty)
@@ -66,19 +69,23 @@ if (UNIX)
       ExternalProject_Add(LibIberty
 	PREFIX ${CMAKE_BINARY_DIR}/binutils
 	URL http://ftp.gnu.org/gnu/binutils/binutils-2.23.tar.gz
-	CONFIGURE_COMMAND CFLAGS=-fPIC CPPFLAGS=-fPIC PICFLAG=-fPIC <SOURCE_DIR>/libiberty/configure --prefix=${CMAKE_BINARY_DIR}/libiberty --enable-shared
+	CONFIGURE_COMMAND env CFLAGS=${CMAKE_C_FLAGS}\ -fPIC CPPFLAGS=-fPIC PICFLAG=-fPIC <SOURCE_DIR>/libiberty/configure --prefix=${CMAKE_BINARY_DIR}/libiberty --enable-shared
 	BUILD_COMMAND make all
 	INSTALL_DIR ${CMAKE_BINARY_DIR}/libiberty
 	INSTALL_COMMAND install <BINARY_DIR>/libiberty.a <INSTALL_DIR>
 	)
       set(IBERTY_LIBRARIES ${CMAKE_BINARY_DIR}/libiberty/libiberty.a)
       set(IBERTY_FOUND TRUE)
+      set(IBERTY_BUILD TRUE)
     endif()
 
     message(STATUS "Using libiberty ${IBERTY_LIBRARIES}")
     add_library(libiberty_imp STATIC IMPORTED)
     set_property(TARGET libiberty_imp
       PROPERTY IMPORTED_LOCATION ${IBERTY_LIBRARIES})
+    if(IBERTY_BUILD)
+      add_dependencies(libiberty_imp LibIberty)
+    endif()
   endif()
 
   find_package (ThreadDB)
diff --git a/common/h/Graph.h b/common/h/Graph.h
index 426d120..6dcb67f 100644
--- a/common/h/Graph.h
+++ b/common/h/Graph.h
@@ -132,6 +132,7 @@ class COMMON_EXPORT Graph : public AnnotatableSparse {
 
     void clearEntryNodes();
     void clearExitNodes();
+    void adjustEntryAndExitNodes();
 
     unsigned size() const;
 
diff --git a/common/src/Graph.C b/common/src/Graph.C
index 4882890..8f43e61 100644
--- a/common/src/Graph.C
+++ b/common/src/Graph.C
@@ -194,3 +194,16 @@ bool Graph::isExitNode(NodePtr node) {
 unsigned Graph::size() const {
    return nodes_.size();
 }
+
+void Graph::adjustEntryAndExitNodes() {
+    entryNodes_.clear();
+    exitNodes_.clear();
+    NodeIterator gbegin, gend;
+    allNodes(gbegin, gend);
+    for (; gbegin != gend; ++gbegin) {
+        Node::Ptr ptr = *gbegin;
+	if (!ptr->hasInEdges()) insertEntryNode(ptr);
+	if (!ptr->hasOutEdges()) insertExitNode(ptr);
+    }
+
+}
diff --git a/common/src/dyn_regs.C b/common/src/dyn_regs.C
index 383e4c3..5abd56b 100644
--- a/common/src/dyn_regs.C
+++ b/common/src/dyn_regs.C
@@ -918,7 +918,13 @@ void MachRegister::getROSERegister(int &c, int &n, int &p)
                }
                    break;
                default:
-                   assert(!"unknown register type!");
+	           // We do not want to assert here.
+		   // Set these output variable to invalid values and let the
+		   // semantics code to throw exceptions
+	           p = -1;
+		   c = -1;
+		   n = -1;
+//                   assert(!"unknown register type!");
                    break;
            }
            return;
diff --git a/dataflowAPI/h/ABI.h b/dataflowAPI/h/ABI.h
index 70704cc..4d53b9e 100644
--- a/dataflowAPI/h/ABI.h
+++ b/dataflowAPI/h/ABI.h
@@ -47,6 +47,7 @@ class ABI{
     DATAFLOW_EXPORT const bitArray &getCallWrittenRegisters() const;
     DATAFLOW_EXPORT const bitArray &getReturnReadRegisters() const;
     DATAFLOW_EXPORT const bitArray &getReturnRegisters() const;
+    DATAFLOW_EXPORT const bitArray &getParameterRegisters() const;
     // No such thing as return written...
 
     // Syscall!
@@ -76,6 +77,9 @@ class ABI{
     static bitArray returnRegs_;
     static bitArray returnRegs64_;
 
+    static bitArray callParam_;
+    static bitArray callParam64_;
+
     static bitArray syscallRead_;
     static bitArray syscallRead64_;
 
diff --git a/dataflowAPI/h/slicing.h b/dataflowAPI/h/slicing.h
index 443945f..02172d4 100644
--- a/dataflowAPI/h/slicing.h
+++ b/dataflowAPI/h/slicing.h
@@ -145,70 +145,7 @@ class Slicer {
     
   DATAFLOW_EXPORT static bool isWidenNode(Node::Ptr n);
 
-  class Predicates {
-    bool clearCache, controlFlowDep;
-
-  public:
-    typedef std::pair<ParseAPI::Function *, int> StackDepth_t;
-    typedef std::stack<StackDepth_t> CallStack_t;
-    DATAFLOW_EXPORT bool performCacheClear() { if (clearCache) {clearCache = false; return true;} else return false; }
-    DATAFLOW_EXPORT void setClearCache(bool b) { clearCache = b; }
-    DATAFLOW_EXPORT bool searchForControlFlowDep() { return controlFlowDep; }
-    DATAFLOW_EXPORT void setSearchForControlFlowDep(bool cfd) { controlFlowDep = cfd; }
-
-    DATAFLOW_EXPORT virtual bool allowImprecision() { return false; }
-    DATAFLOW_EXPORT virtual bool widenAtPoint(AssignmentPtr) { return false; }
-    DATAFLOW_EXPORT virtual bool endAtPoint(AssignmentPtr) { return false; }
-    DATAFLOW_EXPORT virtual bool followCall(ParseAPI::Function * /*callee*/,
-                                           CallStack_t & /*cs*/,
-                                           AbsRegion /*argument*/) { 
-       return false; 
-    }
-    DATAFLOW_EXPORT virtual std::vector<ParseAPI::Function *> 
-        followCallBackward(ParseAPI::Block * /*callerB*/,
-            CallStack_t & /*cs*/,
-            AbsRegion /*argument*/) {
-            std::vector<ParseAPI::Function *> vec;
-            return vec;
-        }
-    DATAFLOW_EXPORT virtual bool addPredecessor(AbsRegion /*reg*/) {
-        return true;
-    }
-    DATAFLOW_EXPORT virtual bool widenAtAssignment(const AbsRegion & /*in*/,
-                                                  const AbsRegion & /*out*/) { 
-       return false; 
-    }
-    DATAFLOW_EXPORT virtual ~Predicates() {};
-
-    // Callback function when adding a new node to the slice.
-    // Return true if we want to continue slicing
-    DATAFLOW_EXPORT virtual bool addNodeCallback(AssignmentPtr,
-                                                 std::set<ParseAPI::Edge*> &) { return true;}
-    DATAFLOW_EXPORT Predicates() : clearCache(false), controlFlowDep(false) {}						
-
-  };
-
-  DATAFLOW_EXPORT GraphPtr forwardSlice(Predicates &predicates);
-  
-  DATAFLOW_EXPORT GraphPtr backwardSlice(Predicates &predicates);
-
- private:
-
-  typedef enum {
-    forward,
-    backward } Direction;
-
-  typedef std::map<ParseAPI::Block *, InsnVec> InsnCache;
-
-  // Our slicing is context-sensitive; that is, if we enter
-  // a function foo from a caller bar, all return edges
-  // from foo must enter bar. This makes an assumption that
-  // the return address is not modified, but hey. 
-  // We represent this as a list of call sites. This is redundant
-  // with the image_instPoint data structure, but hopefully that
-  // one will be going away. 
-
-  struct ContextElement {
+  struct DATAFLOW_EXPORT ContextElement {
     // We can implicitly find the callsite given a block,
     // since calls end blocks. It's easier to look up 
     // the successor this way than with an address.
@@ -234,19 +171,9 @@ class Slicer {
   // This should be sufficient...
   typedef std::deque<ContextElement> Context;
 
-  bool getStackDepth(ParseAPI::Function *func, ParseAPI::Block *block, Address callAddr, long &height);
-
-  // Add the newly called function to the given Context.
-  void pushContext(Context &context,
-		   ParseAPI::Function *callee,
-		   ParseAPI::Block *callBlock,
-		   long stackDepth);
-
-  // And remove it as appropriate
-  void popContext(Context &context);
 
   // Where we are in a particular search...
-  struct Location {
+  struct DATAFLOW_EXPORT Location {
     // The block we're looking through
     ParseAPI::Function *func;
     ParseAPI::Block *block; // current block
@@ -267,8 +194,6 @@ class Slicer {
   Location() : func(NULL), block(NULL), fwd(true) {};
   };
     
-  typedef std::queue<Location> LocList;
- 
   // Describes an abstract region, a minimal context
   // (block and function), and the assignment that
   // relates to that region (uses or defines it, 
@@ -278,7 +203,7 @@ class Slicer {
   // keep a list of the currently active elements
   // that are at the `leading edge' of the 
   // under-construction slice
-  struct Element {
+  struct DATAFLOW_EXPORT Element {
     Element(ParseAPI::Block * b,
         ParseAPI::Function * f,
         AbsRegion const& r,
@@ -303,11 +228,10 @@ class Slicer {
     AbsRegion reg;
     Assignment::Ptr ptr;
   };
-  bool ReachableFromBothBranches(ParseAPI::Edge *e, std::vector<Element> &newE);
 
   // State for recursive slicing is a context, location pair
   // and a list of AbsRegions that are being searched for.
-  struct SliceFrame {
+  struct DATAFLOW_EXPORT SliceFrame {
     SliceFrame(
         Location const& l,
         Context const& c)
@@ -330,6 +254,90 @@ class Slicer {
     Address addr() const { return loc.addr(); }
   };
 
+
+  class Predicates {
+    bool clearCache, controlFlowDep;
+
+  public:
+    typedef std::pair<ParseAPI::Function *, int> StackDepth_t;
+    typedef std::stack<StackDepth_t> CallStack_t;
+    DATAFLOW_EXPORT bool performCacheClear() { if (clearCache) {clearCache = false; return true;} else return false; }
+    DATAFLOW_EXPORT void setClearCache(bool b) { clearCache = b; }
+    DATAFLOW_EXPORT bool searchForControlFlowDep() { return controlFlowDep; }
+    DATAFLOW_EXPORT void setSearchForControlFlowDep(bool cfd) { controlFlowDep = cfd; }
+
+    DATAFLOW_EXPORT virtual bool allowImprecision() { return false; }
+    DATAFLOW_EXPORT virtual bool widenAtPoint(AssignmentPtr) { return false; }
+    DATAFLOW_EXPORT virtual bool endAtPoint(AssignmentPtr) { return false; }
+    DATAFLOW_EXPORT virtual bool followCall(ParseAPI::Function * /*callee*/,
+                                           CallStack_t & /*cs*/,
+                                           AbsRegion /*argument*/) { 
+       return false; 
+    }
+    DATAFLOW_EXPORT virtual std::vector<ParseAPI::Function *> 
+        followCallBackward(ParseAPI::Block * /*callerB*/,
+            CallStack_t & /*cs*/,
+            AbsRegion /*argument*/) {
+            std::vector<ParseAPI::Function *> vec;
+            return vec;
+        }
+    DATAFLOW_EXPORT virtual bool addPredecessor(AbsRegion /*reg*/) {
+        return true;
+    }
+    DATAFLOW_EXPORT virtual bool widenAtAssignment(const AbsRegion & /*in*/,
+                                                  const AbsRegion & /*out*/) { 
+       return false; 
+    }
+    DATAFLOW_EXPORT virtual ~Predicates() {};
+
+    // Callback function when adding a new node to the slice.
+    // Return true if we want to continue slicing
+    DATAFLOW_EXPORT virtual bool addNodeCallback(AssignmentPtr,
+                                                 std::set<ParseAPI::Edge*> &) { return true;}
+    // Callback function after we have added new a node and corresponding new edges to the slice.
+    // This function allows users to inspect the current slice graph and determine which abslocs
+    // need further slicing and which abslocs are no longer interesting, by modifying the current
+    // SliceFrame.
+    DATAFLOW_EXPORT virtual bool modifyCurrentFrame(SliceFrame &, GraphPtr, Slicer*) {return true;} 						
+    DATAFLOW_EXPORT Predicates() : clearCache(false), controlFlowDep(false) {}						
+
+  };
+
+  DATAFLOW_EXPORT GraphPtr forwardSlice(Predicates &predicates);
+  
+  DATAFLOW_EXPORT GraphPtr backwardSlice(Predicates &predicates);
+
+ private:
+
+  typedef enum {
+    forward,
+    backward } Direction;
+
+  typedef std::map<ParseAPI::Block *, InsnVec> InsnCache;
+
+  // Our slicing is context-sensitive; that is, if we enter
+  // a function foo from a caller bar, all return edges
+  // from foo must enter bar. This makes an assumption that
+  // the return address is not modified, but hey. 
+  // We represent this as a list of call sites. This is redundant
+  // with the image_instPoint data structure, but hopefully that
+  // one will be going away. 
+
+  bool getStackDepth(ParseAPI::Function *func, ParseAPI::Block *block, Address callAddr, long &height);
+
+  // Add the newly called function to the given Context.
+  void pushContext(Context &context,
+		   ParseAPI::Function *callee,
+		   ParseAPI::Block *callBlock,
+		   long stackDepth);
+
+  // And remove it as appropriate
+  void popContext(Context &context);
+
+  typedef std::queue<Location> LocList;
+ 
+  bool ReachableFromBothBranches(ParseAPI::Edge *e, std::vector<Element> &newE);
+
   // Used for keeping track of visited edges in the
   // slicing search
   struct CacheEdge {
@@ -658,8 +666,11 @@ class Slicer {
 
   void getInsns(Location &loc);
 
+public:
   void getInsnsBackward(Location &loc);
 
+private:  
+
   void setAliases(Assignment::Ptr, Element &);
 
   SliceNode::Ptr createNode(Element const&);
diff --git a/dataflowAPI/h/stackanalysis.h b/dataflowAPI/h/stackanalysis.h
index 1c58066..88650c1 100644
--- a/dataflowAPI/h/stackanalysis.h
+++ b/dataflowAPI/h/stackanalysis.h
@@ -71,12 +71,61 @@ namespace Dyninst {
       class Expression;
    };
 
-
 class StackAnalysis {
 public:
    typedef boost::shared_ptr<InstructionAPI::Instruction> InstructionPtr;
    typedef boost::shared_ptr<InstructionAPI::Expression> ExpressionPtr;
 
+   class DATAFLOW_EXPORT Definition {
+   public:
+      typedef enum {TOP, BOTTOM, DEF} Type;
+      Address addr;
+      ParseAPI::Block *block;
+      Absloc origLoc;
+      Type type;
+
+      Definition(ParseAPI::Block *b, Address a, Absloc l) : addr(a),
+         block(b), origLoc(l), type(DEF) {}
+      Definition(ParseAPI::Block *b, Absloc l) : addr(0), block(b),
+         origLoc(l), type(DEF) {}
+      Definition(Address a, Absloc l) : addr(a), block(NULL), origLoc(l),
+         type(DEF) {}
+      Definition() : addr(0), block(NULL), type(TOP) {}
+
+      bool operator==(const Definition &other) const {
+         // FIXME: To pass checks in StackAnalysis::summarize(), we consider
+         // definitions equivalent as long as one is not BOTTOM and the other
+         // something else.  This is not proper.
+         //return type == other.type && block == other.block;
+         if (type == BOTTOM && other.type != BOTTOM) return false;
+         if (type != BOTTOM && other.type == BOTTOM) return false;
+         return true;
+      }
+
+      bool operator<(const Definition &rhs) const {
+         if (type == TOP) return false;
+         if (type == BOTTOM && rhs.type == BOTTOM) return false;
+         if (type == BOTTOM) return true;
+
+         if (rhs.type == TOP) return true;
+         if (rhs.type == BOTTOM) return false;
+
+         // At this point we know both are DEFs
+         return block < rhs.block;
+      }
+
+      std::string format() const;
+
+      static Definition meet(const Definition &lhs, const Definition &rhs) {
+         if (lhs.type == TOP) return rhs;
+         if (rhs.type == TOP) return lhs;
+         if (lhs == rhs) return rhs;
+         Definition bottom;
+         bottom.type = BOTTOM;
+         return bottom;
+      }
+   };
+
    class DATAFLOW_EXPORT Height {
    public:
       typedef signed long Height_t;
@@ -178,6 +227,9 @@ public:
       Type type_;
    };
 
+   typedef std::pair<Definition, Height> DefHeight;
+   DATAFLOW_EXPORT static bool isTopSet(const std::set<DefHeight> &s);
+   DATAFLOW_EXPORT static bool isBottomSet(const std::set<DefHeight> &s);
 
    // We need to represent the effects of instructions. We do this in terms of
    // transfer functions. We recognize the following effects on the stack.
@@ -199,8 +251,8 @@ public:
    // they are fixed) and RV as a parameter. Note that a transfer function is a
    // function T : (RegisterVector, RegisterID, RegisterID, value) ->
    // (RegisterVector).
-   typedef std::map<Absloc, Height> AbslocState;
-   class TransferFunc {
+   typedef std::map<Absloc, std::set<DefHeight> > AbslocState;
+   class DATAFLOW_EXPORT TransferFunc {
    public:
       typedef enum {TOP, BOTTOM, OTHER} Type;
 
@@ -255,7 +307,7 @@ public:
          return !(*this == rhs);
       }
 
-      Height apply(const AbslocState &inputs) const;
+      std::set<DefHeight> apply(const AbslocState &inputs) const;
       void accumulate(std::map<Absloc, TransferFunc> &inputs);
       TransferFunc summaryAccumulate(
          const std::map<Absloc, TransferFunc> &inputs) const;
@@ -302,7 +354,8 @@ public:
 
       SummaryFunc() {};
 
-      void apply(const AbslocState &in, AbslocState &out) const;
+      void apply(ParseAPI::Block *block, const AbslocState &in,
+         AbslocState &out) const;
       void accumulate(const TransferSet &in, TransferSet &out) const;
 
       std::string format() const;
@@ -351,10 +404,15 @@ public:
     DATAFLOW_EXPORT virtual ~StackAnalysis();
 
     DATAFLOW_EXPORT Height find(ParseAPI::Block *, Address addr, Absloc loc);
+    DATAFLOW_EXPORT std::set<DefHeight> findDefHeight(ParseAPI::Block *block,
+        Address addr, Absloc loc);
    DATAFLOW_EXPORT Height findSP(ParseAPI::Block *, Address addr);
    DATAFLOW_EXPORT Height findFP(ParseAPI::Block *, Address addr);
    DATAFLOW_EXPORT void findDefinedHeights(ParseAPI::Block* b, Address addr,
       std::vector<std::pair<Absloc, Height> >& heights);
+   // TODO: Update DataflowAPI manual
+   DATAFLOW_EXPORT void findDefHeightPairs(ParseAPI::Block *b, Address addr,
+      std::vector<std::pair<Absloc, std::set<DefHeight> > > &defHeights);
 
    // TODO: Update DataflowAPI manual
    DATAFLOW_EXPORT bool canGetFunctionSummary();
@@ -385,6 +443,9 @@ private:
       AbslocState &input);
    void meetSummaryInputs(ParseAPI::Block *b, TransferSet &blockInput,
       TransferSet &input);
+   DefHeight meetDefHeight(const DefHeight &dh1, const DefHeight &dh2);
+   std::set<DefHeight> meetDefHeights(const std::set<DefHeight> &s1,
+      const std::set<DefHeight> &s2);
    void meet(const AbslocState &source, AbslocState &accum);
    void meetSummary(const TransferSet &source, TransferSet &accum);
    AbslocState getSrcOutputLocs(ParseAPI::Edge* e);
@@ -396,7 +457,8 @@ private:
    bool isJump(InstructionPtr insn);
    bool handleNormalCall(InstructionPtr insn, ParseAPI::Block *block,
       Offset off, TransferFuncs &xferFuncs, TransferSet &funcSummary);
-   bool handleThunkCall(InstructionPtr insn, TransferFuncs &xferFuncs);
+   bool handleThunkCall(InstructionPtr insn, ParseAPI::Block *block,
+      const Offset off, TransferFuncs &xferFuncs);
    bool handleJump(InstructionPtr insn, ParseAPI::Block *block,
       Offset off, TransferFuncs &xferFuncs, TransferSet &funcSummary);
    void handlePushPop(InstructionPtr insn, ParseAPI::Block *block,
@@ -424,6 +486,8 @@ private:
       TransferFuncs &xferFuncs);
    void handleDiv(InstructionPtr insn, TransferFuncs &xferFuncs);
    void handleMul(InstructionPtr insn, TransferFuncs &xferFuncs);
+   void handleSyscall(InstructionPtr insn, ParseAPI::Block *block,
+      const Offset off, TransferFuncs &xferFuncs);
    void handleDefault(InstructionPtr insn, ParseAPI::Block *block,
       const Offset off, TransferFuncs &xferFuncs);
 
@@ -433,8 +497,22 @@ private:
    void copyBaseSubReg(const MachRegister &reg, TransferFuncs &xferFuncs);
    void bottomBaseSubReg(const MachRegister &reg, TransferFuncs &xferFuncs);
 
+   static void makeTopSet(std::set<DefHeight> &s);
+   static void makeBottomSet(std::set<DefHeight> &s);
+   static void makeNewSet(ParseAPI::Block *b, Address addr,
+      const Absloc &origLoc, const Height &h, std::set<DefHeight> &s);
+   static void addInitSet(const Height &h, std::set<DefHeight> &s);
+   static void addDeltaSet(long delta, std::set<DefHeight> &s);
+   static Height getHeightSet(const std::set<DefHeight> &s);
+   static Definition getDefSet(const std::set<DefHeight> &s);
+
+
    Height getStackCleanAmount(ParseAPI::Function *func);
 
+   // This constant limits the number of definitions we track per register. If
+   // more than this many definitions are found, the register is considered to
+   // be BOTTOM, and the definitions tracked so far are dropped.
+   static const unsigned DEF_LIMIT = 2;
 
    ParseAPI::Function *func;
 
diff --git a/dataflowAPI/src/ABI.C b/dataflowAPI/src/ABI.C
index 9389109..fb77137 100644
--- a/dataflowAPI/src/ABI.C
+++ b/dataflowAPI/src/ABI.C
@@ -39,6 +39,7 @@ bitArray ABI::callRead_;
 bitArray ABI::callWritten_;
 bitArray ABI::returnRead_;
 bitArray ABI::returnRegs_;
+bitArray ABI::callParam_;
 bitArray ABI::syscallRead_;
 bitArray ABI::syscallWritten_;
 
@@ -46,6 +47,7 @@ bitArray ABI::callRead64_;
 bitArray ABI::callWritten64_;
 bitArray ABI::returnRead64_;
 bitArray ABI::returnRegs64_;
+bitArray ABI::callParam64_;
 bitArray ABI::syscallRead64_;
 bitArray ABI::syscallWritten64_;
 bitArray ABI::allRegs_;
@@ -141,6 +143,17 @@ const bitArray &ABI::getReturnRegisters() const {
     }
 }
 
+const bitArray &ABI::getParameterRegisters() const {
+    if (addr_width == 4)
+        return callParam_;
+    else if (addr_width == 8)
+        return callParam64_;
+    else {
+        assert(0);
+        return callParam_;
+    }
+}
+
 const bitArray &ABI::getSyscallReadRegisters() const {
     if (addr_width == 4)
         return syscallRead_;
@@ -183,6 +196,7 @@ void ABI::initialize32(){
    returnRegs_ = getBitArray(machRegIndex_x86().size());
    returnRegs_[machRegIndex_x86()[x86::eax]] = true;
 
+   callParam_ = getBitArray(machRegIndex_x86().size());
 
    returnRead_ = getBitArray(machRegIndex_x86().size());
    // Callee-save registers...
@@ -267,6 +281,13 @@ void ABI::initialize64(){
     returnRegs64_[machRegIndex_x86_64()[x86_64::rax]] = true;
     returnRegs64_[machRegIndex_x86_64()[x86_64::rdx]] = true;
 
+    callParam64_ = getBitArray(machRegIndex_x86_64().size());
+    callParam64_[machRegIndex_x86_64()[x86_64::rdi]] = true;
+    callParam64_[machRegIndex_x86_64()[x86_64::rsi]] = true;
+    callParam64_[machRegIndex_x86_64()[x86_64::rdx]] = true;
+    callParam64_[machRegIndex_x86_64()[x86_64::rcx]] = true;
+    callParam64_[machRegIndex_x86_64()[x86_64::r8]] = true;
+    callParam64_[machRegIndex_x86_64()[x86_64::r9]] = true;
 
     returnRead64_ = getBitArray(machRegIndex_x86_64().size());
     returnRead64_[machRegIndex_x86_64()[x86_64::rax]] = true;
@@ -338,6 +359,17 @@ void ABI::initialize32(){
     returnRegs_ = getBitArray(machRegIndex_ppc().size());
     returnRegs_[machRegIndex_ppc()[ppc32::r3]] = true;
 
+    callParam_ = getBitArray(machRegIndex_ppc().size());
+    callParam_[machRegIndex_ppc()[ppc32::r3]] = true;
+    callParam_[machRegIndex_ppc()[ppc32::r4]] = true;
+    callParam_[machRegIndex_ppc()[ppc32::r5]] = true;
+    callParam_[machRegIndex_ppc()[ppc32::r6]] = true;
+    callParam_[machRegIndex_ppc()[ppc32::r7]] = true;
+    callParam_[machRegIndex_ppc()[ppc32::r8]] = true;
+    callParam_[machRegIndex_ppc()[ppc32::r9]] = true;
+    callParam_[machRegIndex_ppc()[ppc32::r10]] = true;
+
+
     returnRead_ = getBitArray(machRegIndex_ppc().size());
     // Return reads r3, r4, fpr1, fpr2
     returnRead_[machRegIndex_ppc()[ppc32::r3]] = true;
@@ -425,6 +457,16 @@ void ABI::initialize64(){
     returnRegs64_ = getBitArray(machRegIndex_ppc_64().size());
     returnRegs64_[machRegIndex_ppc_64()[ppc64::r3]] = true;
 
+    callParam64_ = getBitArray(machRegIndex_ppc_64().size());
+    callParam64_[machRegIndex_ppc_64()[ppc64::r3]] = true;
+    callParam64_[machRegIndex_ppc_64()[ppc64::r4]] = true;
+    callParam64_[machRegIndex_ppc_64()[ppc64::r5]] = true;
+    callParam64_[machRegIndex_ppc_64()[ppc64::r6]] = true;
+    callParam64_[machRegIndex_ppc_64()[ppc64::r7]] = true;
+    callParam64_[machRegIndex_ppc_64()[ppc64::r8]] = true;
+    callParam64_[machRegIndex_ppc_64()[ppc64::r9]] = true;
+    callParam64_[machRegIndex_ppc_64()[ppc64::r10]] = true;
+
     returnRead64_ = getBitArray(machRegIndex_ppc_64().size());
     // Return reads r3, r4, fpr1, fpr2
     returnRead64_[machRegIndex_ppc_64()[ppc64::r3]] = true;
diff --git a/dataflowAPI/src/slicing.C b/dataflowAPI/src/slicing.C
index 8e9b068..86e4136 100644
--- a/dataflowAPI/src/slicing.C
+++ b/dataflowAPI/src/slicing.C
@@ -185,7 +185,7 @@ Slicer::sliceInternal(
 
     // add to graph
     insertInitialNode(ret, dir, aP);
-    if (p.addNodeCallback(a_,visitedEdges)) {
+    if (p.addNodeCallback(a_,visitedEdges) && p.modifyCurrentFrame(initFrame, ret, this)) {
         // initialize slice stack and set for loop detection.
         // the set may be redundant, but speeds up the loopless case.
         addrStack.push_back(initFrame.addr());
@@ -446,7 +446,7 @@ bool Slicer::updateAndLink(
           cand.active[matches[i].reg].push_back(matches[i]);
        }
     }
-    return true;
+    return p.modifyCurrentFrame(cand, g, this);
 }
 
 // similar to updateAndLink, but this version only looks at the
@@ -1488,7 +1488,7 @@ bool Slicer::kills(AbsRegion const&reg, Assignment::Ptr &assign) {
       ABI* abi = ABI::getABI(b_->obj()->cs()->getAddressWidth());
       int index = abi->getIndex(r);
       if (index >= 0)
-          if (abi->getCallWrittenRegisters()[abi->getIndex(r)]) return true;
+          if (abi->getCallWrittenRegisters()[abi->getIndex(r)] && r != x86_64::r11) return true;
   }
   return reg.contains(assign->out());
 }
diff --git a/dataflowAPI/src/stackanalysis.C b/dataflowAPI/src/stackanalysis.C
index 5c98227..90bb9b1 100644
--- a/dataflowAPI/src/stackanalysis.C
+++ b/dataflowAPI/src/stackanalysis.C
@@ -331,7 +331,7 @@ void StackAnalysis::fixpoint(bool verbose) {
       blockInputs[block] = input;
 
       // Step 3: calculate our new outs
-      (*blockEffects)[block].apply(input, blockOutputs[block]);
+      (*blockEffects)[block].apply(block, input, blockOutputs[block]);
       if (verbose) {
          stackanalysis_printf("\t ... output from block: %s\n",
             format(blockOutputs[block]).c_str());
@@ -510,6 +510,9 @@ void StackAnalysis::summarize() {
    if (intervals_ != NULL) delete intervals_;
    intervals_ = new Intervals();
 
+   // Map to record definition addresses as they are resolved.
+   std::map<Block *, std::map<Absloc, Address> > defAddrs;
+
    for (auto bit = blockInputs.begin(); bit != blockInputs.end(); ++bit) {
       Block *block = bit->first;
       AbslocState input = bit->second;
@@ -526,7 +529,16 @@ void StackAnalysis::summarize() {
          for (TransferFuncs::iterator iter2 = xferFuncs.begin();
             iter2 != xferFuncs.end(); ++iter2) {
             input[iter2->target] = iter2->apply(input);
-            if (input[iter2->target].isTop()) {
+            std::set<DefHeight> &s = input[iter2->target];
+            const Definition &def = s.begin()->first;
+            const Height &h = s.begin()->second;
+            if (def.type == Definition::DEF && def.block == NULL) {
+               // New definition
+               STACKANALYSIS_ASSERT(iter2->target == def.origLoc);
+               makeNewSet(block, off, iter2->target, h, s);
+               defAddrs[block][iter2->target] = off;
+            }
+            if (h.isTop()) {
                input.erase(iter2->target);
             }
          }
@@ -541,16 +553,63 @@ void StackAnalysis::summarize() {
                const Absloc &target = summaryIter->first;
                const TransferFunc &tf = summaryIter->second;
                newInput[target] = tf.apply(input);
-               if (newInput[target].isTop()) {
+               std::set<DefHeight> &s = newInput[target];
+               const Definition &def = s.begin()->first;
+               const Height &h = s.begin()->second;
+               if (def.type == Definition::DEF && def.block == NULL) {
+                  // New definition
+                  STACKANALYSIS_ASSERT(target == def.origLoc);
+                  makeNewSet(block, off, target, h, s);
+                  defAddrs[block][target] = off;
+               }
+               if (h.isTop()) {
                   newInput.erase(target);
                }
             }
             input = newInput;
          }
+         //stackanalysis_printf("\tSummary %lx: %s\n", off,
+         //   format(input).c_str());
       }
+
       (*intervals_)[block][block->end()] = input;
+      //stackanalysis_printf("blockOutputs: %s\n",
+      //   format(blockOutputs[block]).c_str());
       STACKANALYSIS_ASSERT(input == blockOutputs[block]);
    }
+
+   // Resolve addresses in all propagated definitions using our map.
+   for (auto bIter = intervals_->begin(); bIter != intervals_->end(); bIter++) {
+      Block *block = bIter->first;
+      for (auto aIter = (*intervals_)[block].begin();
+         aIter != (*intervals_)[block].end(); aIter++) {
+         Address addr = aIter->first;
+         AbslocState &as = aIter->second;
+         for (auto tIter = as.begin(); tIter != as.end(); tIter++) {
+            const Absloc &target = tIter->first;
+            std::set<DefHeight> &dhSet = tIter->second;
+            std::set<DefHeight> dhSetNew;
+            for (auto dIter = dhSet.begin(); dIter != dhSet.end(); dIter++) {
+               const Definition &def = dIter->first;
+               const Height &h = dIter->second;
+               if (def.addr == 0 &&
+                  defAddrs.find(def.block) != defAddrs.end() &&
+                  defAddrs[def.block].find(def.origLoc) !=
+                     defAddrs[def.block].end()) {
+                  // Update this definition using our map
+                  Definition defNew(def.block, defAddrs[def.block][def.origLoc],
+                     def.origLoc);
+                  dhSetNew.insert(std::make_pair(defNew, h));
+               } else {
+                  dhSetNew.insert(std::make_pair(def, h));
+               }
+            }
+            as[target] = dhSetNew;
+         }
+         //stackanalysis_printf("Final defs %lx: %s\n\n", addr,
+         //   format((*intervals_)[block][addr]).c_str());
+      }
+   }
 }
 
 void StackAnalysis::computeInsnEffects(ParseAPI::Block *block,
@@ -580,7 +639,7 @@ void StackAnalysis::computeInsnEffects(ParseAPI::Block *block,
    // Cases we handle
    if (isCall(insn)) {
       if (handleNormalCall(insn, block, off, xferFuncs, funcSummary)) return;
-      else if (handleThunkCall(insn, xferFuncs)) return;
+      else if (handleThunkCall(insn, block, off, xferFuncs)) return;
       else return handleDefault(insn, block, off, xferFuncs);
    }
 
@@ -661,6 +720,9 @@ void StackAnalysis::computeInsnEffects(ParseAPI::Block *block,
       case e_imul:
          handleMul(insn, xferFuncs);
          break;
+      case e_syscall:
+         handleSyscall(insn, block, off, xferFuncs);
+         break;
       default:
          handleDefault(insn, block, off, xferFuncs);
    }
@@ -802,6 +864,29 @@ std::string StackAnalysis::SummaryFunc::format() const {
    return ret.str();
 }
 
+std::string StackAnalysis::Definition::format() const {
+   std::stringstream ret;
+   if (type == TOP) {
+      ret << "TOP";
+   } else if (type == BOTTOM) {
+      ret << "BOTTOM";
+   } else if (addr != 0) {
+      STACKANALYSIS_ASSERT(block != NULL);
+      ret << "0x" << std::hex << block->start() << "-0x" << std::hex <<
+         block->last() << "(";
+      ret << "0x" << std::hex << addr;
+      ret << ", " << origLoc.format();
+      ret << ")";
+   } else if (block != NULL) {
+      ret << "0x" << std::hex << block->start() << "-0x" << std::hex <<
+         block->last() << "(" << origLoc.format() << ")";
+   } else {
+      ret << "BAD";
+   }
+   return ret.str();
+}
+
+
 
 void StackAnalysis::findDefinedHeights(ParseAPI::Block* b, Address addr,
    std::vector<std::pair<Absloc, Height> >& heights) {
@@ -818,12 +903,82 @@ void StackAnalysis::findDefinedHeights(ParseAPI::Block* b, Address addr,
    STACKANALYSIS_ASSERT(intervals_);
    for (AbslocState::iterator i = (*intervals_)[b][addr].begin();
       i != (*intervals_)[b][addr].end(); ++i) {
-      if (i->second.isTop()) continue;
+      if (isTopSet(i->second)) continue;
+
+      heights.push_back(std::make_pair(i->first, getHeightSet(i->second)));
+   }
+}
+
+
+void StackAnalysis::findDefHeightPairs(Block *b, Address addr,
+   std::vector<std::pair<Absloc, std::set<DefHeight> > > &defHeights) {
+   if (func == NULL) return;
+
+   if (!intervals_) {
+      // Check annotation
+      func->getAnnotation(intervals_, Stack_Anno_Intervals);
+   }
+   if (!intervals_) {
+      // Analyze?
+      if (!analyze()) return;
+   }
+   STACKANALYSIS_ASSERT(intervals_);
+   for (AbslocState::iterator i = (*intervals_)[b][addr].begin();
+      i != (*intervals_)[b][addr].end(); ++i) {
+      if (isTopSet(i->second)) continue;
 
-      heights.push_back(*i);
+      defHeights.push_back(std::make_pair(i->first, i->second));
    }
 }
 
+
+std::set<StackAnalysis::DefHeight> StackAnalysis::findDefHeight(Block *b,
+   Address addr, Absloc loc) {
+   std::set<DefHeight> ret;
+   makeTopSet(ret);
+
+   if (func == NULL) return ret;
+
+   if (!intervals_) {
+      // Check annotation
+      func->getAnnotation(intervals_, Stack_Anno_Intervals);
+   }
+   if (!intervals_) {
+      // Analyze?
+      if (!analyze()) return ret;
+   }
+   STACKANALYSIS_ASSERT(intervals_);
+
+   //(*intervals_)[b].find(addr, state);
+   //  ret = (*intervals_)[b][addr][reg];
+   Intervals::iterator iter = intervals_->find(b);
+   if (iter == intervals_->end()) {
+      // How do we return "you stupid idiot"?
+      makeBottomSet(ret);
+      return ret;
+   }
+
+   StateIntervals &sintervals = iter->second;
+   if (sintervals.empty()) {
+      makeBottomSet(ret);
+      return ret;
+   }
+   // Find the last instruction that is <= addr
+   StateIntervals::iterator i = sintervals.lower_bound(addr);
+   if ((i == sintervals.end() && !sintervals.empty()) ||
+      (i->first != addr && i != sintervals.begin())) {
+      i--;
+   }
+   if (i == sintervals.end()) {
+      makeBottomSet(ret);
+      return ret;
+   }
+
+   ret = i->second[loc];
+   return ret;
+}
+
+
 StackAnalysis::Height StackAnalysis::find(Block *b, Address addr, Absloc loc) {
    Height ret; // Defaults to "top"
 
@@ -859,11 +1014,7 @@ StackAnalysis::Height StackAnalysis::find(Block *b, Address addr, Absloc loc) {
    }
    if (i == sintervals.end()) return Height::bottom;
 
-   ret = i->second[loc];
-
-   if (ret.isTop()) {
-      return Height::bottom;
-   }
+   ret = getHeightSet(i->second[loc]);
    return ret;
 }
 
@@ -946,11 +1097,14 @@ public:
          results.push_back(make_pair(rip, false));
       } else if (state != NULL) {
          auto regState = state->find(Absloc(reg));
-         if (regState == state->end() || regState->second.isTop() ||
-            regState->second.isBottom()) {
+         if (regState == state->end() ||
+            regState->second.size() != 1 ||
+            regState->second.begin()->second.isTop() ||
+            regState->second.begin()->second.isBottom()) {
             defined = false;
          } else {
-            results.push_back(make_pair(regState->second.height(), true));
+            results.push_back(make_pair(
+               regState->second.begin()->second.height(), true));
          }
       } else {
          defined = false;
@@ -968,7 +1122,7 @@ private:
 
    // Stack for calculations
    // bool is true if the value in Address is a stack height
-   std::deque<std::pair<Address, bool>> results;
+   std::deque<std::pair<Address, bool> > results;
 
 };
 
@@ -1040,7 +1194,7 @@ void StackAnalysis::handleXor(Instruction::Ptr insn, Block *block,
          // xor mem1, reg2
          STACKANALYSIS_ASSERT(readSet.size() == 1);
          Absloc from((*readSet.begin())->getID());
-         std::map<Absloc, std::pair<long, bool>> fromRegs;
+         std::map<Absloc, std::pair<long, bool> > fromRegs;
          fromRegs[writtenLoc] = std::make_pair(1, true);
          fromRegs[from] = std::make_pair(1, true);
          xferFuncs.push_back(TransferFunc::sibFunc(fromRegs, 0, writtenLoc));
@@ -1084,7 +1238,7 @@ void StackAnalysis::handleXor(Instruction::Ptr insn, Block *block,
             // We have a static address
             readLoc = Absloc(resultPair.first);
          }
-         std::map<Absloc, std::pair<long, bool>> fromRegs;
+         std::map<Absloc, std::pair<long, bool> > fromRegs;
          fromRegs[writtenLoc] = std::make_pair(1, true);
          fromRegs[readLoc] = std::make_pair(1, true);
          xferFuncs.push_back(TransferFunc::sibFunc(fromRegs, 0, writtenLoc));
@@ -1109,7 +1263,7 @@ void StackAnalysis::handleXor(Instruction::Ptr insn, Block *block,
 
    if (read.isValid()) {
       // xor reg1, reg2
-      std::map<Absloc, std::pair<long, bool>> fromRegs;
+      std::map<Absloc, std::pair<long, bool> > fromRegs;
       fromRegs[writtenLoc] = std::make_pair(1, true);
       fromRegs[readLoc] = std::make_pair(1, true);
       xferFuncs.push_back(TransferFunc::sibFunc(fromRegs, 0, writtenLoc));
@@ -1237,7 +1391,8 @@ void StackAnalysis::handlePushPop(Instruction::Ptr insn, Block *block,
       // possible.
       if (intervals_ != NULL) {
          Absloc sploc(sp());
-         Height spHeight = (*intervals_)[block][off][sploc];
+         const std::set<DefHeight> &spSet = (*intervals_)[block][off][sploc];
+         const Height &spHeight = getHeightSet(spSet);
          if (!spHeight.isTop() && !spHeight.isBottom()) {
             // Get written stack slot
             long writtenSlotHeight = spHeight.height() - word_size;
@@ -1258,7 +1413,7 @@ void StackAnalysis::handlePushPop(Instruction::Ptr insn, Block *block,
                // Extract the read address expression
                std::vector<Expression::Ptr> addrExpr;
                readExpr->getChildren(addrExpr);
-               assert(addrExpr.size() == 1);
+               STACKANALYSIS_ASSERT(addrExpr.size() == 1);
 
                // Try to determine the read memory address
                StateEvalVisitor visitor;
@@ -1302,7 +1457,8 @@ void StackAnalysis::handlePushPop(Instruction::Ptr insn, Block *block,
 
       if (intervals_ != NULL) {
          Absloc sploc(sp());
-         Height spHeight = (*intervals_)[block][off][sploc];
+         const std::set<DefHeight> &spSet = (*intervals_)[block][off][sploc];
+         const Height &spHeight = getHeightSet(spSet);
          if (spHeight.isTop()) {
             // Load from a topped location. Since StackMod fails when storing
             // to an undetermined topped location, it is safe to assume the
@@ -1337,9 +1493,10 @@ void StackAnalysis::handleReturn(Instruction::Ptr insn,
    if (operands.size() < 2) {
       delta = word_size;
    } else {
-      fprintf(stderr, "Unhandled RET instruction: %s\n",
-         insn->format().c_str());
-      STACKANALYSIS_ASSERT(false);
+      STACKANALYSIS_ASSERT(operands.size() == 2);
+      Result imm = operands[1].getValue()->eval();
+      STACKANALYSIS_ASSERT(imm.defined);
+      delta = word_size + imm.convert<long>();
    }
 /*   else if (operands.size() == 1) {
       // Ret immediate
@@ -1438,7 +1595,7 @@ void StackAnalysis::handleAddSub(Instruction::Ptr insn, Block *block,
             xferFuncs.push_back(TransferFunc::copyFunc(writtenLoc, writtenLoc,
                true));
          } else {
-            std::map<Absloc, std::pair<long, bool>> terms;
+            std::map<Absloc, std::pair<long, bool> > terms;
             Absloc src(srcReg);
             Absloc &dest = writtenLoc;
             terms[src] = make_pair(sign, false);
@@ -1494,7 +1651,7 @@ void StackAnalysis::handleAddSub(Instruction::Ptr insn, Block *block,
             // We have a static address
             readLoc = Absloc(resultPair.first);
          }
-         std::map<Absloc, std::pair<long, bool>> terms;
+         std::map<Absloc, std::pair<long, bool> > terms;
          terms[readLoc] = make_pair(sign, false);
          terms[writtenLoc] = make_pair(1, false);
          xferFuncs.push_back(TransferFunc::sibFunc(terms, 0, writtenLoc));
@@ -1523,7 +1680,7 @@ void StackAnalysis::handleAddSub(Instruction::Ptr insn, Block *block,
          xferFuncs.push_back(TransferFunc::copyFunc(writtenLoc, writtenLoc,
             true));
       } else {
-         std::map<Absloc, std::pair<long, bool>> terms;
+         std::map<Absloc, std::pair<long, bool> > terms;
          Absloc src(srcReg);
          Absloc &dest = writtenLoc;
          terms[src] = make_pair(sign, false);
@@ -1716,7 +1873,8 @@ void StackAnalysis::handleLeave(Block *block, const Offset off,
       // use the height of the frame pointer at the start of this instruction to
       // track the memory location read by the pop.
       Absloc sploc(fp());
-      Height spHeight = (*intervals_)[block][off][sploc];
+      const std::set<DefHeight> &spSet = (*intervals_)[block][off][sploc];
+      const Height &spHeight = getHeightSet(spSet);
       if (spHeight.isTop()) {
          // Load from a topped location. Since StackMod fails when storing
          // to an undetermined topped location, it is safe to assume the
@@ -2131,6 +2289,25 @@ void StackAnalysis::handleSpecialSignExtend(Instruction::Ptr insn,
    copyBaseSubReg(writtenReg, xferFuncs);
 }
 
+void StackAnalysis::handleSyscall(Instruction::Ptr insn, Block *block,
+   const Offset off, TransferFuncs &xferFuncs) {
+   Architecture arch = insn->getArch();
+   if (arch == Arch_x86) {
+      // x86 returns an error code in EAX
+      xferFuncs.push_back(TransferFunc::retopFunc(Absloc(x86::eax)));
+   } else if (arch == Arch_x86_64) {
+      // x86_64 returns an error code in RAX and destroys RCX and R11
+      xferFuncs.push_back(TransferFunc::retopFunc(Absloc(x86_64::rax)));
+      retopBaseSubReg(x86_64::rax, xferFuncs);
+      xferFuncs.push_back(TransferFunc::retopFunc(Absloc(x86_64::rcx)));
+      retopBaseSubReg(x86_64::rcx, xferFuncs);
+      xferFuncs.push_back(TransferFunc::retopFunc(Absloc(x86_64::r11)));
+      retopBaseSubReg(x86_64::r11, xferFuncs);
+   } else {
+      handleDefault(insn, block, off, xferFuncs);
+   }
+}
+
 // Handle instructions for which we have no special handling implemented.  Be
 // conservative for safety.
 void StackAnalysis::handleDefault(Instruction::Ptr insn, Block *block,
@@ -2233,7 +2410,7 @@ void StackAnalysis::handleDefault(Instruction::Ptr insn, Block *block,
          xferFuncs.push_back(TransferFunc::retopFunc(writtenLoc));
          continue;
       }
-      std::map<Absloc, std::pair<long, bool>> fromRegs;
+      std::map<Absloc, std::pair<long, bool> > fromRegs;
       for (auto rIter = readLocs.begin(); rIter != readLocs.end(); rIter++) {
          const Absloc &readLoc = *rIter;
          fromRegs[readLoc] = std::make_pair(1, true);
@@ -2256,6 +2433,20 @@ bool StackAnalysis::isJump(Instruction::Ptr insn) {
 bool StackAnalysis::handleNormalCall(Instruction::Ptr insn, Block *block,
    Offset off, TransferFuncs &xferFuncs, TransferSet &funcSummary) {
 
+   // Identify syscalls of the form: call *%gs:0x10
+   Expression::Ptr callAddrExpr = insn->getOperand(0).getValue();
+   if (dynamic_cast<Dereference *>(callAddrExpr.get())) {
+      std::vector<Expression::Ptr> children;
+      callAddrExpr->getChildren(children);
+      if (children.size() == 1 &&
+         dynamic_cast<Immediate *>(children[0].get()) &&
+         children[0]->eval().convert<long>() == 16) {
+         // We have a syscall
+         handleSyscall(insn, block, off, xferFuncs);
+         return true;
+      }
+   }
+
    if (!insn->getControlFlowTarget()) return false;
 
    // Must be a thunk based on parsing.
@@ -2285,7 +2476,9 @@ bool StackAnalysis::handleNormalCall(Instruction::Ptr insn, Block *block,
 
          // Update stack slots in the summary to line up with this stack frame,
          // and then add the modified transfer functions to xferFuncs.
-         Height spHeight = (*intervals_)[block][off][Absloc(sp())];
+         Absloc sploc(sp());
+         const std::set<DefHeight> &spSet = (*intervals_)[block][off][sploc];
+         const Height &spHeight = getHeightSet(spSet);
          const TransferSet &fs = functionSummaries[calledAddr];
          for (auto fsIter = fs.begin(); fsIter != fs.end(); fsIter++) {
             Absloc summaryLoc = fsIter->first;
@@ -2315,7 +2508,7 @@ bool StackAnalysis::handleNormalCall(Instruction::Ptr insn, Block *block,
                tf.target = Absloc(newOff, 0, NULL);
                summaryLoc = tf.target;
             }
-            std::map<Absloc, std::pair<long, bool>> newFromRegs;
+            std::map<Absloc, std::pair<long, bool> > newFromRegs;
             for (auto frIter = tf.fromRegs.begin(); frIter != tf.fromRegs.end();
                frIter++) {
                const Absloc &loc = frIter->first;
@@ -2451,7 +2644,9 @@ bool StackAnalysis::handleJump(Instruction::Ptr insn, Block *block, Offset off,
 
          // Update stack slots in the summary to line up with this stack frame,
          // and then add the modified transfer functions to xferFuncs.
-         Height spHeight = (*intervals_)[block][off][Absloc(sp())];
+         Absloc sploc(sp());
+         const std::set<DefHeight> &spSet = (*intervals_)[block][off][sploc];
+         const Height &spHeight = getHeightSet(spSet);
          const TransferSet &fs = functionSummaries[calledAddr];
          for (auto fsIter = fs.begin(); fsIter != fs.end(); fsIter++) {
             Absloc summaryLoc = fsIter->first;
@@ -2481,7 +2676,7 @@ bool StackAnalysis::handleJump(Instruction::Ptr insn, Block *block, Offset off,
                tf.target = Absloc(newOff, 0, NULL);
                summaryLoc = tf.target;
             }
-            std::map<Absloc, std::pair<long, bool>> newFromRegs;
+            std::map<Absloc, std::pair<long, bool> > newFromRegs;
             for (auto frIter = tf.fromRegs.begin(); frIter != tf.fromRegs.end();
                frIter++) {
                const Absloc &loc = frIter->first;
@@ -2574,8 +2769,8 @@ bool StackAnalysis::handleJump(Instruction::Ptr insn, Block *block, Offset off,
    return true;
 }
 
-bool StackAnalysis::handleThunkCall(Instruction::Ptr insn,
-   TransferFuncs &xferFuncs) {
+bool StackAnalysis::handleThunkCall(Instruction::Ptr insn, Block *block,
+   const Offset off, TransferFuncs &xferFuncs) {
 
    // We know that we're not a normal call, so it depends on whether the CFT is
    // "next instruction" or not.
@@ -2592,10 +2787,23 @@ bool StackAnalysis::handleThunkCall(Instruction::Ptr insn,
       Absloc sploc(sp());
       xferFuncs.push_back(TransferFunc::deltaFunc(sploc, -1 * word_size));
       copyBaseSubReg(sp(), xferFuncs);
-      return true;
    }
    // Else we're calling a mov, ret thunk that has no effect on the stack
    // pointer
+
+   // Check the next instruction to see which register is holding the PC.
+   // Assumes next instruction is add thunk_reg, offset.
+   const Address pc = off + insn->size();
+   Instruction::Ptr thunkAddInsn = block->getInsn(pc);
+   if (thunkAddInsn == Instruction::Ptr()) return true;
+   if (thunkAddInsn->getOperation().getID() != e_add) return true;
+   std::set<RegisterAST::Ptr> writtenRegs;
+   thunkAddInsn->getOperand(0).getWriteSet(writtenRegs);
+   if (writtenRegs.size() != 1) return true;
+   const MachRegister &thunkTarget = (*writtenRegs.begin())->getID();
+
+   xferFuncs.push_back(TransferFunc::absFunc(Absloc(thunkTarget), pc));
+   copyBaseSubReg(thunkTarget, xferFuncs);
    return true;
 }
 
@@ -2606,10 +2814,12 @@ void StackAnalysis::createEntryInput(AbslocState &input) {
    // is <wordsize>
    // POWER - the in height is 0
 #if defined(arch_power)
-   input[Absloc(sp())] = Height(0);
+   addInitSet(Height(0), input[Absloc(sp())]);
 #elif (defined(arch_x86) || defined(arch_x86_64))
-   input[Absloc(sp())] = Height(-1 * word_size);
-   if (sp() == x86_64::rsp) input[Absloc(x86_64::esp)] = Height(-word_size);
+   addInitSet(Height(-word_size), input[Absloc(sp())]);
+   if (sp() == x86_64::rsp) {
+      addInitSet(Height(-word_size), input[Absloc(x86_64::esp)]);
+   }
 #else
    STACKANALYSIS_ASSERT(0 && "Unimplemented architecture");
 #endif
@@ -2660,7 +2870,7 @@ StackAnalysis::TransferSet StackAnalysis::getSummarySrcOutputLocs(Edge* e) {
    return blockSummaryOutputs[b];
 }
 
-void StackAnalysis::meetInputs(Block *block, AbslocState& blockInput,
+void StackAnalysis::meetInputs(Block *block, AbslocState &blockInput,
    AbslocState &input) {
    input.clear();
    intra_nosink_nocatch epred2;
@@ -2696,12 +2906,38 @@ void StackAnalysis::meetSummaryInputs(Block *block, TransferSet &blockInput,
 }
 
 
+// Keep track of up to DEF_LIMIT multiple definitions/heights, then bottom
+std::set<StackAnalysis::DefHeight> StackAnalysis::meetDefHeights(
+   const std::set<DefHeight> &s1, const std::set<DefHeight> &s2) {
+   std::set<DefHeight> newSet;
+   if (s1.size() == 1 && s1.begin()->second.isTop()) return s2;
+   if (s2.size() == 1 && s2.begin()->second.isTop()) return s1;
+   if ((s1.size() == 1 && s1.begin()->second.isBottom()) ||
+      (s2.size() == 1 && s2.begin()->second.isBottom())) {
+      makeBottomSet(newSet);
+      return newSet;
+   }
+
+   // At this point, we know that both sets contain only heights since we ensure
+   // that all sets containing TOP/BOTTOM are size 1.
+   newSet = s1;
+   for (auto iter = s2.begin();
+      iter != s2.end() && newSet.size() <= DEF_LIMIT; iter++) {
+      newSet.insert(*iter);
+   }
+   if (newSet.size() > DEF_LIMIT) {
+      makeBottomSet(newSet);
+   }
+   return newSet;
+}
+
+
 void StackAnalysis::meet(const AbslocState &input, AbslocState &accum) {
-   for (AbslocState::const_iterator iter = input.begin();
-      iter != input.end(); ++iter) {
-      accum[iter->first] = Height::meet(iter->second, accum[iter->first]);
-      if (accum[iter->first].isTop()) {
-         accum.erase(iter->first);
+   for (auto iter = input.begin(); iter != input.end(); ++iter) {
+      const Absloc &loc = iter->first;
+      accum[loc] = meetDefHeights(iter->second, accum[loc]);
+      if (accum[loc].begin()->second.isTop()) {
+         accum.erase(loc);
       }
    }
 }
@@ -2844,7 +3080,7 @@ StackAnalysis::TransferFunc StackAnalysis::TransferFunc::meet(
             // possible bases.  Note that current SIB function handling doesn't
             // actually add the terms together.
             // FIXME if SIB function handling changes.
-            std::map<Absloc, std::pair<long, bool>> fromRegs;
+            std::map<Absloc, std::pair<long, bool> > fromRegs;
             fromRegs[lhs.from] = std::make_pair(1, true);
             fromRegs[rhs.from] = std::make_pair(1, true);
             ret = sibFunc(fromRegs, 0, lhs.target);
@@ -2966,32 +3202,103 @@ bool StackAnalysis::TransferFunc::isDelta() const {
 }
 
 bool StackAnalysis::TransferFunc::isSIB() const {
-    return (fromRegs.size() > 0);
+   return (fromRegs.size() > 0);
+}
+
+
+void StackAnalysis::makeTopSet(std::set<DefHeight> &s) {
+   s.clear();
+   s.insert(std::make_pair(Definition(), Height::top));
+}
+
+void StackAnalysis::makeBottomSet(std::set<DefHeight> &s) {
+   s.clear();
+   Definition d;
+   d.type = Definition::BOTTOM;
+   s.insert(std::make_pair(d, Height::bottom));
+}
+
+void StackAnalysis::makeNewSet(Block *b, Address addr, const Absloc &origLoc,
+   const Height &h, std::set<DefHeight> &s) {
+   s.clear();
+   s.insert(std::make_pair(Definition(b, addr, origLoc), h));
+}
+
+void StackAnalysis::addInitSet(const Height &h, std::set<DefHeight> &s) {
+   s.insert(std::make_pair(Definition(), h));
+}
+
+void StackAnalysis::addDeltaSet(long delta, std::set<DefHeight> &s) {
+   std::set<DefHeight> temp = s;
+   s.clear();
+   for (auto iter = temp.begin(); iter != temp.end(); iter++) {
+      const Definition &d = iter->first;
+      const Height &h = iter->second;
+      s.insert(std::make_pair(d, h + delta));
+   }
+}
+
+StackAnalysis::Height StackAnalysis::getHeightSet(
+   const std::set<DefHeight> &s) {
+   Height h;
+   if (s.size() == 0) {
+      h = Height::top;
+   } else if (s.size() == 1) {
+      h = s.begin()->second;
+   } else {
+      h = Height::bottom;
+   }
+   return h;
+}
+
+StackAnalysis::Definition StackAnalysis::getDefSet(
+   const std::set<DefHeight> &s) {
+   Definition d;
+   if (s.size() == 0) {
+      d.type = Definition::TOP;
+   } else if (s.size() == 1) {
+      d = s.begin()->first;
+   } else {
+      d.type = Definition::BOTTOM;
+   }
+   return d;
+}
+
+bool StackAnalysis::isTopSet(const std::set<DefHeight> &s) {
+   if (s.size() == 0) return true;
+   return s.size() == 1 && s.begin()->first.type == Definition::TOP &&
+      s.begin()->second.isTop();
+}
+
+bool StackAnalysis::isBottomSet(const std::set<DefHeight> &s) {
+   return s.size() == 1 && s.begin()->first.type == Definition::BOTTOM &&
+      s.begin()->second.isBottom();
 }
 
 
 // Destructive update of the input map. Assumes inputs are absolute,
 // uninitialized, or bottom; no deltas.
-StackAnalysis::Height StackAnalysis::TransferFunc::apply(
+std::set<StackAnalysis::DefHeight> StackAnalysis::TransferFunc::apply(
    const AbslocState &inputs) const {
    STACKANALYSIS_ASSERT(target.isValid());
+   std:set<DefHeight> inputSet;
    // Bottom stomps everything
    if (isBottom()) {
-      return Height::bottom;
+      makeBottomSet(inputSet);
+      return inputSet;
    }
 
    AbslocState::const_iterator iter = inputs.find(target);
-   Height input;
    if (iter != inputs.end()) {
-      input = iter->second;
+      inputSet = iter->second;
    } else {
-      input = Height::top;
+      makeTopSet(inputSet);
    }
 
    bool isTopBottomOrig = isTopBottom();
 
    if (isSIB()) {
-      input = Height::top; // SIB overwrites, so start at TOP
+      makeTopSet(inputSet);  // SIB overwrites, so start at TOP
       for (auto iter = fromRegs.begin(); iter != fromRegs.end(); ++iter) {
          Absloc curLoc = (*iter).first;
          long curScale = (*iter).second.first;
@@ -3001,29 +3308,18 @@ StackAnalysis::Height StackAnalysis::TransferFunc::apply(
          if (findLoc == inputs.end()) {
             locInput = Height::top;
          } else {
-            locInput = findLoc->second;
+            locInput = getHeightSet(findLoc->second);
          }
 
          if (locInput == Height::top) {
             // This term doesn't affect our end result, so it can be safely
             // ignored.
-         } else if (locInput == Height::bottom) {
-            if (curScale == 1) {
-               // Must bottom everything only if the scale is 1.  Otherwise,
-               // any stack height will be obfuscated.
-               input = Height::bottom;
-               break;
-            }
          } else {
             if (curScale == 1) {
                // If the scale isn't 1, then any stack height is obfuscated,
                // and we can safely ignore the term.
-               if (curTopBottom) {
-                  input = Height::bottom;
-                  break;
-               } else {
-                  input += locInput; // Matt: Always results in bottom?
-               }
+               makeBottomSet(inputSet);
+               break;
             }
          }
       }
@@ -3035,28 +3331,49 @@ StackAnalysis::Height StackAnalysis::TransferFunc::apply(
       // Apply the absolute
       // NOTE: an absolute is not a stack height, set input to top
       //input = abs;
-      input = Height::top;
+      makeTopSet(inputSet);
    }
    if (isCopy()) {
       // Cannot be absolute
       STACKANALYSIS_ASSERT(!isAbs());
       // Copy the input value from whatever we're a copy of.
       AbslocState::const_iterator iter2 = inputs.find(from);
-      if (iter2 != inputs.end()) input = iter2->second;
-      else input = Height::top;
+      if (iter2 != inputs.end()) {
+         const Definition &def = getDefSet(iter2->second);
+         const Height &h = getHeightSet(iter2->second);
+         if (!h.isBottom() && !h.isTop()) {
+            if ((from.isSP() || from.isFP()) &&
+               (target.type() != Absloc::Register ||
+                  (!target.reg().getBaseRegister().isStackPointer() &&
+                     !target.reg().getBaseRegister().isFramePointer()))) {
+               // Create new definitions when based on SP or FP
+               makeNewSet(NULL, 0, target, h, inputSet);
+            } else {
+               // Reuse base definition otherwise
+               inputSet = iter2->second;
+            }
+         } else if (h.isBottom()) {
+            makeBottomSet(inputSet);
+         } else {
+            makeTopSet(inputSet);
+         }
+      } else {
+         makeTopSet(inputSet);
+      }
    }
    if (isDelta()) {
-      input += delta;
+      addDeltaSet(delta, inputSet);
    }
    if (isRetop()) {
-      input = Height::top;
+      makeTopSet(inputSet);
    }
    if (isTopBottomOrig) {
-      if (!input.isTop()) {
-         input = Height::bottom;
+      auto iter = inputSet.begin();
+      if (!iter->second.isTop()) {
+         makeBottomSet(inputSet);
       }
    }
-   return input;
+   return inputSet;
 }
 
 // Returns accumulated transfer function without modifying inputs
@@ -3339,9 +3656,8 @@ void StackAnalysis::TransferFunc::accumulate(TransferSet &inputs) {
 }
 
 
-void StackAnalysis::SummaryFunc::apply(const AbslocState &in,
+void StackAnalysis::SummaryFunc::apply(Block *block, const AbslocState &in,
    AbslocState &out) const {
-
    // Copy all the elements we don't have xfer funcs for.
    out = in;
 
@@ -3350,7 +3666,14 @@ void StackAnalysis::SummaryFunc::apply(const AbslocState &in,
       iter != accumFuncs.end(); ++iter) {
       STACKANALYSIS_ASSERT(iter->first.isValid());
       out[iter->first] = iter->second.apply(in);
-      if (out[iter->first].isTop()) {
+      std::set<DefHeight> &s = out[iter->first];
+      const Definition &def = s.begin()->first;
+      const Height &h = s.begin()->second;
+      if (def.type == Definition::DEF && def.block == NULL) {
+         // New definition
+         makeNewSet(block, 0, def.origLoc, h, s);
+      }
+      if (h.isTop()) {
          out.erase(iter->first);
       }
    }
@@ -3416,9 +3739,14 @@ MachRegister StackAnalysis::fp() {
 
 std::string StackAnalysis::format(const AbslocState &input) const {
    std::stringstream ret;
-   for (AbslocState::const_iterator iter = input.begin();
-      iter != input.end(); ++iter) {
-      ret << iter->first.format() << " := " << iter->second.format() << ", ";
+   for (auto iter = input.begin(); iter != input.end(); ++iter) {
+      const std::set<DefHeight> &s = iter->second;
+      ret << iter->first.format() << " := {";
+      for (auto iter2 = s.begin(); iter2 != s.end(); iter2++) {
+         ret << "(" << iter2->first.format() << ", " <<
+            iter2->second.format() << "), ";
+      }
+      ret << "}, ";
    }
    return ret.str();
 }
diff --git a/dyninstAPI/src/BPatch_object.C b/dyninstAPI/src/BPatch_object.C
index ca413bc..935389a 100644
--- a/dyninstAPI/src/BPatch_object.C
+++ b/dyninstAPI/src/BPatch_object.C
@@ -513,7 +513,26 @@ void funcSummaryFixpoint(std::set<BPatch_function *> funcSet,
             functionSummaries, summarizableSet);
         Address funcBaseAddr = (Address) currFunc->getBaseAddr();
         StackAnalysis::TransferSet summary;
-        bool summarySuccess = sa.getFunctionSummary(summary);
+
+        // Hard-coded function summaries for LibC
+        bool summarySuccess;
+        if (currFunc->getName() == "__libc_memalign") {
+            stackmods_printf("Using hard-coded summary for __libc_memalign\n");
+#if defined(arch_x86)
+            Absloc eax(x86::eax);
+            summary[eax] = StackAnalysis::TransferFunc::retopFunc(eax);
+#elif defined(arch_x86_64)
+            Absloc rax(x86_64::rax);
+            Absloc eax(x86_64::eax);
+            summary[rax] = StackAnalysis::TransferFunc::retopFunc(rax);
+            summary[eax] = StackAnalysis::TransferFunc::retopFunc(eax);
+#else
+            assert(false);
+#endif
+            summarySuccess = true;
+        } else {
+            summarySuccess = sa.getFunctionSummary(summary);
+        }
 
         // If summary has changed, add affected functions back to worklist
         if (summary != functionSummaries[funcBaseAddr]) {
diff --git a/dyninstAPI/src/Relocation/CFG/RelocBlock.C b/dyninstAPI/src/Relocation/CFG/RelocBlock.C
index caae988..502a680 100644
--- a/dyninstAPI/src/Relocation/CFG/RelocBlock.C
+++ b/dyninstAPI/src/Relocation/CFG/RelocBlock.C
@@ -215,8 +215,9 @@ void RelocBlock::processEdge(EdgeDirection e, edge_instance *edge, RelocGraph *c
       block_instance *block = (e == OutEdge) ? edge->trg() : edge->src();
 
       func_instance *f = NULL;
-      // Let's determine the function. If this is a call edge, then block must be
-      // an entry block and we use its function. Otherwise we use ours. 
+      // Let's determine the function. If this is an interprocedural edge,
+      // then block must be an entry block and we use its function. Otherwise
+      // we use ours.
       if (edge->interproc()) {
          f = block->entryOfFunc();
       }
diff --git a/dyninstAPI/src/Relocation/CFG/RelocGraph.C b/dyninstAPI/src/Relocation/CFG/RelocGraph.C
index dc63f41..885361a 100644
--- a/dyninstAPI/src/Relocation/CFG/RelocGraph.C
+++ b/dyninstAPI/src/Relocation/CFG/RelocGraph.C
@@ -211,13 +211,39 @@ bool RelocGraph::changeType(RelocEdge *e, ParseAPI::EdgeTypeEnum t) {
 }
    
 bool Predicates::Interprocedural::operator()(RelocEdge *e) {
-   return (e->type == ParseAPI::CALL ||
-           e->type == ParseAPI::RET);
+    // Calls and returns are always interprocedural
+    if (e->type == ParseAPI::CALL || e->type == ParseAPI::RET) return true;
+
+    // If there is an underlying edge_instance, use its interproc() method
+    if (e->edge != NULL) return e->edge->interproc();
+
+    // If both endpoints are RelocBlocks, check if they are in the same func
+    if (e->src->type() == TargetInt::RelocBlockTarget &&
+        e->trg->type() == TargetInt::RelocBlockTarget) {
+        Target<RelocBlock *> *src = static_cast<Target<RelocBlock *>*>(e->src);
+        Target<RelocBlock *> *trg = static_cast<Target<RelocBlock *>*>(e->trg);
+        return src->t()->func() != trg->t()->func();
+    }
+
+    return false;
 }
 
 bool Predicates::Intraprocedural::operator()(RelocEdge *e) {
-   return (e->type != ParseAPI::CALL &&
-           e->type != ParseAPI::RET);
+    // Calls and returns are always interprocedural
+    if (e->type == ParseAPI::CALL || e->type == ParseAPI::RET) return false;
+
+    // If there is an underlying edge_instance, use its interproc() method
+    if (e->edge != NULL) return !e->edge->interproc();
+
+    // If both endpoints are RelocBlocks, check if they are in the same func
+    if (e->src->type() == TargetInt::RelocBlockTarget &&
+        e->trg->type() == TargetInt::RelocBlockTarget) {
+        Target<RelocBlock *> *src = static_cast<Target<RelocBlock *>*>(e->src);
+        Target<RelocBlock *> *trg = static_cast<Target<RelocBlock *>*>(e->trg);
+        return src->t()->func() == trg->t()->func();
+    }
+
+    return true;
 }
 
 bool Predicates::Fallthrough::operator()(RelocEdge *e) {
diff --git a/dyninstAPI/src/Relocation/CodeBuffer.C b/dyninstAPI/src/Relocation/CodeBuffer.C
index f54ad07..e7d0ccf 100644
--- a/dyninstAPI/src/Relocation/CodeBuffer.C
+++ b/dyninstAPI/src/Relocation/CodeBuffer.C
@@ -315,10 +315,10 @@ void CodeBuffer::updateLabel(unsigned id, Address offset, bool &regenerate) {
    if (!l.valid()) return;
 
    //relocation_cerr << "\t Updating label " << id 
-//                   << " -> " << hex << offset << dec << endl;
+//                   << " -> " << std::hex << offset << std::dec << endl;
    if (l.addr != offset) {
-      //relocation_cerr << "\t\t Old value " << hex << labels_[id].addr
-//                      << ", regenerating!" << dec << endl;
+      //relocation_cerr << "\t\t Old value " << std::hex << labels_[id].addr
+//                      << ", regenerating!" << std::dec << endl;
       regenerate = true;
    }
    l.addr = offset;
@@ -342,15 +342,15 @@ Address CodeBuffer::predictedAddr(unsigned id) {
    switch(label.type) {
       case Label::Absolute:
          //relocation_cerr << "\t\t Requested predicted addr for " << id
-//                         << ", label is absolute, ret " << hex << label.addr << dec << endl;
+//                         << ", label is absolute, ret " << std::hex << label.addr << std::dec << endl;
          return label.addr;
       case Label::Relative:
          assert(gen_.startAddr());
          assert(gen_.startAddr() != (Address) -1);
          //relocation_cerr << "\t\t Requested predicted addr for " << id
-//                         << ", label is relative, ret " << hex << label.addr + gen_.startAddr()
+//                         << ", label is relative, ret " << std::hex << label.addr + gen_.startAddr()
 //                         << " = " << label.addr << " + " << gen_.startAddr()
-            //             << dec << endl;
+            //             << std::dec << endl;
          return label.addr + gen_.startAddr();
       case Label::Estimate: {
          // In this case we want to adjust the address by 
@@ -363,11 +363,11 @@ Address CodeBuffer::predictedAddr(unsigned id) {
          if (label.iteration < curIteration_)
             ret += shift_;
          //relocation_cerr << "\t\t Requested predicted addr for " << id
-//                         << ", label is relative, ret " << hex << ret
+//                         << ", label is relative, ret " << std::hex << ret
     //                     << " = " << label.addr << " + " << gen_.startAddr()
    //                      << " + (" << label.iteration << " < " 
    //                      << curIteration_ << ") ? " << shift_ 
-   //                      << " : 0" << dec << endl;
+   //                      << " : 0" << std::dec << endl;
          return ret;
       }
       default:
diff --git a/dyninstAPI/src/Relocation/Transformers/Movement-adhoc.C b/dyninstAPI/src/Relocation/Transformers/Movement-adhoc.C
index 35d3cfc..254ef00 100644
--- a/dyninstAPI/src/Relocation/Transformers/Movement-adhoc.C
+++ b/dyninstAPI/src/Relocation/Transformers/Movement-adhoc.C
@@ -84,6 +84,44 @@ bool adhocMovementTransformer::process(RelocBlock *cur, RelocGraph *cfg) {
 
     tMap = cur->func()->getTMap();
     assert(tMap);
+
+    // Analyze definitions to figure out how their displacements need to be
+    // modified.
+    std::map<Address, StackAccess *> *definitionMap =
+      cur->func()->getDefinitionMap();
+    for (auto defIter = definitionMap->begin(); defIter != definitionMap->end();
+      defIter++) {
+      const Address defAddr = defIter->first;
+      StackAccess *defAccess = defIter->second;
+
+      // Set up parameters for call to  isStackFrameSensitive
+      Offset origDisp;
+      signed long delta;
+      Accesses tmpAccesses;
+      tmpAccesses[defAccess->reg()].insert(defAccess);
+      ParseAPI::Block *defBlock = NULL;
+      const ParseAPI::Function::blocklist &blocks =
+          cur->func()->ifunc()->blocks();
+      for (auto blockIter = blocks.begin(); blockIter != blocks.end();
+        blockIter++) {
+        ParseAPI::Block *block = *blockIter;
+        Address tmp;
+        if (block->start() <= defAddr && defAddr < block->end() &&
+          block->consistent(defAddr, tmp)) {
+          defBlock = block;
+          break;
+        }
+      }
+      assert(defBlock != NULL);
+
+      // Get origDisp, delta for this definition via isStackFrameSensitive
+      stackmods_printf("Checking isStackFrameSensitive for def @ 0x%lx\n",
+        defAddr);
+      if (isStackFrameSensitive(origDisp, delta, &tmpAccesses, offVec, tMap,
+        defBlock, defAddr)) {
+        definitionDeltas[defAddr] = std::make_pair(origDisp, delta);
+      }
+    }
   }
 #endif
 
@@ -464,125 +502,180 @@ bool adhocMovementTransformer::isStackFrameSensitive(Offset& origDisp,
     ParseAPI::Block* block,
     Address addr)
 {
-    // Track changes after transformations are applied
-    StackAnalysis::Height regDelta(0);  // Change in base register height
-    StackAnalysis::Height readDelta(0);  // Change in access height
-
-    bool ret = false;
-    for (auto iter = accesses->begin(); iter != accesses->end(); ++iter) {
-        MachRegister curReg = (*iter).first;
-        StackAccess* access = (*iter).second;
-
-        // The original difference between base register height and access
-        // height
-        origDisp = access->disp();
-
-        stackmods_printf("\t %s\n", access->format().c_str());
-
-        StackAnalysis::Height regHeightPrime = access->regHeight();
-        StackAnalysis::Height readHeightPrime = access->readHeight();
-
-        stackmods_printf("\t\t regHeight = %ld, readHeight = %ld\n",
-            access->regHeight().height(), access->readHeight().height());
-
-        // Idea: Check for exact match first, then check for overlaps.  This
-        // should fix the case where we add an exact match. However, find is
-        // going to search for any match, so we need to look ourselves.
-
-        bool foundReg = false;
-        bool foundRead = false;
-
-        // Find any updates to regHeight or readHeight (exact matches)
-        for (auto tIter = tMap->begin(); (!foundReg || !foundRead) &&
-            tIter != tMap->end(); ++tIter) {
-            StackLocation* src = (*tIter).first;
-            StackLocation* dest = (*tIter).second;
-
-            stackmods_printf("\t\t\t Checking %s -> %s\n",
-                src->format().c_str(), dest->format().c_str());
-
-            if (src->isStackMemory() && dest->isStackMemory()) {
-                if (src->isRegisterHeight()) {
-                    if (src->off() == access->regHeight()) {
-                        int tmp;
-                        if (src->valid() && !src->valid()->find(addr, tmp)) {
-                            stackmods_printf("\t\t\t\t Matching src height not "
-                                "valid for this PC\n");
-                            continue;
-                        }
+    // Short-circuit if this instruction is a definition that we already
+    // analyzed.
+    if (definitionDeltas.find(addr) != definitionDeltas.end()) {
+       origDisp = definitionDeltas[addr].first;
+       delta = definitionDeltas[addr].second;
+       return true;
+    }
 
-                        if (src->reg() == curReg) {
-                            foundReg = true;
-                            assert(!offVec->isSkip(curReg, access->regHeight(),
-                                block->start(), addr));
-                            regHeightPrime = dest->off();
-                            stackmods_printf("\t\t\t\t regHeight' = %ld\n",
-                                regHeightPrime.height());
+    delta = 0;
+
+    assert(accesses->size() <= 1);
+    if (accesses->size() == 1) {
+        MachRegister curReg = accesses->begin()->first;
+        const std::set<StackAccess *> &accessSet = accesses->begin()->second;
+        const unsigned accessSetSize = accessSet.size();
+
+        // Change in base register height for each possible location accessed
+        StackAnalysis::Height *regDeltas =
+            new StackAnalysis::Height[accessSetSize];
+        // Change in access height for each possible location accessed
+        StackAnalysis::Height *readDeltas =
+            new StackAnalysis::Height[accessSetSize];
+        // Change in definition height for each possible location accessed
+        StackAnalysis::Height *defDeltas =
+            new StackAnalysis::Height[accessSetSize];
+
+        unsigned i = 0;
+        for (auto iter = accessSet.begin(); iter != accessSet.end(); iter++) {
+            StackAccess *access = *iter;
+
+            // The original difference between base register height and access
+            // height
+            origDisp = access->disp();
+
+            stackmods_printf("\t %s\n", access->format().c_str());
+
+            StackAnalysis::Height regHeightPrime = access->regHeight();
+            StackAnalysis::Height readHeightPrime = access->readHeight();
+
+            stackmods_printf("\t\t regHeight = %ld, readHeight = %ld\n",
+                access->regHeight().height(), access->readHeight().height());
+
+            // Idea: Check for exact match first, then check for overlaps.  This
+            // should fix the case where we add an exact match. However, find is
+            // going to search for any match, so we need to look ourselves.
+
+            bool foundReg = false;
+            bool foundRead = false;
+
+            // Find any updates to regHeight or readHeight (exact matches)
+            for (auto tIter = tMap->begin(); (!foundReg || !foundRead) &&
+                tIter != tMap->end(); ++tIter) {
+                StackLocation* src = (*tIter).first;
+                StackLocation* dest = (*tIter).second;
+
+                stackmods_printf("\t\t\t Checking %s -> %s\n",
+                    src->format().c_str(), dest->format().c_str());
+
+                if (src->isStackMemory() && dest->isStackMemory()) {
+                    if (src->isRegisterHeight()) {
+                        if (src->off() == access->regHeight()) {
+                            int tmp;
+                            if (src->valid() &&
+                                !src->valid()->find(addr, tmp)) {
+                                stackmods_printf("\t\t\t\t Matching src height "
+                                    "not valid for this PC\n");
+                                continue;
+                            }
+
+                            if (src->reg() == curReg) {
+                                foundReg = true;
+                                assert(!offVec->isSkip(curReg,
+                                    access->regHeight(), block->start(), addr));
+                                regHeightPrime = dest->off();
+                                stackmods_printf("\t\t\t\t regHeight' = %ld\n",
+                                    regHeightPrime.height());
+                            }
                         }
-                    }
-                } else {
-                    if (src->off() == access->readHeight()) {
-                        int tmp;
-                        if (src->valid() && !src->valid()->find(addr, tmp)) {
-                            stackmods_printf("\t\t\t\t Matching src height not "
-                                "valid for this PC\n");
-                            continue;
+                    } else {
+                        if (src->off() == access->readHeight()) {
+                            int tmp;
+                            if (src->valid() &&
+                                !src->valid()->find(addr, tmp)) {
+                                stackmods_printf("\t\t\t\t Matching src height "
+                                    "not valid for this PC\n");
+                                continue;
+                            }
+
+                            foundRead = true;
+                            readHeightPrime = dest->off();
+                            stackmods_printf("\t\t\t\t readHeight' = %ld\n",
+                                readHeightPrime.height());
                         }
-
-                        foundRead = true;
-                        readHeightPrime = dest->off();
-                        stackmods_printf("\t\t\t\t readHeight' = %ld\n",
-                            readHeightPrime.height());
                     }
+                } else if (src->isNull()) {
+                    stackmods_printf("\t\t\t\t Ignoring: insertion\n");
+                } else {
+                    assert(0);
                 }
-            } else if (src->isNull()) {
-                stackmods_printf("\t\t\t\t Ignoring: insertion\n");
-            } else {
-                assert(0);
             }
-        }
 
-        // Still necessary because accesses contained inside other accesses may
-        // not have an exact offset match in O.
-        // Look for ranges that include the readHeight.
-        for (auto tIter = tMap->begin(); !foundRead && tIter != tMap->end();
-            ++tIter) {
-            StackLocation* src = (*tIter).first;
-            StackLocation* dest = (*tIter).second;
-
-            stackmods_printf("\t\t\t Checking %s -> %s\n",
-                src->format().c_str(), dest->format().c_str());
-            if (src->isStackMemory() && dest->isStackMemory()) {
-                if (src->isRegisterHeight()) {
-                    // Nothing to do
-                } else {
-                    if (src->off() < access->readHeight() &&
-                        access->readHeight() < src->off() + src->size()) {
-                        int tmp;
-                        if (src->valid() && !src->valid()->find(addr, tmp)) {
-                            stackmods_printf("\t\t\t\t Matching src height not "
-                                "valid for this PC\n");
-                            continue;
+            // Still necessary because accesses contained inside other accesses
+            // may not have an exact offset match in O.
+            // Look for ranges that include the readHeight.
+            for (auto tIter = tMap->begin(); !foundRead && tIter != tMap->end();
+                ++tIter) {
+                StackLocation* src = (*tIter).first;
+                StackLocation* dest = (*tIter).second;
+
+                stackmods_printf("\t\t\t Checking %s -> %s\n",
+                    src->format().c_str(), dest->format().c_str());
+                if (src->isStackMemory() && dest->isStackMemory()) {
+                    if (src->isRegisterHeight()) {
+                        // Nothing to do
+                    } else {
+                        if (src->off() < access->readHeight() &&
+                            access->readHeight() < src->off() + src->size()) {
+                            int tmp;
+                            if (src->valid() &&
+                                !src->valid()->find(addr, tmp)) {
+                                stackmods_printf("\t\t\t\t Matching src height "
+                                    "not valid for this PC\n");
+                                continue;
+                            }
+                            foundRead = true;
+                            readHeightPrime = dest->off() +
+                                (access->readHeight() - src->off());
+                            stackmods_printf("\t\t\t\t readHeight' = %ld\n",
+                                readHeightPrime.height());
                         }
-                        foundRead = true;
-                        readHeightPrime = dest->off() +
-                            (access->readHeight() - src->off());
-                        stackmods_printf("\t\t\t\t readHeight' = %ld\n",
-                            readHeightPrime.height());
                     }
                 }
             }
+
+            regDeltas[i] = regHeightPrime - access->regHeight();
+            readDeltas[i] = readHeightPrime - access->readHeight();
+
+            // Check if we have a delta for this access's defintion.  Take it
+            // into account if we do.
+            const StackAnalysis::Definition &def = access->regDef();
+            if (definitionDeltas.find(def.addr) == definitionDeltas.end()) {
+                defDeltas[i] = 0;
+            } else {
+                defDeltas[i] = definitionDeltas[def.addr].second;
+            }
+
+            //stackmods_printf("[isStackFrameSensitive] readD: %ld, regD: %ld, "
+            //   "defD: %ld\n", readDeltas[i].height(), regDeltas[i].height(),
+            //   defDeltas[i].height());
+            i++;
         }
 
-        regDelta += access->regHeight() - regHeightPrime;
-        readDelta += access->readHeight() - readHeightPrime;
-    }
+        // Ensure that this access always needs the same change in displacement
+        // regardless of which location is being accessed.  If accesses to
+        // different locations require different displacements, we can't fix
+        // this instruction for all locations.  In that case, we fail.
+        // TODO: Fail gracefully, allowing other functions to still be
+        //       instrumented
+        delta = readDeltas[0].height() - regDeltas[0].height() -
+            defDeltas[0].height();
+        for (unsigned i = 1; i < accessSetSize; i++) {
+            if (delta != readDeltas[i].height() - regDeltas[i].height() -
+                defDeltas[i].height()) {
+                fprintf(stderr, "Access to multiple locations is unresolvable: "
+                    "different displacements required\n");
+                assert(false);
+            }
+        }
 
-    if (regDelta != readDelta) {
-        ret = true;
-        delta = regDelta.height() - readDelta.height();
+        delete[] regDeltas;
+        delete[] readDeltas;
+        delete[] defDeltas;
     }
 
-    return ret;
+    return delta != 0;
 }
 #endif
diff --git a/dyninstAPI/src/Relocation/Transformers/Movement-adhoc.h b/dyninstAPI/src/Relocation/Transformers/Movement-adhoc.h
index 8d07875..9d65c4d 100644
--- a/dyninstAPI/src/Relocation/Transformers/Movement-adhoc.h
+++ b/dyninstAPI/src/Relocation/Transformers/Movement-adhoc.h
@@ -83,6 +83,8 @@ class adhocMovementTransformer : public Transformer {
 
   // Used for finding call targets
   AddressSpace *addrSpace;
+  // Map of definition addresses to (origDisp, delta) pairs
+  std::map<Address, std::pair<Offset, signed long> > definitionDeltas;
 };
 
 };
diff --git a/dyninstAPI/src/StackMod/StackAccess.C b/dyninstAPI/src/StackMod/StackAccess.C
index c05468c..65abb04 100644
--- a/dyninstAPI/src/StackMod/StackAccess.C
+++ b/dyninstAPI/src/StackMod/StackAccess.C
@@ -33,6 +33,7 @@
 #include "debug.h"
 
 #include "Instruction.h"
+#include "InstructionCategories.h"
 #include "InstructionDecoder.h"
 #include "Expression.h"
 #include "Register.h"
@@ -43,6 +44,7 @@
 
 #include "CFG.h"
 
+#include "ABI.h"
 #include "slicing.h"
 #include "SymEval.h"
 
@@ -82,7 +84,8 @@ std::string StackAccess::format()
     std::stringstream ret;
     ret << "Access to " << _readHeight.height()
         << " from " << _reg.name()
-        << " (at " << _regHeight.height() << ")"
+        << " (at " << _regHeight.height()
+        << ", defined: " << _regDef.format() << ")"
         << ", insn disp = " << _disp
         << ", is " << printStackAccessType(_type);
     return ret.str();
@@ -124,10 +127,11 @@ int getAccessSize(InstructionAPI::Instruction::Ptr insn)
 #endif
 class detectToppedLoc : public InstructionAPI::Visitor {
 private:
-    typedef std::vector<std::pair<Absloc, StackAnalysis::Height>> Heights;
+    typedef std::vector<std::pair<Absloc, std::set<StackAnalysis::DefHeight> > >
+        DefHeights;
     bool defined;
     bool containsToppedReg;
-    Heights heights;
+    DefHeights defHeights;
 
     std::deque<long> results;  // Stack for calculations
 
@@ -137,8 +141,8 @@ private:
     static const long determinable = 0;
 
 public:
-    detectToppedLoc(Heights &h) : defined(true), containsToppedReg(false),
-        heights(h) {}
+    detectToppedLoc(DefHeights &h) : defined(true), containsToppedReg(false),
+        defHeights(h) {}
 
     bool isDefined() {
         return defined && results.size() == 1;
@@ -205,9 +209,9 @@ public:
         }
 
         Absloc regLoc(reg);
-        for (auto iter = heights.begin(); iter != heights.end(); iter++) {
+        for (auto iter = defHeights.begin(); iter != defHeights.end(); iter++) {
             if (regLoc == iter->first) {
-                if (iter->second.isTop()) {
+                if (StackAnalysis::isTopSet(iter->second)) {
                     containsToppedReg = true;
                     results.push_back((long) top);
                 } else {
@@ -216,7 +220,7 @@ public:
                 return;
             }
         }
-        // If reg isn't in heights, its height is TOP
+        // If reg isn't in defHeights, its height is TOP
         containsToppedReg = true;
         results.push_back((long) top);
     }
@@ -226,14 +230,25 @@ public:
     }
 };
 
+
+bool defsSameHeights(const std::set<StackAnalysis::DefHeight> &dhSet) {
+    if (dhSet.size() == 0) return true;
+    const StackAnalysis::Height &h = dhSet.begin()->second;
+    for (auto iter = dhSet.begin(); iter != dhSet.end(); iter++) {
+        if (h != iter->second) return false;
+    }
+    return true;
+}
+
+
 bool getAccesses(ParseAPI::Function* func,
         ParseAPI::Block* block,
         Address addr,
         InstructionAPI::Instruction::Ptr insn,
-        Accesses*& accesses)
+        Accesses* accesses,
+        std::set<Address> &defPointsToMod,
+        bool analyzeDefinition)
 {
-    bool ret = true;
-
     stackmods_printf("\t\t getAccesses %s, 0x%lx @ 0x%lx: %s\n",
         func->name().c_str(), block->start(), addr, insn->format().c_str());
 
@@ -242,26 +257,113 @@ bool getAccesses(ParseAPI::Function* func,
     insn->getReadSet(readRegs);
     StackAnalysis sa(func);
     std::vector<std::pair<Absloc, StackAnalysis::Height> > heights;
+    std::vector<std::pair<Absloc, std::set<StackAnalysis::DefHeight> > >
+        defHeights;
     sa.findDefinedHeights(block, addr, heights);
+    sa.findDefHeightPairs(block, addr, defHeights);
 
     if (insn->getOperation().getID() == e_ret_far ||
         insn->getOperation().getID() == e_ret_near) {
         return true;
     }
 
-    for (auto iter = heights.begin(); iter != heights.end(); ++iter) {
-        // Only consider registers, not tracked memory locations
-        if (iter->first.type() != Absloc::Register) continue;
-        MachRegister curReg = iter->first.reg();
+    unsigned int gpr;
+    if (arch == Arch_x86) {
+        gpr = x86::GPR;
+    } else if (arch == Arch_x86_64) {
+        gpr = x86_64::GPR;
+    } else {
+        assert(0);
+    }
 
-        unsigned int gpr;
-        if (arch == Arch_x86) {
-            gpr = x86::GPR;
-        } else if (arch == Arch_x86_64) {
-            gpr = x86_64::GPR;
+    int word_size = func->isrc()->getAddressWidth();
+
+    // If this instruction is a call, check if any stack pointers are possibly
+    // being passed as parameters.  If so, we don't know what the callee will
+    // access through that pointer and need to return false.
+    if (insn->getCategory() == InstructionAPI::c_CallInsn) {
+        // Check parameter registers for stack pointers
+        ABI *abi = ABI::getABI(word_size);
+        const bitArray &callParamRegs = abi->getParameterRegisters();
+        for (auto iter = abi->getIndexMap()->begin();
+            iter != abi->getIndexMap()->end(); iter++) {
+            const MachRegister &reg = iter->first;
+            if (reg.regClass() == gpr && callParamRegs.test(iter->second)) {
+                // This register is used as a parameter. Check if it contains a
+                // stack pointer.
+                const std::set<StackAnalysis::DefHeight> &dhSet =
+                    sa.findDefHeight(block, addr, Absloc(reg));
+                if (!StackAnalysis::isTopSet(dhSet)) {
+                    for (auto dhIter = dhSet.begin(); dhIter != dhSet.end();
+                        dhIter++) {
+                        const StackAnalysis::Definition &def = dhIter->first;
+                        if (def.addr != 0) {
+                            defPointsToMod.insert(def.addr);
+                        } else {
+                            return false;
+                        }
+                    }
+                }
+            }
+        }
+
+        // Check parameters passed on stack for stack pointers
+        const StackAnalysis::Height &sp = sa.findSP(block, addr);
+        if (!sp.isTop() && !sp.isBottom()) {
+            // Check most recent words on stack for stack pointers.  We check
+            // last 7 words as a reasonable medium between conservatism and
+            // liberalism.
+            long lb = sp.height();
+            long ub = sp.height() + word_size * 7;
+            for (auto iter = heights.begin(); iter != heights.end();
+                iter++) {
+                const Absloc &loc = iter->first;
+                const StackAnalysis::Height &h = iter->second;
+
+                if (loc.type() != Absloc::Stack) continue;
+                long stackOff = loc.off();
+
+                if (stackOff < ub && stackOff >= lb && !h.isTop()) {
+                    const std::set<StackAnalysis::DefHeight> &dhSet =
+                        sa.findDefHeight(block, addr, loc);
+                    for (auto dhIter = dhSet.begin(); dhIter != dhSet.end();
+                        dhIter++) {
+                        const StackAnalysis::Definition &def = dhIter->first;
+                        if (def.addr != 0) {
+                            defPointsToMod.insert(def.addr);
+                        } else {
+                            return false;
+                        }
+                    }
+                }
+            }
         } else {
-            assert(0);
+            // Check all stack locations for stack pointers since we don't know
+            // where RSP is pointing on the stack.
+            for (auto iter = heights.begin(); iter != heights.end(); iter++) {
+                const Absloc &loc = iter->first;
+                const StackAnalysis::Height &h = iter->second;
+                if (loc.type() == Absloc::Stack && !h.isTop()) {
+                    const std::set<StackAnalysis::DefHeight> &dhSet =
+                        sa.findDefHeight(block, addr, loc);
+                    for (auto dhIter = dhSet.begin(); dhIter != dhSet.end();
+                        dhIter++) {
+                        const StackAnalysis::Definition &def = dhIter->first;
+                        if (def.addr != 0) {
+                            defPointsToMod.insert(def.addr);
+                        } else {
+                            return false;
+                        }
+                    }
+                }
+            }
         }
+    }
+
+    for (auto iter = defHeights.begin(); iter != defHeights.end(); ++iter) {
+        // Only consider registers, not tracked memory locations
+        if (iter->first.type() != Absloc::Register) continue;
+        const MachRegister &curReg = iter->first.reg();
 
         // Skip the PC
         if (curReg == MachRegister::getPC(arch)) {
@@ -273,29 +375,59 @@ bool getAccesses(ParseAPI::Function* func,
             continue;
         }
 
-        StackAnalysis::Height curHeight = (*iter).second;
-        StackAccess* access = NULL;
-        if (getMemoryOffset(func,
-                    block,
-                    insn,
-                    addr,
-                    curReg,
-                    curHeight,
-                    access,
-                    arch)) {
-            if (curHeight.isBottom()) {
-                stackmods_printf("\t\t\t\t INVALID: Found access based on "
-                    "register we don't understand (%s = %s)\n",
-                    curReg.name().c_str(), curHeight.format().c_str());
-                // Once we've found a bad access, stop looking!
-                return false;
-            } else {
-                if (access->readHeight().height() > 20480) {
-                    stackmods_printf("\t\t\t\t Found bogus %s. Skipping.\n",
-                        access->format().c_str());
-                    continue;
+        const std::set<StackAnalysis::DefHeight> &dhSet = iter->second;
+        for (auto dhIter = dhSet.begin(); dhIter != dhSet.end(); dhIter++) {
+            const StackAnalysis::Definition &curDef = dhIter->first;
+            const StackAnalysis::Height &curHeight = dhIter->second;
+            StackAccess* access = NULL;
+            if (getMemoryOffset(func,
+                        block,
+                        insn,
+                        addr,
+                        curReg,
+                        curHeight,
+                        curDef,
+                        access,
+                        arch,
+                        analyzeDefinition)) {
+                if (curHeight.isBottom()) {
+                    stackmods_printf("\t\t\t\t INVALID: Found access based on "
+                        "register we don't understand (%s = %s)\n",
+                        curReg.name().c_str(), curHeight.format().c_str());
+                    // Once we've found a bad access, stop looking!
+                    return false;
+                } else {
+                    if (access->readHeight().height() > 20480) {
+                        stackmods_printf("\t\t\t\t Found bogus %s. Skipping.\n",
+                            access->format().c_str());
+                        continue;
+                    }
+                    (*accesses)[curReg].insert(access);
+//                accesses->insert(make_pair(curReg, access));
                 }
-                accesses->insert(make_pair(curReg, access));
+            }
+        }
+
+        // If there are multiple possible heights that can be accessed, verify
+        // that we have definitions for all of them.  Also add the definitions
+        // to defsToMod.
+        if (accesses->find(curReg) != accesses->end() &&
+            (*accesses)[curReg].size() > 1) {
+            stackmods_printf("\t\t\t\t Multiple access locs possible!\n");
+            if (!defsSameHeights(dhSet)) {
+                for (auto dhIter = dhSet.begin(); dhIter != dhSet.end();
+                    dhIter++) {
+                    const StackAnalysis::Definition &d = dhIter->first;
+                    if (d.type != StackAnalysis::Definition::DEF ||
+                        d.addr == 0) {
+                        stackmods_printf("\t\t\t\t INVALID: Multiple accesses "
+                            "possible; missing corresponding definition(s)\n");
+                        return false;
+                    }
+                    defPointsToMod.insert(d.addr);
+                }
+            } else {
+                stackmods_printf("\t\t\t\t All definitions have same height\n");
             }
         }
     }
@@ -309,7 +441,7 @@ bool getAccesses(ParseAPI::Function* func,
         insn->getMemoryWriteOperands(writeOperands);
         assert(writeOperands.size() == 1);
 
-        detectToppedLoc dtl(heights);
+        detectToppedLoc dtl(defHeights);
         (*writeOperands.begin())->apply(&dtl);
         if (dtl.isTopped()) {
             // We are writing to a topped location.
@@ -319,9 +451,10 @@ bool getAccesses(ParseAPI::Function* func,
                 regIter++) {
                 Absloc regLoc((*regIter)->getID());
 
-                for (auto hIter = heights.begin(); hIter != heights.end();
+                for (auto hIter = defHeights.begin(); hIter != defHeights.end();
                     hIter++) {
-                    if (hIter->first == regLoc && !hIter->second.isTop()) {
+                    if (hIter->first == regLoc &&
+                        !StackAnalysis::isTopSet(hIter->second)) {
                         stackmods_printf("\t\t\t\tINVALID: Writing stack "
                             "height to topped location\n");
                         return false;
@@ -338,7 +471,7 @@ bool getAccesses(ParseAPI::Function* func,
         insn->getMemoryReadOperands(readOperands);
         for (auto rIter = readOperands.begin(); rIter != readOperands.end();
             rIter++) {
-            detectToppedLoc dtl(heights);
+            detectToppedLoc dtl(defHeights);
             (*rIter)->apply(&dtl);
             if (dtl.isBottomed()) {
                 stackmods_printf("\t\t\t\tINVALID: Reading unknown stack "
@@ -348,7 +481,16 @@ bool getAccesses(ParseAPI::Function* func,
         }
     }
 
-    return ret;
+    // If we are analyzing a definition and aren't able to find the exact
+    // height of the definition, we won't be able to do any stack modifications.
+    if (analyzeDefinition && (accesses->size() != 1 ||
+        accesses->begin()->second.size() != 1)) {
+        stackmods_printf("\t\t\t\tINVALID: Unable to determine height of "
+            "definition\n");
+        return false;
+    }
+
+    return true;
 }
 
 using namespace InstructionAPI;
@@ -443,10 +585,12 @@ bool getMemoryOffset(ParseAPI::Function* func,
         ParseAPI::Block* block,
         InstructionAPI::InstructionPtr insn,
         Address addr,
-        MachRegister reg,
-        StackAnalysis::Height height,
+        const MachRegister &reg,
+        const StackAnalysis::Height &height,
+        const StackAnalysis::Definition &def,
         StackAccess*& ret,
-        Architecture arch)
+        Architecture arch,
+        bool analyzeDefinition)
 {
     stackmods_printf("\t\t\t getMemoryOffset for %s; checking reg %s = %s\n",
         insn->format().c_str(), reg.name().c_str(), height.format().c_str());
@@ -463,7 +607,9 @@ bool getMemoryOffset(ParseAPI::Function* func,
 
     // Determine how memory is accessed
     StackAccess::StackAccessType type = StackAccess::UNKNOWN;
-    if (insn->readsMemory() && insn->writesMemory()) {
+    if (analyzeDefinition) {
+        type = StackAccess::DEFINITION;
+    } else if (insn->readsMemory() && insn->writesMemory()) {
         type = StackAccess::READWRITE;
     } else if (insn->readsMemory()) {
         type = StackAccess::READ;
@@ -565,6 +711,7 @@ bool getMemoryOffset(ParseAPI::Function* func,
     if (isOffsetSet) {
         ret = new StackAccess();
         ret->setRegHeight(height);
+        ret->setRegDef(def);
         ret->setReg(reg);
         ret->setType(type);
         ret->setDisp(disp);
diff --git a/dyninstAPI/src/StackMod/StackAccess.h b/dyninstAPI/src/StackMod/StackAccess.h
index 98a0382..f7c0839 100644
--- a/dyninstAPI/src/StackMod/StackAccess.h
+++ b/dyninstAPI/src/StackMod/StackAccess.h
@@ -48,6 +48,7 @@ class StackAccess {
             READ,
             READWRITE,
             REGHEIGHT,
+            DEFINITION,
             MISUNDERSTOOD
         };
 
@@ -64,10 +65,13 @@ class StackAccess {
         void setReg(MachRegister r) { _reg = r; }
 
         StackAnalysis::Height regHeight() const { return _regHeight; }
-        void setRegHeight(StackAnalysis::Height h) { _regHeight = h; }
+        void setRegHeight(const StackAnalysis::Height &h) { _regHeight = h; }
+
+        StackAnalysis::Definition regDef() const { return _regDef; }
+        void setRegDef(const StackAnalysis::Definition &d) { _regDef = d; }
 
         StackAnalysis::Height readHeight() const { return _readHeight; }
-        void setReadHeight(StackAnalysis::Height h) { _readHeight = h; }
+        void setReadHeight(const StackAnalysis::Height &h) { _readHeight = h; }
 
         StackAccessType type() const { return _type; }
         void setType(StackAccessType t) { _type = t; }
@@ -82,13 +86,14 @@ class StackAccess {
     private:
         MachRegister _reg;
         StackAnalysis::Height _regHeight;
+        StackAnalysis::Definition _regDef;
         StackAnalysis::Height _readHeight;
         StackAccessType _type;
         signed long _disp;
         bool _skipReg;
 };
 
-typedef std::map<MachRegister,StackAccess*> Accesses;
+typedef std::map<MachRegister, std::set<StackAccess*> > Accesses;
 
 bool isDebugType(StackAccess::StackAccessType t);
 
@@ -98,16 +103,20 @@ bool getAccesses(ParseAPI::Function* func,
         ParseAPI::Block* block,
         Address addr,
         InstructionAPI::Instruction::Ptr insn,
-        Accesses*& accesses);
+        Accesses* accesses,
+        std::set<Address> &defPointsToMod,
+        bool analyzeDefinition = false);
 
 bool getMemoryOffset(ParseAPI::Function* func,
         ParseAPI::Block* block,
         InstructionAPI::Instruction::Ptr insn,
         Address addr,
-        MachRegister reg,
-        StackAnalysis::Height height,
+        const MachRegister &reg,
+        const StackAnalysis::Height &height,
+        const StackAnalysis::Definition &def,
         StackAccess*& ret,
-        Architecture arch);
+        Architecture arch,
+        bool analyzeDefintion = false);
 
 
 #endif
diff --git a/dyninstAPI/src/StackMod/StackModChecker.C b/dyninstAPI/src/StackMod/StackModChecker.C
index c57ab49..e416b94 100644
--- a/dyninstAPI/src/StackMod/StackModChecker.C
+++ b/dyninstAPI/src/StackMod/StackModChecker.C
@@ -1294,10 +1294,15 @@ bool StackModChecker::areModificationsSafe()
             Offset off = (*iIter).first;
             InstructionAPI::InstructionPtr insn = (*iIter).second; 
             Accesses* accesses = func->getAccesses(off);
-            for (auto aIter = accesses->begin(); aIter != accesses->end(); ++aIter) {
-                if (!isAccessSafe(insn, (*aIter).second)) {
-                    return false;
-                } 
+            for (auto aIter = accesses->begin(); aIter != accesses->end();
+                ++aIter) {
+                const std::set<StackAccess *> &accessSet = aIter->second;
+                for (auto setIter = accessSet.begin();
+                    setIter != accessSet.end(); setIter++) {
+                    if (!isAccessSafe(insn, *setIter)) {
+                        return false;
+                    }
+                }
             }
         }
     }
diff --git a/dyninstAPI/src/codegen-x86.C b/dyninstAPI/src/codegen-x86.C
index 9d71301..c35229b 100644
--- a/dyninstAPI/src/codegen-x86.C
+++ b/dyninstAPI/src/codegen-x86.C
@@ -36,6 +36,7 @@
 #include <map>
 #include <string>
 #include "common/src/Types.h"
+#include "common/src/ia32_locations.h"
 #include "codegen.h"
 #include "util.h"
 #include "debug.h"
@@ -1185,7 +1186,8 @@ bool insnCodeGen::modifyData(Address targetAddr, instruction &insn, codeGen &gen
 
     /******************************************* prefix/opcode ****************/
 
-    ia32_instruction instruct;
+    ia32_locations loc;
+    ia32_instruction instruct(NULL, NULL, &loc);
 
     /**
      * This information is generated during ia32_decode. To make this faster
@@ -1203,7 +1205,7 @@ bool insnCodeGen::modifyData(Address targetAddr, instruction &insn, codeGen &gen
         assert(!"Couldn't decode opcode of already known instruction!\n");
 
     /* Calculate the amount of opcode bytes */
-    size_t opcode_len = instruct.getSize() - pref_count;
+    size_t opcode_len = instruct.getLocationInfo().opcode_size;
     origInsn += opcode_len;
 
     /* Get the value of the Mod/RM byte */
@@ -1295,9 +1297,17 @@ bool insnCodeGen::modifyDisp(signed long newDisp, instruction &insn, codeGen &ge
     InstructionAPI::InstructionDecoder d2(origInsn, insnSz, arch);
     InstructionAPI::Instruction::Ptr origInsnPtr = d2.decode();
 
+    bool modifyDefinition = false;
+    if (!origInsnPtr->readsMemory() && !origInsnPtr->writesMemory()) {
+        // This instruction should be a definition
+        modifyDefinition = true;
+    }
+
     StackAccess* origAccess;
     signed long origDisp;
-    if (!getMemoryOffset(NULL, NULL, origInsnPtr, addr, MachRegister(), StackAnalysis::Height(0), origAccess, arch)) {
+    if (!getMemoryOffset(NULL, NULL, origInsnPtr, addr, MachRegister(),
+        StackAnalysis::Height(0), StackAnalysis::Definition(),  origAccess,
+        arch, modifyDefinition)) {
         assert(0);
     } else {
         origDisp = origAccess->disp();
@@ -1478,7 +1488,9 @@ bool insnCodeGen::modifyDisp(signed long newDisp, instruction &insn, codeGen &ge
 
     // Validate
     StackAccess* newAccess = NULL;
-    getMemoryOffset(NULL, NULL, newInsnPtr, addr, MachRegister(), StackAnalysis::Height(0), newAccess, arch);
+    getMemoryOffset(NULL, NULL, newInsnPtr, addr, MachRegister(),
+        StackAnalysis::Height(0), StackAnalysis::Definition(),  newAccess,
+        arch, modifyDefinition);
     if (!newAccess) {
         if (newDisp != 0) {
             return false;
diff --git a/dyninstAPI/src/function.C b/dyninstAPI/src/function.C
index a6bf851..f496e76 100644
--- a/dyninstAPI/src/function.C
+++ b/dyninstAPI/src/function.C
@@ -92,7 +92,8 @@ func_instance::func_instance(parse_func *f,
     _tmpObjects = new set<tmpObject, less_tmpObject>();
     _tMap = new TMap();
     _accessMap = new std::map<Address, Accesses*>();
-    assert(_modifications && _offVec && _tMap && _accessMap);
+    _definitionMap = new std::map<Address, StackAccess *>();
+    assert(_modifications && _offVec && _tMap && _accessMap && _definitionMap);
 #endif
 }
 
@@ -137,7 +138,8 @@ func_instance::func_instance(const func_instance *parFunc,
    _tmpObjects = new set<tmpObject, less_tmpObject>();
    _tMap = new TMap();
    _accessMap = new std::map<Address, Accesses*>();
-   assert(_modifications && _offVec && _tMap && _accessMap);
+   _definitionMap = new std::map<Address, StackAccess *>();
+   assert(_modifications && _offVec && _tMap && _accessMap && _definitionMap);
 #endif
 }
 
@@ -1000,6 +1002,53 @@ bool func_instance::createOffsetVector()
         }
     }
 
+    // Now that createOffsetVector_Analysis has created entries in
+    // _definitionMap for all the definitions we need to modify, we can now fill
+    // out the entries with all the information we need.
+    for (auto defIter = _definitionMap->begin();
+        defIter != _definitionMap->end(); defIter++) {
+        const Address defAddr = defIter->first;
+        StackAccess *&defAccess = defIter->second;
+
+        // Get the appropriate block and instruction for the definition
+        ParseAPI::Block *defBlock = NULL;
+        InstructionAPI::Instruction::Ptr defInsn;
+        for (auto blockIter = blocks.begin(); blockIter != blocks.end();
+            blockIter++) {
+            ParseAPI::Block *block = *blockIter;
+            Address tmp;
+            if (block->start() <= defAddr &&
+                defAddr < block->end() &&
+                block->consistent(defAddr, tmp)) {
+                defBlock = block;
+                defInsn = block->getInsn(defAddr);
+                break;
+            }
+        }
+        assert(defBlock != NULL);
+
+        // Populate definition information in defAccess
+        Accesses tmpDefAccesses;
+        std::set<Address> tmp;
+        if (::getAccesses(func, defBlock, defAddr, defInsn, &tmpDefAccesses,
+            tmp, true)) {
+            assert(tmpDefAccesses.size() == 1);
+            std::set<StackAccess *> &defAccessSet =
+                tmpDefAccesses.begin()->second;
+            assert(defAccessSet.size() == 1);
+            defAccess = *defAccessSet.begin();
+
+            _tmpObjects->insert(tmpObject(defAccess->readHeight().height(),
+                getAccessSize(defInsn), defAccess->type()));
+        } else {
+            // If any definition can't be understood sufficiently, we can't do
+            // stack modifications safely.
+            stackmods_printf("\t\t\t INVALID: getAccesses failed\n");
+            ret = false;
+            break;
+        }
+    }
+
     // Populate offset vector
     for (auto iter = _tmpObjects->begin(); iter != _tmpObjects->end(); ++iter) {
         if (!addToOffsetVector((*iter).offset(), (*iter).size(), (*iter).type(), false, (*iter).valid())) {
@@ -1304,27 +1353,44 @@ bool func_instance::createOffsetVector_Analysis(ParseAPI::Function* func,
     int accessSize = getAccessSize(insn);
     Accesses* accesses = new Accesses();
     assert(accesses);
-    if (::getAccesses(func, block, addr, insn, accesses)) {
+    std::set<Address> defAddrsToMod;
+    if (::getAccesses(func, block, addr, insn, accesses, defAddrsToMod)) {
         _accessMap->insert(make_pair(addr, accesses));
 
+        // Create entries in our definition map for any definitions that need
+        // to be modified.  We will fill out the entries after we've collected
+        // all the definitions.
+        for (auto addrIter = defAddrsToMod.begin();
+            addrIter != defAddrsToMod.end(); addrIter++) {
+            const Address defAddr = *addrIter;
+            if (_definitionMap->find(defAddr) == _definitionMap->end()) {
+                (*_definitionMap)[defAddr] = NULL;
+            }
+        }
+
         for (auto accessIter = accesses->begin(); accessIter != accesses->end();
             ++accessIter) {
-            StackAccess* access = (*accessIter).second;
-
-            stackmods_printf("\t\t Processing %s, size %d\n",
-                access->format().c_str(), accessSize);
-
-            assert(!access->skipReg());
-            if (!addToOffsetVector(access->regHeight(), 1,
-                StackAccess::REGHEIGHT, true, NULL, access->reg())) {
-                stackmods_printf("\t\t\t INVALID: addToOffsetVector failed\n");
-                return false;
+            const std::set<StackAccess *> &saSet = accessIter->second;
+            for (auto saIter = saSet.begin(); saIter != saSet.end(); saIter++) {
+                StackAccess *access = *saIter;
+
+                stackmods_printf("\t\t Processing %s, size %d\n",
+                    access->format().c_str(), accessSize);
+
+                assert(!access->skipReg());
+                if (!addToOffsetVector(access->regHeight(), 1,
+                    StackAccess::REGHEIGHT, true, NULL, access->reg())) {
+                    stackmods_printf("\t\t\t INVALID: addToOffsetVector "
+                        "failed\n");
+                    return false;
+                }
+                _tmpObjects->insert(tmpObject(access->readHeight().height(),
+                    accessSize, access->type()));
             }
-            _tmpObjects->insert(tmpObject(access->readHeight().height(),
-                accessSize, access->type()));
         }
     } else {
         stackmods_printf("\t\t\t INVALID: getAccesses failed\n");
+        delete accesses;
         // Once we've found a bad access, stop looking!
         return false;
     }
@@ -1514,18 +1580,10 @@ void func_instance::createTMap_internal(StackMod* mod, StackLocation* loc, TMap*
                           StackAnalysis::Height c(insertMod->low());
                           StackAnalysis::Height d(insertMod->high());
 
-                          if (!loc->isRegisterHeight()) {
-                              if (off < d || off == d) {
-                                  stackmods_printf("\t\t Processing interaction with %s\n", loc->format().c_str());
-                                  int delta = c.height() - d.height();
-                                tMap->update(loc, delta);
-                              }
-                          } else {
-                              if (off < d || off == d) {
-                                  stackmods_printf("\t\t Processing interaction with %s\n", loc->format().c_str());
-                                  int delta = c.height() - d.height();
-                                  tMap->update(loc, delta);
-                              }
+                          if (off < d || off == d) {
+                              stackmods_printf("\t\t Processing interaction with %s\n", loc->format().c_str());
+                              int delta = c.height() - d.height();
+                              tMap->update(loc, delta);
                           }
                           break;
                       }
diff --git a/dyninstAPI/src/function.h b/dyninstAPI/src/function.h
index db98727..0cf55b0 100644
--- a/dyninstAPI/src/function.h
+++ b/dyninstAPI/src/function.h
@@ -341,6 +341,10 @@ class func_instance : public patchTarget, public Dyninst::PatchAPI::PatchFunctio
   TMap* getTMap() const { return _tMap; }
   void replaceTMap(TMap* newTMap) { _tMap = newTMap; }
 
+  std::map<Address, StackAccess *> *getDefinitionMap() {
+    return _definitionMap;
+  }
+
   bool randomize(TMap* tMap, bool seeded = false, int seed = -1);
   void freeStackMod();
 
@@ -423,8 +427,17 @@ class func_instance : public patchTarget, public Dyninst::PatchAPI::PatchFunctio
   OffsetVector* _offVec;
   set<tmpObject, less_tmpObject >* _tmpObjects;
 
+  // Records transformations to known stack locations and stack pointers due to
+  // stack modifications.
   TMap* _tMap;
+
+  // Records known accesses to stack locations (so we can determine how to
+  // modify the accesses for stack modifications).
   std::map<Address, Accesses*>* _accessMap;
+
+  // Records stack pointer definitions that need to be modified for stack
+  // modifications.
+  std::map<Address, StackAccess *> *_definitionMap;
 #endif
 };
 
diff --git a/parseAPI/CMakeLists.txt b/parseAPI/CMakeLists.txt
index 2e10338..82ca795 100644
--- a/parseAPI/CMakeLists.txt
+++ b/parseAPI/CMakeLists.txt
@@ -25,11 +25,13 @@ set (SRC_LIST
         src/IA_platformDetailsFactory.C 
         src/CFGModifier.C
         src/StackTamperVisitor.C
-	src/JumpTablePred.C
-	src/BoundFactCalculator.C
-	src/BoundFactData.C
+	src/JumpTableFormatPred.C
+	src/JumpTableIndexPred.C
 	src/IndirectAnalyzer.C
 	src/IndirectASTVisitor.C
+	src/SymbolicExpression.C
+	src/BoundFactCalculator.C
+	src/BoundFactData.C
 	src/ThunkData.C
 	../dataflowAPI/src/ABI.C 
 	src/dominator.C
diff --git a/parseAPI/h/CodeObject.h b/parseAPI/h/CodeObject.h
index c8af4d7..a294765 100644
--- a/parseAPI/h/CodeObject.h
+++ b/parseAPI/h/CodeObject.h
@@ -108,6 +108,11 @@ class CodeObject {
     PARSER_EXPORT int findFuncs(CodeRegion * cr,
             Address start, Address end,
             std::set<Function*> & funcs);
+    PARSER_EXPORT int findCurrentFuncs(CodeRegion * cr,
+            Address addr,
+            std::set<Function*> & funcs);
+
+
     PARSER_EXPORT const funclist & funcs() { return flist; }
 
     // blocks
diff --git a/parseAPI/src/BoundFactCalculator.C b/parseAPI/src/BoundFactCalculator.C
index 028cad5..0cba042 100644
--- a/parseAPI/src/BoundFactCalculator.C
+++ b/parseAPI/src/BoundFactCalculator.C
@@ -5,9 +5,8 @@
 #include "BoundFactCalculator.h"
 #include "IndirectASTVisitor.h"
 #include "debug_parse.h"
-#include "JumpTablePred.h"
 #include "Instruction.h"
-
+#include "JumpTableIndexPred.h"
 using namespace Dyninst::InstructionAPI;
 
 void BoundFactsCalculator::NaturalDFS(Node::Ptr cur) {
@@ -234,7 +233,8 @@ bool BoundFactsCalculator::CalculateBoundedFacts() {
 
 		// The current node has a transfer function
 		// that changes the analysis results
-		CalcTransferFunction(curNode, newFactOut);
+		if (!slice->isExitNode(curNode))
+		    CalcTransferFunction(curNode, newFactOut);
 
 		if (boundFactsOut.find(curNode) != boundFactsOut.end() && boundFactsOut[curNode] != NULL)
 		    delete boundFactsOut[curNode];
@@ -265,6 +265,7 @@ void BoundFactsCalculator::ThunkBound( BoundFact*& curFact, Node::Ptr src, Node:
     // This function checks whether any found thunk is between
     // the src node and the trg node. If there is any, then we have
     // extra bound information to be added.
+/*    
     ParseAPI::Block *srcBlock;
     Address srcAddr = 0;
     if (src == Node::Ptr())
@@ -297,7 +298,7 @@ void BoundFactsCalculator::ThunkBound( BoundFact*& curFact, Node::Ptr src, Node:
 	}
 
 	parsing_printf("\t\t\tfind thunk at %lx between the source and the target. Add fact", tit->first);
-	BoundValue *bv = new BoundValue(tit->second.value);
+	StridedInterval *bv = new StridedInterval(tit->second.value);
 	bv->Print();
 	if (first && !newCopy) {
 	    newCopy = true;
@@ -306,7 +307,7 @@ void BoundFactsCalculator::ThunkBound( BoundFact*& curFact, Node::Ptr src, Node:
 	curFact->GenFact(VariableAST::create(Variable(AbsRegion(Absloc(tit->second.reg)))), bv, false);
 	first = false;
     }
-
+*/
 
 }
 
@@ -365,7 +366,7 @@ BoundFact* BoundFactsCalculator::Meet(Node::Ptr curNode) {
 	        else
 	            // DOES THIS REALLY SHOW UP IN 32-BIT CODE???
 	            axAST = VariableAST::create(Variable(AbsRegion(Absloc(x86::eax))));
-	        prevFact->GenFact(axAST, new BoundValue(StridedInterval(1,0,8)), false);
+	        prevFact->GenFact(axAST, new StridedInterval(1,0,8), false);
 	    }
 	} else if (srcNode->assign() && IsConditionalJump(srcNode->assign()->insn())) {
 	    // If the predecessor is a conditional jump,
@@ -376,7 +377,7 @@ BoundFact* BoundFactsCalculator::Meet(Node::Ptr curNode) {
 		assert(0);
 	    }
 	}
-	ThunkBound(prevFact, srcNode, node, newCopy);
+	//ThunkBound(prevFact, srcNode, node, newCopy);
 	parsing_printf("\t\tFact from %lx after applying transfer function\n", srcNode->addr());
 	prevFact->Print();
         if (first) {
@@ -403,7 +404,7 @@ void BoundFactsCalculator::CalcTransferFunction(Node::Ptr curNode, BoundFact *ne
 	node->assign()->out().absloc().reg() == MachRegister::getZeroFlag(func->obj()->cs()->getArch())) {
 	    // zf should be only predecessor of this node
         parsing_printf("\t\tThe predecessor node is zf assignment!\n");
-	newFact->SetPredicate(node->assign(), ExpandAssignment(node->assign()) );
+	newFact->SetPredicate(node->assign(), se.ExpandAssignment(node->assign()) );
 	return;
     }
     entryID id = node->assign()->insn()->getOperation().getID();
@@ -414,7 +415,7 @@ void BoundFactsCalculator::CalcTransferFunction(Node::Ptr curNode, BoundFact *ne
 
     AbsRegion &ar = node->assign()->out();
     Instruction::Ptr insn = node->assign()->insn();
-    pair<AST::Ptr, bool> expandRet = ExpandAssignment(node->assign());
+    pair<AST::Ptr, bool> expandRet = se.ExpandAssignment(node->assign());
 
     if (expandRet.first == NULL) {
         parsing_printf("\t\t\t No semantic support for this instruction. Assume it does not affect jump target calculation. Ignore it (Treat as identity function) except for ptest. ptest should kill the current predicate\n");
@@ -454,8 +455,9 @@ void BoundFactsCalculator::CalcTransferFunction(Node::Ptr curNode, BoundFact *ne
     // In other cases, if the AbsRegion represents a register,
     // the generator is not set.
     if (ar.generator() != NULL)
-        outAST = SimplifyAnAST(RoseAST::create(ROSEOperation(ROSEOperation::derefOp, ar.size()), ar.generator()), 
-	                       PCValue(node->assign()->addr(), 
+        outAST = SymbolicExpression::SimplifyAnAST(
+	                       RoseAST::create(ROSEOperation(ROSEOperation::derefOp, ar.size()), ar.generator()), 
+	                       SymbolicExpression::PCValue(node->assign()->addr(), 
 			               insn->size(), 
 				       node->assign()->block()->obj()->cs()->getArch()));
 
@@ -476,7 +478,7 @@ void BoundFactsCalculator::CalcTransferFunction(Node::Ptr curNode, BoundFact *ne
  * It is important to further anaylze the operand in bsf rather than directly conclude the bound
     if (id == e_bsf || id == e_bsr) {
 	int size = node->assign()->insn()->getOperand(0).getValue()->size();
-	newFact->GenFact(outAST, new BoundValue(StridedInterval(1,0, size * 8 - 1)), false);
+	newFact->GenFact(outAST, new StridedInterval(StridedInterval(1,0, size * 8 - 1)), false);
         parsing_printf("\t\t\tCalculating transfer function: Output facts\n");
 	newFact->Print();
 	return;
@@ -510,7 +512,7 @@ void BoundFactsCalculator::CalcTransferFunction(Node::Ptr curNode, BoundFact *ne
 
     // Assume all SETxx entry ids are contiguous
     if (id >= e_setb && id <= e_setz) {
-        newFact->GenFact(outAST, new BoundValue(StridedInterval(1,0,1)), false);
+        newFact->GenFact(outAST, new StridedInterval(1,0,1), false);
 	parsing_printf("\t\t\tCalculating transfer function: Output facts\n");
 	newFact->Print();
 	return;
@@ -520,7 +522,7 @@ void BoundFactsCalculator::CalcTransferFunction(Node::Ptr curNode, BoundFact *ne
     if (bcv.IsResultBounded(calculation)) {
         findBound = true;
         parsing_printf("\t\t\tGenerate bound fact for %s\n", outAST->format().c_str());
-	newFact->GenFact(outAST, new BoundValue(*bcv.GetResultBound(calculation)), false);
+	newFact->GenFact(outAST, new StridedInterval(*bcv.GetResultBound(calculation)), false);
     }
     else {
         parsing_printf("\t\t\tKill bound fact for %s\n", outAST->format().c_str());
@@ -531,19 +533,19 @@ void BoundFactsCalculator::CalcTransferFunction(Node::Ptr curNode, BoundFact *ne
 	parsing_printf("\t\t\t%s and %s are equal\n", calculation->format().c_str(), outAST->format().c_str());
 	newFact->InsertRelation(calculation, outAST, BoundFact::Equal);
     }
-    if (id == e_movzx)
-        newFact->CheckZeroExtend(outAST);
+//    if (id == e_movzx)
+//        newFact->CheckZeroExtend(outAST);
     newFact->AdjustPredicate(outAST, calculation);
 
     // Now try to track all aliasing.
     // Currently, all variables in the slice are presented as an AST
     // consists of input variables to the slice (the variables that
     // we do not know the sources of their values).
-    newFact->TrackAlias(DeepCopyAnAST(calculation), outAST, findBound);
+    newFact->TrackAlias(SymbolicExpression::DeepCopyAnAST(calculation), outAST, findBound);
 
     // Apply tracking relations to the calculation to generate a
     // potentially stricter bound
-    BoundValue *strictValue = newFact->ApplyRelations(outAST);
+    StridedInterval *strictValue = newFact->ApplyRelations(outAST);
     if (strictValue != NULL) {
         parsing_printf("\t\t\tGenerate stricter bound fact for %s\n", outAST->format().c_str());
 	newFact->GenFact(outAST, strictValue, false);
@@ -587,25 +589,4 @@ BoundFactsCalculator::~BoundFactsCalculator() {
 
 }
 
-pair<AST::Ptr, bool> BoundFactsCalculator::ExpandAssignment(Assignment::Ptr assign) {
-    parsing_printf("Expand assignment : %s Instruction: %s\n", assign->format().c_str(), assign->insn()->format().c_str());
-    if (expandCache.find(assign) != expandCache.end()) {
-        AST::Ptr ast = expandCache[assign];
-        if (ast) return make_pair(ast, true); else return make_pair(ast, false);
-
-    } else {
-        pair<AST::Ptr, bool> expandRet = SymEval::expand(assign, false);
-	if (expandRet.second && expandRet.first) {
-	    parsing_printf("Original expand: %s\n", expandRet.first->format().c_str());
-	    AST::Ptr calculation = SimplifyAnAST(expandRet.first, 
-	                                         PCValue(assign->addr(), 
-						         assign->insn()->size(), 
-							 assign->block()->obj()->cs()->getArch()));
-	    expandCache[assign] = calculation;
-	} else {
-	    expandCache[assign] = AST::Ptr();
-	}
-	return make_pair( expandCache[assign], expandRet.second );
-    }
-}
 
diff --git a/parseAPI/src/BoundFactCalculator.h b/parseAPI/src/BoundFactCalculator.h
index 6a139bb..7dee40e 100644
--- a/parseAPI/src/BoundFactCalculator.h
+++ b/parseAPI/src/BoundFactCalculator.h
@@ -4,7 +4,7 @@
 #include "ThunkData.h"
 #include "BoundFactData.h"
 #include "CFG.h"
-
+#include "SymbolicExpression.h"
 #include "slicing.h"
 
 #include <unordered_set>
@@ -23,10 +23,8 @@ class BoundFactsCalculator {
     ParseAPI::Function *func;
     GraphPtr slice;
     bool firstBlock;
-    ReachFact &rf;
-    ThunkData &thunks;
     bool handleOneByteRead;
-    std::unordered_map<Assignment::Ptr, AST::Ptr, Assignment::AssignmentPtrHasher> &expandCache;
+    SymbolicExpression &se;
 
     void ThunkBound(BoundFact*& curFact, Node::Ptr src, Node::Ptr trg, bool &newCopy);
     BoundFact* Meet(Node::Ptr curNode);
@@ -41,19 +39,15 @@ class BoundFactsCalculator {
     void ReverseDFS(Node::Ptr);
     bool HasIncomingEdgesFromLowerLevel(int curOrder, std::vector<Node::Ptr>& curNodes);
 
-    std::pair<AST::Ptr, bool> ExpandAssignment(Assignment::Ptr);
-
 public:
     bool CalculateBoundedFacts(); 
 
     BoundFactsCalculator(ParseAPI::Function *f, 
                          GraphPtr s, 
 			 bool first, 
-			 ReachFact &r, 
-			 ThunkData &t, 
 			 bool oneByteRead,
-			 std::unordered_map<Assignment::Ptr, AST::Ptr, Assignment::AssignmentPtrHasher>& cache): 
-        func(f), slice(s), firstBlock(first), rf(r), thunks(t), handleOneByteRead(oneByteRead), expandCache(cache) {}
+			 SymbolicExpression &sym):
+        func(f), slice(s), firstBlock(first), handleOneByteRead(oneByteRead), se(sym) {}
 
     BoundFact *GetBoundFactIn(Node::Ptr node);
     BoundFact *GetBoundFactOut(Node::Ptr node);
diff --git a/parseAPI/src/BoundFactData.C b/parseAPI/src/BoundFactData.C
index 8fa36bd..4883b88 100644
--- a/parseAPI/src/BoundFactData.C
+++ b/parseAPI/src/BoundFactData.C
@@ -7,6 +7,7 @@
 #include "CodeSource.h"
 #include "CodeObject.h"
 #include "CFG.h"
+#include "SymbolicExpression.h"
 #include <iostream>
 
 #define MAX_TABLE_ENTRY 1000000
@@ -18,9 +19,6 @@ using namespace Dyninst::DataflowAPI;
 const StridedInterval StridedInterval::top = StridedInterval(1, StridedInterval::minValue, StridedInterval::maxValue);
 const StridedInterval StridedInterval::bottom = StridedInterval();
 
-const BoundValue BoundValue::top = BoundValue(StridedInterval::top);
-const BoundValue BoundValue::bottom = BoundValue();
-
 // Greatest common divisor
 static int64_t GCD(int64_t a, int64_t b) {
     if (a == 0 && b == 0) return 0;
@@ -155,7 +153,7 @@ void StridedInterval::Sub(const StridedInterval& minuend) {
 void StridedInterval::And(const StridedInterval &rhs) {
     // Currently only consider the case where at least one of them is constant
     if (stride == 0) {
-       // CONSTANT and any thing ==> 1[1, CONSTANT]
+       // CONSTANT and any thing ==> 1[0, CONSTANT]
        low = 0;
        stride = 1;
     } else if (rhs.stride == 0) {
@@ -169,14 +167,17 @@ void StridedInterval::And(const StridedInterval &rhs) {
 }
 
 void StridedInterval::Or(const StridedInterval &rhs) {
-    // currently only consider the case where
-    // one of them is 1[0, high], the other is a constant
+    // consider
+    // case 1: one of them is 1[0, high], the other is a constant
+    // case 2: both are 1[0, high]
     if (stride == 0 && rhs.stride == 1 && rhs.low == 0) {
         stride = 1;
 	low = 0;
 	high |= rhs.high;
     } else if (stride == 1 && low == 0 && rhs.stride == 0) {
         high |= rhs.high;
+    } else if (stride == 1 && low == 0 && rhs.stride == 1 && rhs.low == 0) {
+        high |= rhs.high;
     } else {
         // Otherwise, widen
 	*this = top;
@@ -355,324 +356,8 @@ bool StridedInterval::IsConst() const{
     return stride == 0;
 }
 
-BoundValue::BoundValue(int64_t val):
-        interval(val), 
-	targetBase(0), 
-	tableReadSize(0),
-	multiply(1),
-	values(NULL),
-	isInverted(false),
-	isSubReadContent(false),
-	isZeroExtend(false) {}
-
-BoundValue::BoundValue(const StridedInterval &si):
-        interval(si), 
-	targetBase(0), 
-	tableReadSize(0),
-	multiply(1),
-	values(NULL),
-	isInverted(false),
-	isSubReadContent(false),
-	isZeroExtend(false){}
-
-BoundValue::BoundValue():
-        interval(),
-	targetBase(0),
-	tableReadSize(0),
-	multiply(1),
-	values(NULL),
-	isInverted(false),
-	isSubReadContent(false),
-	isZeroExtend(false) {}
-
-BoundValue::BoundValue(const BoundValue & bv):
-        interval(bv.interval),
-	targetBase(bv.targetBase),
-	tableReadSize(bv.tableReadSize),
-	multiply(bv.multiply),
-	values(NULL),
-	isInverted(bv.isInverted),
-	isSubReadContent(bv.isSubReadContent),
-	isZeroExtend(bv.isZeroExtend)
-{
-    if (bv.values != NULL) {
-        values = new set<int64_t>(*(bv.values));
-    }
-}
-
-BoundValue::~BoundValue() {
-    if (values != NULL) {
-        delete values;
-	values = NULL;
-    }
-}
-
-bool BoundValue::operator == (const BoundValue &bv) const {
-    if (values == NULL && bv.values == NULL) {
-        return (interval == bv.interval) &&
-	       (targetBase == bv.targetBase) &&
-	       (tableReadSize == bv.tableReadSize) &&
-	       (multiply == bv.multiply) &&
-	       (isInverted == bv.isInverted) &&
-	       (isSubReadContent == bv.isSubReadContent) &&
-	       (isZeroExtend == bv.isZeroExtend);
-    } else if (values != NULL && bv.values != NULL) {
-        return *values == *bv.values;
-    } else {
-        return false;
-    }
-}
-
-bool BoundValue::operator != (const BoundValue &bv) const {
-    return !(*this == bv);
-}
-
-BoundValue & BoundValue::operator = (const BoundValue &bv) {
-
-    interval = bv.interval;
-    targetBase = bv.targetBase;
-    tableReadSize = bv.tableReadSize;
-    multiply = bv.multiply;
-    isInverted = bv.isInverted;
-    isSubReadContent = bv.isSubReadContent;
-    isZeroExtend = bv.isZeroExtend;
-    if (values != NULL) {
-        delete values;
-	values = NULL;
-    }
-    if (bv.values != NULL) {
-        values = new set<int64_t>(*bv.values);
-    }
-    return *this;
-
-}
-
-void BoundValue::Print() {
-    if (values == NULL) {
-        parsing_printf("Interval %s, ", interval.format().c_str() );
-        parsing_printf("targetBase %lx, ",targetBase);
-        parsing_printf("tableReadSize %d, ", tableReadSize);
-        parsing_printf("multiply %d, ", multiply);
-        parsing_printf("isInverted %d, ", isInverted);
-        parsing_printf("isSubReadContent %d, ", isSubReadContent);
-        parsing_printf("isZeroExtend %d\n", isZeroExtend);
-    } else {
-        parsing_printf("Values:");
-	for (auto vit = values->begin(); vit != values->end(); ++vit)
-	    parsing_printf(" %x", *vit);
-	parsing_printf("\n");
-    }
-}
-
-
-
-BoundValue* BoundFact::GetBound(const AST::Ptr ast) {
-    return GetBound(ast.get());
-}
-
-BoundValue* BoundFact::GetBound(const AST* ast) {
-    BoundValue *ret = NULL;
-    for (auto fit = fact.begin(); fit != fact.end(); ++fit)
-        if (*(fit->first) == *ast) {
-	    ret = fit->second;
-	    break;
-	}
-    return ret;
-}
-
-void BoundValue::IntersectInterval(StridedInterval &si) {
-    if (tableReadSize) {
-        // We are not going to continue tracking
-	// how the memory read is used.
-	// The read contents can be anything, so set to top
-	*this = top;	
-    }
-    parsing_printf("Intersect interval %s and %s", interval.format().c_str(), si.format().c_str());
-    interval.Intersect(si);
-    parsing_printf("resulting in %s\n", interval.format().c_str());
-    if (interval == StridedInterval::bottom) {
-        // If the interval becomes bottom (empty set),
-	// it means that this control flow path is impossble.
-	// However, it is more likely that we miss some control
-	// flow paths. 
-	// We simply abandon previous bounds.
-        interval = si;
-    }
-}
-
-void BoundValue::DeleteElementFromInterval(int64_t val) {
-    interval.DeleteElement(val);
-}
-
-void BoundValue::Join(BoundValue &bv, Block *b) {
-    // If one is a table read and the other is a constant,
-    // assume that the constant appears in the table read.
-    if (tableReadSize > 0 && bv.interval.stride == 0) {
-        return;
-    }
-    if (bv.tableReadSize > 0 && interval.stride == 0) {
-        *this = bv;
-	return;
-    }
-    if (tableReadSize > 0 && bv.tableReadSize > 0) {
-        // If both paths represent a table read,
-	// it could be a case where multiple jump tables share
-	// an indirect jump. 
-	// Example: 0x47947 at libc-2.17.so 
-	set<int64_t> left, right;
-	bool leftRet, rightRet;
-	leftRet = PerformTableRead(*this, left, b->obj()->cs());
-	rightRet = PerformTableRead(bv, right, b->obj()->cs());
-	if (leftRet && rightRet) {
-	    left.insert(right.begin(), right.end());
-	    values = new set<int64_t> (left);
-	    return;
-	}
-    }
-    if (tableReadSize != bv.tableReadSize) {
-        // Unless boths are table reads, we stop trakcing
-	// how the read is used.
-	// Also, since a memory read can be any value,
-	// we set to top.
-	*this = top;
-    } else {
-        interval.Join(bv.interval);
-	if (targetBase != bv.targetBase) targetBase = 0;
-	if (multiply != bv.multiply) multiply = 1;
-	if (isInverted != bv.isInverted) isInverted = false;
-	if (isSubReadContent != bv.isSubReadContent) isSubReadContent = false;
-	if (isZeroExtend != bv.isZeroExtend) isZeroExtend = false;
-    }
-}
-
-void BoundValue::ClearTableCheck(){
-    tableReadSize = 0;
-    targetBase = 0;
-    multiply = 1;
-    isInverted = false;
-    isSubReadContent = false;
-    isZeroExtend = false;
-}
-
-void BoundValue::Add(const BoundValue &rhs) {
-    // First consider the case for: Imm - [table read address]
-    // where the isInverted is true
-    if (tableReadSize && isInverted && rhs.interval.IsConst(1)) {
-        isInverted = false;
-	isSubReadContent = true;
-    } else if (rhs.tableReadSize && rhs.isInverted && interval.IsConst(1)) {
-        *this = rhs;
-        isInverted = false;
-	isSubReadContent = true;
-    }
-    // Then check if we find the target base
-    else if (tableReadSize && !isInverted && rhs.interval.IsConst() && !rhs.tableReadSize) {
-        targetBase = (Address)rhs.interval.low;
-    } else if (rhs.tableReadSize && !rhs.isInverted && interval.IsConst() && !tableReadSize) {
-        int64_t val = interval.low;
-        *this = rhs;
-		targetBase = (Address)val;
-    } 
-    // In other case, we only track the values
-    else {
-        // If either one of the operand is a table read,
-	// then the result can be anything
-        if (tableReadSize || rhs.tableReadSize) {
-	    *this = top;
-	} else {
-	    interval.Add(rhs.interval);
-	    ClearTableCheck();
-	}
-    }
-}
-
-void BoundValue::And(const BoundValue &rhs) { 
-    if (tableReadSize) {        
-        // The memory read content can be anything
-        *this = top;
-    }
-    if (rhs.tableReadSize)
-        interval.And(StridedInterval::top);
-    else
-        interval.And(rhs.interval);
-    
-    // The result is not a table read
-    ClearTableCheck();
-}
-
-void BoundValue::Mul(const BoundValue &rhs) { 
-    if (tableReadSize && rhs.interval.IsConst()) {    
-        multiply *= rhs.interval.low;
-	return;
-    }
-    if (tableReadSize) {        
-        // The memory read content can be anything
-        *this = top;
-    }
-    if (rhs.tableReadSize)
-        interval.Mul(StridedInterval::top);
-    else
-        interval.Mul(rhs.interval);
-    
-    // The result is not a table read
-    ClearTableCheck();
-}
-
-void BoundValue::ShiftLeft(const BoundValue &rhs) {
-    if (tableReadSize && rhs.interval.IsConst()) {
-        multiply *= (1 << rhs.interval.low);
-	return;
-    }
-    if (tableReadSize) {        
-        // The memory read content can be anything
-        *this = top;
-    }
-    if (rhs.tableReadSize)
-        interval.ShiftLeft(StridedInterval::top);
-    else
-        interval.ShiftLeft(rhs.interval);
-    
-    // The result is not a table read
-    ClearTableCheck();
-}
-void BoundValue::ShiftRight(const BoundValue &rhs) {
-    if (tableReadSize) {        
-        // The memory read content can be anything
-        *this = top;
-    }
-    if (rhs.tableReadSize)
-        interval.ShiftRight(StridedInterval::top);
-    else
-        interval.ShiftRight(rhs.interval);
-    
-    // The result is not a table read
-    ClearTableCheck();
-}
-
-void BoundValue::Or(const BoundValue &rhs) { 
-    if (tableReadSize) {        
-        // The memory read content can be anything
-        *this = top;
-    }
-    if (rhs.tableReadSize)
-        interval.Or(StridedInterval::top);
-    else
-        interval.Or(rhs.interval);
-    
-    // The result is not a table read
-    ClearTableCheck();
-}
-
-void BoundValue::Invert() {
-    if (tableReadSize) {        
-        // The memory read content can be anything
-        *this = top;
-    } else {
-        interval.Not();
-    }    
-    // The result is not a table read
-    ClearTableCheck();
-
+void StridedInterval::Print() {
+    parsing_printf("%s\n", format().c_str());
 }
 
 static bool IsInReadOnlyRegion(Address low, Address high) {	
@@ -690,10 +375,11 @@ static bool IsTableIndex(set<uint64_t> &values) {
 	return true;
 }
 
-void BoundValue::MemoryRead(Block* b, int readSize) {
+/*
+void StridedInterval::MemoryRead(Block* b, int readSize) {
         if (interval.stride == 0) {
             // This is a read to variable, not a table read
-	    *this = BoundValue::top;
+	    *this = StridedInterval::top;
             return;
         }
 
@@ -747,16 +433,16 @@ void BoundValue::MemoryRead(Block* b, int readSize) {
 	        tableReadSize = readSize;
 	}	
 }
-
+*/
 void BoundFact::Meet(BoundFact &bf, Block* b) {
         for (auto fit = fact.begin(); fit != fact.end();) {
-	    BoundValue *val2 = bf.GetBound(fit->first);
+	    StridedInterval *val2 = bf.GetBound(fit->first);
 	    // if ast fit->first cannot be found in bf,
 	    // then fit->first is top on this path.
 	    // Anything joins top becomes top
 	    if (val2 != NULL) {
-	        BoundValue *val1 = fit->second;
-		val1->Join(*val2, b);
+	        StridedInterval *val1 = fit->second;
+		val1->Join(*val2);
 		++fit;
 	    } else {
 	        auto toErase = fit;
@@ -833,7 +519,7 @@ void BoundFact::Print() {
     }
 }
 
-void BoundFact::GenFact(const AST::Ptr ast, BoundValue* bv, bool isConditionalJump) {
+void BoundFact::GenFact(const AST::Ptr ast, StridedInterval* bv, bool isConditionalJump) {
     bv->Print();
     KillFact(ast, isConditionalJump);
     fact.insert(make_pair(ast, bv));
@@ -841,24 +527,24 @@ void BoundFact::GenFact(const AST::Ptr ast, BoundValue* bv, bool isConditionalJu
 	if ((*rit)->type == Equal) {
 	    if (*((*rit)->left) == *ast) {
 	        KillFact((*rit)->right, isConditionalJump);
-	        fact.insert(make_pair((*rit)->right, new BoundValue(*bv)));
+	        fact.insert(make_pair((*rit)->right, new StridedInterval(*bv)));
 	    }
 	    if (*((*rit)->right) == *ast) {
 	        KillFact((*rit)->left, isConditionalJump);
-	        fact.insert(make_pair((*rit)->left, new BoundValue(*bv))); 
+	        fact.insert(make_pair((*rit)->left, new StridedInterval(*bv))); 
 	    }
 	}
     }
 
     // Only check alias for bound produced by conditinal jumps.
     if (isConditionalJump) {
-        AST::Ptr subAST = DeepCopyAnAST(ast);
+        AST::Ptr subAST = SymbolicExpression::DeepCopyAnAST(ast);
 	parsing_printf("Before substitute %s\n", ast->format().c_str());
-	subAST = SubstituteAnAST(subAST, aliasMap);
+	subAST = SymbolicExpression::SubstituteAnAST(subAST, aliasMap);
 	parsing_printf("After  substitute %s\n", subAST->format().c_str());
 	if (!(*subAST == *ast)) {
 	    KillFact(subAST, true);
-	    fact.insert(make_pair(subAST, new BoundValue(*bv)));
+	    fact.insert(make_pair(subAST, new StridedInterval(*bv)));
 
 	}
     }
@@ -943,13 +629,13 @@ BoundFact& BoundFact::operator = (const BoundFact &bf) {
         if (fit->second != NULL) delete fit->second;
     fact.clear();
     for (auto fit = bf.fact.begin(); fit != bf.fact.end(); ++fit)     
-        fact.insert(make_pair(fit->first, new BoundValue(*(fit->second))));
+        fact.insert(make_pair(fit->first, new StridedInterval(*(fit->second))));
 
     for (auto rit = relation.begin(); rit != relation.end(); ++rit)
         if (*rit != NULL) delete *rit;
     relation.clear();
     for (auto rit = bf.relation.begin(); rit != bf.relation.end(); ++rit)
-        relation.push_back(new RelationShip(**rit));
+        relation.push_back(new Relation(**rit));
     aliasMap = bf.aliasMap;
 
     return *this;
@@ -1352,16 +1038,16 @@ bool BoundFact::ConditionalJumpBound(Instruction::Ptr insn, EdgeTypeEnum type) {
 
     if (pred.id == e_sub) {
         if (pred.e2->getID() == AST::V_ConstantAST) {
-	    BoundValue *val = GetBound(pred.e1);
+	    StridedInterval *val = GetBound(pred.e1);
 	    if (val != NULL) {
 	        ConstantAST::Ptr constAST = boost::static_pointer_cast<ConstantAST>(pred.e2);
-	        val->interval.Sub(StridedInterval(constAST->val().val));
+	        val->Sub(StridedInterval(constAST->val().val));
 	    }
 	} else if (pred.e1->getID() == AST::V_ConstantAST) {
-	    BoundValue *val = GetBound(pred.e2);
+	    StridedInterval *val = GetBound(pred.e2);
 	    if (val != NULL) {
 	        ConstantAST::Ptr constAST = boost::static_pointer_cast<ConstantAST>(pred.e1);
-	        val->interval.Sub(StridedInterval(constAST->val().val));
+	        val->Sub(StridedInterval(constAST->val().val));
 	    }
 
 	}
@@ -1471,22 +1157,37 @@ void BoundFact::SetToBottom() {
     aliasMap.clear();
 }
 
+StridedInterval* BoundFact::GetBound(const AST::Ptr ast) {
+    return GetBound(ast.get());
+}
+
+StridedInterval* BoundFact::GetBound(const AST* ast) {
+    StridedInterval *ret = NULL;
+    for (auto fit = fact.begin(); fit != fact.end(); ++fit)
+        if (*(fit->first) == *ast) {
+	    ret = fit->second;
+	    break;
+	}
+    return ret;
+}
+
+
 void BoundFact::IntersectInterval(const AST::Ptr ast, StridedInterval si) {
-    BoundValue *bv = GetBound(ast);
+    StridedInterval *bv = GetBound(ast);
     if (bv != NULL) {
-        bv->IntersectInterval(si); 
-        GenFact(ast, new BoundValue(*bv), true);
+        bv->Intersect(si); 
+        GenFact(ast, new StridedInterval(*bv), true);
     } else {
         // If the fact value does not exist,
 	// it means it is top and can be any value.
-        GenFact(ast, new BoundValue(si), true);
+        GenFact(ast, new StridedInterval(si), true);
     }
 }
 
 void BoundFact::DeleteElementFromInterval(const AST::Ptr ast, int64_t val) {
-    BoundValue *bv = GetBound(ast);
+    StridedInterval *bv = GetBound(ast);
     if (bv != NULL) {
-        bv->DeleteElementFromInterval(val);
+        bv->DeleteElement(val);
     }
 }
 
@@ -1499,19 +1200,19 @@ void BoundFact::InsertRelation(AST::Ptr left, AST::Ptr right, RelationType r) {
 	for (size_t i = 0; i < n; ++i)
 	    if (relation[i]->type == Equal) {
 	        if (*(relation[i]->left) == *left && !(*(relation[i]->right) == *right))
-		    relation.push_back(new RelationShip(relation[i]->right, right, r));
+		    relation.push_back(new Relation(relation[i]->right, right, r));
 	        if (*(relation[i]->left) == *right && !(*(relation[i]->right) == *left))
-		    relation.push_back(new RelationShip(relation[i]->right, left, r));
+		    relation.push_back(new Relation(relation[i]->right, left, r));
 		if (*(relation[i]->right) == *left && !(*(relation[i]->left) == *right))
-		    relation.push_back(new RelationShip(relation[i]->left, right, r));
+		    relation.push_back(new Relation(relation[i]->left, right, r));
 	        if (*(relation[i]->right) == *right && !(*(relation[i]->left) == *left))
-		    relation.push_back(new RelationShip(relation[i]->left, left, r));
+		    relation.push_back(new Relation(relation[i]->left, left, r));
 	    }
     } else if (r == NotEqual) {
        // The new added NotEqual relation with an existing relation like UnsignedLessThanOrEqual 
        // can be combined to a more strict relation like UnsignedLessThan
        for (auto rit = relation.begin(); rit != relation.end(); ++rit) {
-           RelationShip * re = *rit;
+           Relation * re = *rit;
 	   if ((*(re->left) == *left && *(re->right) == *right) || 
 	       (*(re->left) == *right && *(re->right) == *left)) {
 	           if (re->type == UnsignedLessThanOrEqual) re->type = UnsignedLessThan;
@@ -1528,7 +1229,7 @@ void BoundFact::InsertRelation(AST::Ptr left, AST::Ptr right, RelationType r) {
                r == SignedLessThanOrEqual || r == SignedLargerThanOrEqual) {
         // Similar to the above case
        for (auto rit = relation.begin(); rit != relation.end(); ++rit) {
-           RelationShip * re = *rit;
+           Relation * re = *rit;
 	   if ((*(re->left) == *left && *(re->right) == *right) || 
 	       (*(re->left) == *right && *(re->right) == *left)) {
 	       if (re->type == NotEqual) {
@@ -1539,7 +1240,7 @@ void BoundFact::InsertRelation(AST::Ptr left, AST::Ptr right, RelationType r) {
            }
        }          
     }
-    relation.push_back(new RelationShip(left, right, r));
+    relation.push_back(new Relation(left, right, r));
 
 }
 
@@ -1586,7 +1287,7 @@ AST::Ptr BoundFact::GetAlias(const AST::Ptr ast) {
 }
 
 void BoundFact::TrackAlias(AST::Ptr expr, AST::Ptr outAST, bool findBound) {
-    expr = SubstituteAnAST(expr, aliasMap);
+    expr = SymbolicExpression::SubstituteAnAST(expr, aliasMap);
     bool find = false;    
     for (auto ait = aliasMap.begin(); ait != aliasMap.end(); ++ait) {
         if (*(ait->first) == *outAST) {
@@ -1598,9 +1299,9 @@ void BoundFact::TrackAlias(AST::Ptr expr, AST::Ptr outAST, bool findBound) {
     if (!find) {
         aliasMap.insert(make_pair(outAST, expr));
     }
-    BoundValue *substiBound = GetBound(expr);
+    StridedInterval *substiBound = GetBound(expr);
     if (substiBound != NULL && !findBound) {
-        GenFact(outAST, new BoundValue(*substiBound), false);
+        GenFact(outAST, new StridedInterval(*substiBound), false);
     }
 }
 
@@ -1611,12 +1312,12 @@ void BoundFact::PushAConst(int64_t value) {
 
 bool BoundFact::PopAConst(AST::Ptr ast) {
     if (!stackTop.valid) return false;
-    GenFact(ast, new BoundValue(stackTop.value), false);
+    GenFact(ast, new StridedInterval(stackTop.value), false);
     stackTop.valid = false;
     return true;
 }
 
-BoundValue * BoundFact::ApplyRelations(AST::Ptr outAST) {
+StridedInterval * BoundFact::ApplyRelations(AST::Ptr outAST) {
     AST::Ptr cal;
     for (auto ait = aliasMap.begin(); ait != aliasMap.end(); ++ait)
         if ( *(ait->first) == *outAST) {
@@ -1651,11 +1352,11 @@ BoundValue * BoundFact::ApplyRelations(AST::Ptr outAST) {
 	      }
     }
     parsing_printf("\t\tApply relation matched: %d\n", matched);
-    if (matched) return new BoundValue(StridedInterval(1,0,baseValue-1));
+    if (matched) return new StridedInterval(StridedInterval(1,0,baseValue-1));
     return NULL;
 }
 
-BoundValue * BoundFact::ApplyRelations2(AST::Ptr outAST) {
+StridedInterval * BoundFact::ApplyRelations2(AST::Ptr outAST) {
     AST::Ptr cal;
     for (auto ait = aliasMap.begin(); ait != aliasMap.end(); ++ait)
         if ( *(ait->first) == *outAST) {
@@ -1687,7 +1388,7 @@ BoundValue * BoundFact::ApplyRelations2(AST::Ptr outAST) {
     if (shrAST->child(0)->getID() != AST::V_VariableAST) return NULL;
     VariableAST::Ptr leftChild2 = boost::static_pointer_cast<VariableAST>(shrAST->child(0));
     if (leftChild->val().reg != leftChild2->val().reg) return NULL;
-    return new BoundValue(StridedInterval(1,0,(1 << shlBit->val().val)-1));
+    return new StridedInterval(StridedInterval(1,0,(1 << shlBit->val().val)-1));
 }
 void BoundFact::SwapFact(AST::Ptr a, AST::Ptr b) {
     auto aIter = fact.end();
@@ -1698,7 +1399,7 @@ void BoundFact::SwapFact(AST::Ptr a, AST::Ptr b) {
     }
 
     if (aIter != fact.end() && bIter != fact.end()) {
-        BoundValue * tmp = aIter->second;
+        StridedInterval * tmp = aIter->second;
         aIter->second = bIter->second;
 	bIter->second = tmp;
     } else if (aIter != fact.end() && bIter == fact.end()) {
@@ -1719,10 +1420,12 @@ void BoundFact::SwapFact(AST::Ptr a, AST::Ptr b) {
 
 
 void BoundFact::CheckZeroExtend(AST::Ptr a) {
+/*
     for (auto fit = fact.begin(); fit != fact.end(); ++fit) {
         if (*(fit->first) == *a) {
-	    BoundValue *val = fit->second;
+	    StridedInterval *val = fit->second;
 	    if (val->tableReadSize > 0) val->isZeroExtend = true;
 	}
     }
+*/
 }
diff --git a/parseAPI/src/BoundFactData.h b/parseAPI/src/BoundFactData.h
index 9aa9c45..c657a1c 100644
--- a/parseAPI/src/BoundFactData.h
+++ b/parseAPI/src/BoundFactData.h
@@ -55,6 +55,7 @@ struct StridedInterval {
     void ShiftLeft(const StridedInterval &rhs);
     void ShiftRight(const StridedInterval &rhs);
     std::string format();
+    void Print();
 
     StridedInterval & operator = (const StridedInterval &rhs);
     bool operator == (const StridedInterval &rhs) const;
@@ -69,50 +70,13 @@ struct StridedInterval {
     bool IsConst() const;
 };
 
-struct BoundValue {
-
-    static const BoundValue top;
-    static const BoundValue bottom;
-
-    StridedInterval interval;
-
-    Address targetBase;    
-    // If tableReadSize == 0, this does not represent a memory access
-    // Otherwise, tableReadSize reprenents the number bytes of the access
-    int tableReadSize;
-    int multiply;
-    std::set<int64_t> * values;
-    bool isInverted;
-    bool isSubReadContent;
-    bool isZeroExtend;
-    BoundValue(int64_t val); 
-    BoundValue(const StridedInterval& si); 
-    BoundValue();
-    BoundValue(const BoundValue & bv);
-    BoundValue& operator = (const BoundValue &bv);
-    ~BoundValue();
-    bool operator< (const BoundValue &bv) const { return interval < bv.interval; }
-    bool operator== (const BoundValue &bv) const;
-    bool operator!= (const BoundValue &bv) const;
-    void Print();
-
-    void SetToBottom();
-    void IntersectInterval(StridedInterval &si);
-    void DeleteElementFromInterval(int64_t val);
-    void Join(BoundValue &bv, ParseAPI::Block* b);
-    void ClearTableCheck();
-    void Add(const BoundValue &rhs);
-    void And(const BoundValue &rhs);
-    void Mul(const BoundValue &rhs);
-    void ShiftLeft(const BoundValue &rhs);
-    void ShiftRight(const BoundValue &rhs);
-    void Or(const BoundValue &rhs);
-    void Invert();
-    void MemoryRead(ParseAPI::Block* b, int readSize);
-};
-
 struct BoundFact {
+    typedef map<AST::Ptr, StridedInterval*> FactType;
+    FactType fact;
 
+    // Sometimes the bound of a jump table index are derived from 
+    // the difference between two values. In this case, it is useful
+    // to know that whether there is a certain relation between the two values
     typedef enum {
         Equal,
 	NotEqual, 
@@ -125,34 +89,32 @@ struct BoundFact {
 	SignedLessThanOrEqual,
 	SignedLargerThanOrEqual,
     } RelationType;
-    typedef map<AST::Ptr, BoundValue*> FactType;
-    FactType fact;
 
-    struct RelationShip {
+    struct Relation {
         AST::Ptr left;
 	AST::Ptr right;
 	RelationType type;
-	RelationShip(AST::Ptr l, AST::Ptr r, RelationType t):
+	Relation(AST::Ptr l, AST::Ptr r, RelationType t):
 	    left(l), right(r), type(t) {}
 
-        bool operator != (const RelationShip &rhs) const {
+        bool operator != (const Relation &rhs) const {
 	    if (type != rhs.type) return true;
 	    if (!(*left == *rhs.left)) return true;
 	    if (!(*right == *rhs.right)) return true;
 	    return false;
 	}
 
-	RelationShip& operator = (const RelationShip &rhs) {
+	Relation& operator = (const Relation &rhs) {
 	    left = rhs.left;
 	    right = rhs.right;
 	    type = rhs.type;
 	    return *this;
 	}
 
-	RelationShip(const RelationShip &r) { *this = r; }
+	Relation(const Relation &r) { *this = r; }
     };
 
-    vector<RelationShip*> relation;
+    vector<Relation*> relation;
 
     // We need to track aliases of each register and memory locations.
     // The left hand side represents an abstract location at the current address
@@ -216,15 +178,15 @@ struct BoundFact {
     bool operator< (const BoundFact &bf) const {return fact < bf.fact; }
     bool operator!= (const BoundFact &bf) const;
 
-    BoundValue* GetBound(const AST::Ptr ast); 
-    BoundValue* GetBound(const AST* ast);
+    StridedInterval* GetBound(const AST::Ptr ast); 
+    StridedInterval* GetBound(const AST* ast);
     AST::Ptr GetAlias(const AST::Ptr ast);
     void Meet(BoundFact &bf, ParseAPI::Block* b);
 
 
     bool ConditionalJumpBound(InstructionAPI::Instruction::Ptr insn, EdgeTypeEnum type);
     void SetPredicate(Assignment::Ptr assign, std::pair<AST::Ptr, bool> expand);
-    void GenFact(const AST::Ptr ast, BoundValue* bv, bool isConditionalJump);
+    void GenFact(const AST::Ptr ast, StridedInterval* bv, bool isConditionalJump);
     void KillFact(const AST::Ptr ast, bool isConditionalJump);
     void SetToBottom();
     void Print();
@@ -235,8 +197,8 @@ struct BoundFact {
     void InsertRelation(AST::Ptr left, AST::Ptr right, RelationType);
     void TrackAlias(AST::Ptr expr, AST::Ptr outAST, bool findBound);
 
-    BoundValue *ApplyRelations(AST::Ptr outAST);
-    BoundValue *ApplyRelations2(AST::Ptr outAST);
+    StridedInterval *ApplyRelations(AST::Ptr outAST);
+    StridedInterval *ApplyRelations2(AST::Ptr outAST);
 
     void PushAConst(int64_t value);
     bool PopAConst(AST::Ptr ast);
diff --git a/parseAPI/src/CodeObject.C b/parseAPI/src/CodeObject.C
index 2ab2e56..da33a14 100644
--- a/parseAPI/src/CodeObject.C
+++ b/parseAPI/src/CodeObject.C
@@ -147,6 +147,11 @@ int CodeObject::findCurrentBlocks(CodeRegion * cr, Address addr, set<Block*> & b
     return parser->findCurrentBlocks(cr,addr,blocks);
 }
 
+int CodeObject::findCurrentFuncs(CodeRegion * cr, Address addr, set<Function*> & funcs)
+{
+    return parser->findCurrentFuncs(cr,addr,funcs);
+}
+
 void
 CodeObject::parse() {
     if(!parser) {
diff --git a/parseAPI/src/IndirectASTVisitor.C b/parseAPI/src/IndirectASTVisitor.C
index 038c48f..c71339e 100644
--- a/parseAPI/src/IndirectASTVisitor.C
+++ b/parseAPI/src/IndirectASTVisitor.C
@@ -3,7 +3,7 @@
 #include "debug_parse.h"
 #include "CodeObject.h"
 #include <algorithm>
-
+#include "SymbolicExpression.h"
 using namespace Dyninst::ParseAPI;
 #define SIGNEX_64_32 0xffffffff00000000LL
 #define SIGNEX_64_16 0xffffffffffff0000LL
@@ -11,190 +11,20 @@ using namespace Dyninst::ParseAPI;
 #define SIGNEX_32_16 0xffff0000
 #define SIGNEX_32_8 0xffffff00
 
-Address PCValue(Address cur, size_t insnSize, Architecture a) {
-    switch (a) {
-        case Arch_x86:
-	case Arch_x86_64:
-	    return cur + insnSize;
-	case Arch_aarch64:
-	    return cur;
-        case Arch_aarch32:
-        case Arch_ppc32:
-        case Arch_ppc64:
-        case Arch_none:
-            assert(0);
-    }    
-    return cur + insnSize;
-}
 
 AST::Ptr SimplifyVisitor::visit(DataflowAPI::RoseAST *ast) {
         unsigned totalChildren = ast->numChildren();
 	for (unsigned i = 0 ; i < totalChildren; ++i) {
 	    ast->child(i)->accept(this);
-	    ast->setChild(i, SimplifyRoot(ast->child(i), addr));
+	    ast->setChild(i, SymbolicExpression::SimplifyRoot(ast->child(i), addr));
 	}
 	return AST::Ptr();
 }
 
-AST::Ptr SimplifyRoot(AST::Ptr ast, Address addr) {
-    if (ast->getID() == AST::V_RoseAST) {
-        RoseAST::Ptr roseAST = boost::static_pointer_cast<RoseAST>(ast); 
-	
-	switch (roseAST->val().op) {
-	    case ROSEOperation::invertOp:
-	        if (roseAST->child(0)->getID() == AST::V_RoseAST) {
-		    RoseAST::Ptr child = boost::static_pointer_cast<RoseAST>(roseAST->child(0));
-		    if (child->val().op == ROSEOperation::invertOp) return child->child(0);
-		} else if (roseAST->child(0)->getID() == AST::V_ConstantAST) {
-		    ConstantAST::Ptr child = boost::static_pointer_cast<ConstantAST>(roseAST->child(0));
-		    size_t size = child->val().size;
-		    uint64_t val = child->val().val;
-		    if (size < 64) {
-		        uint64_t mask = (1ULL << size) - 1;
-		        val = (~val) & mask;
-		    } else
-		        val = ~val;
-		    return ConstantAST::create(Constant(val, size));
-		}
-		break;
-	    case ROSEOperation::extendMSBOp:
-	    case ROSEOperation::extractOp:
-	    case ROSEOperation::signExtendOp:
-	    case ROSEOperation::concatOp:
-	        return roseAST->child(0);
-
-	    case ROSEOperation::addOp:
-	        // We simplify the addition as much as we can
-		// Case 1: two constants
-	        if (roseAST->child(0)->getID() == AST::V_ConstantAST && roseAST->child(1)->getID() == AST::V_ConstantAST) {
-		    ConstantAST::Ptr child0 = boost::static_pointer_cast<ConstantAST>(roseAST->child(0));
-		    ConstantAST::Ptr child1 = boost::static_pointer_cast<ConstantAST>(roseAST->child(1));
-		    uint64_t val = child0->val().val + child1->val().val;
-		    size_t size;
-		    if (child0->val().size > child1->val().size)
-		        size = child0->val().size;
-		    else
-		        size = child1->val().size;
-		    return ConstantAST::create(Constant(val,size));
-   	        }
-		// Case 2: anything adding zero stays the same
-		if (roseAST->child(0)->getID() == AST::V_ConstantAST) {
-		    ConstantAST::Ptr child = boost::static_pointer_cast<ConstantAST>(roseAST->child(0));
-		    if (child->val().val == 0) return roseAST->child(1);
-		}
-		if (roseAST->child(1)->getID() == AST::V_ConstantAST) {
-		    ConstantAST::Ptr child = boost::static_pointer_cast<ConstantAST>(roseAST->child(1));
-		    if (child->val().val == 0) return roseAST->child(0);
-		}
-		// Case 3: if v + v * c = v * (c+1), where v is a variable and c is a constant
-		if (roseAST->child(0)->getID() == AST::V_VariableAST && roseAST->child(1)->getID() == AST::V_RoseAST) {
-		    RoseAST::Ptr rOp = boost::static_pointer_cast<RoseAST>(roseAST->child(1));
-		    if (rOp->val().op == ROSEOperation::uMultOp || rOp->val().op == ROSEOperation::sMultOp) {
-		        if (rOp->child(0)->getID() == AST::V_VariableAST && rOp->child(1)->getID() == AST::V_ConstantAST) {
-			    VariableAST::Ptr varAST1 = boost::static_pointer_cast<VariableAST>(roseAST->child(0));
-			    VariableAST::Ptr varAST2 = boost::static_pointer_cast<VariableAST>(rOp->child(0));
-			    if (varAST1->val().reg == varAST2->val().reg) {
-			        ConstantAST::Ptr oldC = boost::static_pointer_cast<ConstantAST>(rOp->child(1));
-			        ConstantAST::Ptr newC = ConstantAST::create(Constant(oldC->val().val + 1, oldC->val().size));
-				RoseAST::Ptr newRoot = RoseAST::create(ROSEOperation(rOp->val()), varAST1, newC);
-				return newRoot;
-			    }
-			}
-		    }
-		} 
-		break;
-	    case ROSEOperation::sMultOp:
-	    case ROSEOperation::uMultOp:
-	        if (roseAST->child(0)->getID() == AST::V_ConstantAST) {
-		    ConstantAST::Ptr child0 = boost::static_pointer_cast<ConstantAST>(roseAST->child(0));
-		    if (child0->val().val == 1) return roseAST->child(1);
-		}
-
-	        if (roseAST->child(1)->getID() == AST::V_ConstantAST) {
-		    ConstantAST::Ptr child1 = boost::static_pointer_cast<ConstantAST>(roseAST->child(1));
-		    if (child1->val().val == 1) return roseAST->child(0);
-		}
-	        break;
-
-	    case ROSEOperation::xorOp:
-	        if (roseAST->child(0)->getID() == AST::V_VariableAST && roseAST->child(1)->getID() == AST::V_VariableAST) {
-		    VariableAST::Ptr child0 = boost::static_pointer_cast<VariableAST>(roseAST->child(0)); 
-		    VariableAST::Ptr child1 = boost::static_pointer_cast<VariableAST>(roseAST->child(1)); 
-		    if (child0->val() == child1->val()) {
-		        return ConstantAST::create(Constant(0 , 32));
-		    }
-  	        }
-		break;
-	    case ROSEOperation::derefOp:
-	        // Any 8-bit value is bounded in [0,255].
-		// Need to keep the length of the dereference if it is 8-bit.
-		// However, dereference longer than 8-bit should be regarded the same.
-	        if (roseAST->val().size == 8)
-		    return ast;
-		else
-		    return RoseAST::create(ROSEOperation(ROSEOperation::derefOp), ast->child(0));
-		break;
-	    case ROSEOperation::shiftLOp:
-	        if (roseAST->child(0)->getID() == AST::V_ConstantAST && roseAST->child(1)->getID() == AST::V_ConstantAST) {
-		    ConstantAST::Ptr child0 = boost::static_pointer_cast<ConstantAST>(roseAST->child(0));
-		    ConstantAST::Ptr child1 = boost::static_pointer_cast<ConstantAST>(roseAST->child(1));
-		    return ConstantAST::create(Constant(child0->val().val << child1->val().val, 64));
-		}
-		break;
-	    case ROSEOperation::andOp:
-	        if (roseAST->child(0)->getID() == AST::V_ConstantAST && roseAST->child(1)->getID() == AST::V_ConstantAST) {
-		    ConstantAST::Ptr child0 = boost::static_pointer_cast<ConstantAST>(roseAST->child(0));
-		    ConstantAST::Ptr child1 = boost::static_pointer_cast<ConstantAST>(roseAST->child(1));
-		    return ConstantAST::create(Constant(child0->val().val & child1->val().val, 64));
-		}
-		break;
-	    case ROSEOperation::orOp:
-	        if (roseAST->child(0)->getID() == AST::V_ConstantAST && roseAST->child(1)->getID() == AST::V_ConstantAST) {
-		    ConstantAST::Ptr child0 = boost::static_pointer_cast<ConstantAST>(roseAST->child(0));
-		    ConstantAST::Ptr child1 = boost::static_pointer_cast<ConstantAST>(roseAST->child(1));
-		    return ConstantAST::create(Constant(child0->val().val | child1->val().val, 64));
-		}
-		break;
-
-	    default:
-	        break;
-
-	}
-    } else if (ast->getID() == AST::V_VariableAST) {
-        VariableAST::Ptr varAST = boost::static_pointer_cast<VariableAST>(ast);
-	if (varAST->val().reg.absloc().isPC()) {
-	    MachRegister pc = varAST->val().reg.absloc().reg();	    
-	    return ConstantAST::create(Constant(addr, getArchAddressWidth(pc.getArchitecture()) * 8));
-	}
-	// We do not care about the address of the a-loc
-	// because we will keep tracking the changes of 
-	// each a-loc. Also, this brings a benefit that
-	// we can directly use ast->isStrictEqual() to 
-	// compare two ast.
-	return VariableAST::create(Variable(varAST->val().reg));
-    } else if (ast->getID() == AST::V_ConstantAST) {
-        ConstantAST::Ptr constAST = boost::static_pointer_cast<ConstantAST>(ast);
-	size_t size = constAST->val().size;
-	uint64_t val = constAST->val().val;	
-	if (size == 32)
-	    if (!(val & (1ULL << (size - 1))))
-	        return ConstantAST::create(Constant(val, 64));
-    }
-
-    return ast;
-}
-
-
-AST::Ptr SimplifyAnAST(AST::Ptr ast, Address addr) {
-    SimplifyVisitor sv(addr);
-    ast->accept(&sv);
-    return SimplifyRoot(ast, addr);
-}
-
 AST::Ptr BoundCalcVisitor::visit(DataflowAPI::RoseAST *ast) {
-    BoundValue *astBound = boundFact.GetBound(ast);
+    StridedInterval *astBound = boundFact.GetBound(ast);
     if (astBound != NULL) {
-        bound.insert(make_pair(ast, new BoundValue(*astBound)));
+        bound.insert(make_pair(ast, new StridedInterval(*astBound)));
         return AST::Ptr();
     }
     unsigned totalChildren = ast->numChildren();
@@ -204,21 +34,17 @@ AST::Ptr BoundCalcVisitor::visit(DataflowAPI::RoseAST *ast) {
     switch (ast->val().op) {
         case ROSEOperation::addOp:
 	    if (IsResultBounded(ast->child(0)) && IsResultBounded(ast->child(1))) {	    
-		BoundValue* val = new BoundValue(*GetResultBound(ast->child(0)));		
+		StridedInterval* val = new StridedInterval(*GetResultBound(ast->child(0)));		
 		val->Add(*GetResultBound(ast->child(1)));
-		if (*val != BoundValue::top)
+		if (*val != StridedInterval::top)
 		    bound.insert(make_pair(ast, val));
 	    }	    
 	    break;
 	case ROSEOperation::invertOp:
 	    if (IsResultBounded(ast->child(0))) {
-	        BoundValue *val = new BoundValue(*GetResultBound(ast->child(0)));
-		if (val->tableReadSize)
-		    val->isInverted = true;
-		else {
-		    val->Invert();
-		}
-		if (*val != BoundValue::top)
+	        StridedInterval *val = new StridedInterval(*GetResultBound(ast->child(0)));
+		val->Not();
+		if (*val != StridedInterval::top)
 		    bound.insert(make_pair(ast,val));
 	    }
 	    break;
@@ -231,19 +57,19 @@ AST::Ptr BoundCalcVisitor::visit(DataflowAPI::RoseAST *ast) {
 	    // a cmp bound not found yet. So we only apply and
 	    // bound when this is the last attempt
 	    if (handleOneByteRead) {
-	        BoundValue *val = NULL;
+	        parsing_printf("\tTry to generate bound for AND\n");
+	        StridedInterval *val = NULL;
 		if (IsResultBounded(ast->child(0)))
-		    val = new BoundValue(*GetResultBound(ast->child(0)));
+		    val = new StridedInterval(*GetResultBound(ast->child(0)));
 		else
-		    val = new BoundValue(BoundValue::top);
+		    val = new StridedInterval(StridedInterval::top);
 		if (IsResultBounded(ast->child(1)))
 		    val->And(*GetResultBound(ast->child(1)));
 		else
 		    val->And(StridedInterval::top);
 		// the result of an AND operation should not be
 	        // the table lookup. Set all other values to default
-	        val->ClearTableCheck();
-	        if (*val != BoundValue::top)
+	        if (*val != StridedInterval::top)
 	            bound.insert(make_pair(ast, val));
 	    }
 	    break;
@@ -251,54 +77,49 @@ AST::Ptr BoundCalcVisitor::visit(DataflowAPI::RoseAST *ast) {
 	case ROSEOperation::sMultOp:
 	case ROSEOperation::uMultOp:
 	    if (IsResultBounded(ast->child(0)) && IsResultBounded(ast->child(1))) {
-	        BoundValue *val = new BoundValue(*GetResultBound(ast->child(0)));
+	        StridedInterval *val = new StridedInterval(*GetResultBound(ast->child(0)));
 	        val->Mul(*GetResultBound(ast->child(1)));
-	        if (*val != BoundValue::top)
+	        if (*val != StridedInterval::top)
 	            bound.insert(make_pair(ast, val));
 	    }
 	    break;
 	case ROSEOperation::shiftLOp:
 	    if (IsResultBounded(ast->child(0)) && IsResultBounded(ast->child(1))) {
-	        BoundValue *val = new BoundValue(*GetResultBound(ast->child(0)));
+	        StridedInterval *val = new StridedInterval(*GetResultBound(ast->child(0)));
 	        val->ShiftLeft(*GetResultBound(ast->child(1)));
-	        if (*val != BoundValue::top)
+	        if (*val != StridedInterval::top)
 	            bound.insert(make_pair(ast, val));
 	    }
 	    break;
 	case ROSEOperation::shiftROp:
 	    if (IsResultBounded(ast->child(0)) && IsResultBounded(ast->child(1))) {
-	        BoundValue *val = new BoundValue(*GetResultBound(ast->child(0)));
+	        StridedInterval *val = new StridedInterval(*GetResultBound(ast->child(0)));
 	        val->ShiftRight(*GetResultBound(ast->child(1)));
-	        if (*val != BoundValue::top)
+	        if (*val != StridedInterval::top)
 	            bound.insert(make_pair(ast, val));
 	    }
 	    break;
 	case ROSEOperation::derefOp: 
-	    if (IsResultBounded(ast->child(0))) {
-	        BoundValue *val = new BoundValue(*GetResultBound(ast->child(0)));
-		val->MemoryRead(block, derefSize);
-	        if (*val != BoundValue::top)
-	            bound.insert(make_pair(ast, val));
-	    } else if (handleOneByteRead && ast->val().size == 8) {
+	    if (handleOneByteRead && ast->val().size == 8) {
 	        // Any 8-bit value is bounded in [0,255]
 		// But I should only do this when I know the read 
 		// itself is not a jump table
-	        bound.insert(make_pair(ast, new BoundValue(StridedInterval(1,0,255))));
+	        bound.insert(make_pair(ast, new StridedInterval(1,0,255)));
 	    }
 	    break;
 	case ROSEOperation::orOp: 
 	    if (IsResultBounded(ast->child(0)) && IsResultBounded(ast->child(1))) {
-	        BoundValue *val = new BoundValue(*GetResultBound(ast->child(0)));
+	        StridedInterval *val = new StridedInterval(*GetResultBound(ast->child(0)));
 	        val->Or(*GetResultBound(ast->child(1)));
-	        if (*val != BoundValue::top)
+	        if (*val != StridedInterval::top)
 	            bound.insert(make_pair(ast, val));
 	    }
 	    break;
 	case ROSEOperation::ifOp:
 	    if (IsResultBounded(ast->child(1)) && IsResultBounded(ast->child(2))) {
-	        BoundValue *val = new BoundValue(*GetResultBound(ast->child(1)));
-		val->Join(*GetResultBound(ast->child(2)), block);
-		if (*val != BoundValue::top)
+	        StridedInterval *val = new StridedInterval(*GetResultBound(ast->child(1)));
+		val->Join(*GetResultBound(ast->child(2)));
+		if (*val != StridedInterval::top)
 		    bound.insert(make_pair(ast, val));
 	    }
 	default:
@@ -316,18 +137,19 @@ AST::Ptr BoundCalcVisitor::visit(DataflowAPI::ConstantAST *ast) {
 	// and change it to a negative number
         value = -(((~value) & ((1ULL << v.size) - 1)) + 1);
     }
-    bound.insert(make_pair(ast, new BoundValue(value)));
+    parsing_printf("\t\tGet a constant %ld\n", value);
+    bound.insert(make_pair(ast, new StridedInterval(value)));
     return AST::Ptr();
 }
 
 AST::Ptr BoundCalcVisitor::visit(DataflowAPI::VariableAST *ast) {
-    BoundValue *astBound = boundFact.GetBound(ast);
+    StridedInterval *astBound = boundFact.GetBound(ast);
     if (astBound != NULL) 
-        bound.insert(make_pair(ast, new BoundValue(*astBound)));
+        bound.insert(make_pair(ast, new StridedInterval(*astBound)));
     return AST::Ptr();
 }
 
-BoundValue* BoundCalcVisitor::GetResultBound(AST::Ptr ast) {
+StridedInterval* BoundCalcVisitor::GetResultBound(AST::Ptr ast) {
     if (IsResultBounded(ast)) {
 	return bound.find(ast.get())->second;
     } else {
@@ -404,210 +226,258 @@ AST::Ptr ComparisonVisitor::visit(DataflowAPI::RoseAST *ast) {
     return AST::Ptr();
 }
 
-AST::Ptr SubstituteAnAST(AST::Ptr ast, const BoundFact::AliasMap &aliasMap) {
-    for (auto ait = aliasMap.begin(); ait != aliasMap.end(); ++ait)
-        if (*ast == *(ait->first)) {
-	    return ait->second;
+JumpTableFormatVisitor::JumpTableFormatVisitor(ParseAPI::Block *bl) {
+    b = bl;
+    numOfVar = 0;
+    memoryReadLayer = 0; 
+    findIncorrectFormat = false;
+    findTableBase = false;
+    findIndex = false;
+    firstAdd = true;
+}
+
+AST::Ptr JumpTableFormatVisitor::visit(DataflowAPI::RoseAST *ast) {
+    if (ast->val().op == ROSEOperation::derefOp) {
+        memoryReadLayer++;
+	if (memoryReadLayer > 1) {
+	    parsing_printf("More than one layer of memory accesses, not jump table format\n");
+	    findIncorrectFormat = true;
+	    return AST::Ptr();
+	}
+	ast->child(0)->accept(this);
+	memoryReadLayer--;
+	return AST::Ptr();
+    }
+
+    if (ast->val().op == ROSEOperation::addOp && memoryReadLayer > 0 && firstAdd) {
+        firstAdd = false;
+        Address tableBase = 0;
+	if (ast->child(0)->getID() == AST::V_ConstantAST && PotentialIndexing(ast->child(1))) {
+	    ConstantAST::Ptr constAST = boost::static_pointer_cast<ConstantAST>(ast->child(0));
+	    tableBase = (Address)constAST->val().val;
+	}
+	if (ast->child(1)->getID() == AST::V_ConstantAST && PotentialIndexing(ast->child(0))) {
+	    ConstantAST::Ptr constAST = boost::static_pointer_cast<ConstantAST>(ast->child(1));
+	    tableBase = (Address)constAST->val().val;
 	}
+	if (tableBase) {
+	    Architecture arch = b->obj()->cs()->getArch();
+	    if (arch == Arch_x86) {
+	        tableBase &= 0xffffffff;
+	    }
+#if defined(os_windows)
+            tableBase -= b->obj()->cs()->loadAddress();
+#endif
+            if (!b->obj()->cs()->isValidAddress(tableBase)) {
+	        parsing_printf("\ttableBase 0x%lx invalid, not jump table format\n", tableBase);
+		findIncorrectFormat = true;
+		return AST::Ptr();
+	    }
+/*
+	    if (!b->obj()->cs()->isReadOnly(tableBase)) {
+	        parsing_printf("\ttableBase 0x%lx not read only, not jump table format\n", tableBase);
+		findIncorrectFormat = true;
+		return AST::Ptr();
+	    }
+*/	    
+	    findTableBase = true;
+       }
+    } 
+    
+    if ((ast->val().op == ROSEOperation::uMultOp || ast->val().op == ROSEOperation::sMultOp || ast->val().op == ROSEOperation::shiftLOp) && memoryReadLayer > 0) {
+	if (ast->child(0)->getID() == AST::V_ConstantAST && ast->child(1)->getID() == AST::V_VariableAST) {
+	    findIndex = true;
+	    numOfVar++;
+	    VariableAST::Ptr varAst = boost::static_pointer_cast<VariableAST>(ast->child(1));
+	    index = varAst->val().reg;
+	    return AST::Ptr();
+	}
+	if (ast->child(1)->getID() == AST::V_ConstantAST && ast->child(0)->getID() == AST::V_VariableAST) {
+	    findIndex = true;
+	    numOfVar++;
+	    VariableAST::Ptr varAst = boost::static_pointer_cast<VariableAST>(ast->child(0));
+	    index = varAst->val().reg;
+	    return AST::Ptr();
+	}
+    }
+
     unsigned totalChildren = ast->numChildren();
     for (unsigned i = 0 ; i < totalChildren; ++i) {
-        ast->setChild(i, SubstituteAnAST(ast->child(i), aliasMap));
-    }
-    if (ast->getID() == AST::V_VariableAST) {
-        // If this variable is not in the aliasMap yet,
-	// this variable is from the input.
-        VariableAST::Ptr varAST = boost::static_pointer_cast<VariableAST>(ast);
-	return VariableAST::create(Variable(varAST->val().reg, 1));
+        ast->child(i)->accept(this);
     }
-    return ast;
 
+    return AST::Ptr();
 }
 
-bool ContainAnAST(AST::Ptr root, AST::Ptr check) {
-    if (*root == *check) return true;
-    bool ret = false;
-    unsigned totalChildren = root->numChildren();
-    for (unsigned i = 0 ; i < totalChildren && !ret; ++i) {
-        ret |= ContainAnAST(root->child(i), check);
-    }
-    return ret;
+AST::Ptr JumpTableFormatVisitor::visit(DataflowAPI::VariableAST *) {
+    numOfVar++;
+    return AST::Ptr();
 }
 
-
-AST::Ptr DeepCopyAnAST(AST::Ptr ast) {
+bool JumpTableFormatVisitor::PotentialIndexing(AST::Ptr ast) {
+    if (ast->getID() == AST::V_VariableAST) return true;
     if (ast->getID() == AST::V_RoseAST) {
-        RoseAST::Ptr roseAST = boost::static_pointer_cast<RoseAST>(ast);
-	AST::Children kids;
-        unsigned totalChildren = ast->numChildren();
-	for (unsigned i = 0 ; i < totalChildren; ++i) {
-	    kids.push_back(DeepCopyAnAST(ast->child(i)));
+        RoseAST::Ptr r = boost::static_pointer_cast<RoseAST>(ast);
+	if (r->val().op == ROSEOperation::uMultOp || r->val().op == ROSEOperation::sMultOp || r->val().op == ROSEOperation::shiftLOp) {
+	    if (r->child(0)->getID() == AST::V_RoseAST) {
+	        return false;
+	    }
+	    return true;
+	}
+	if (r->val().op == ROSEOperation::addOp) {
+	    // The index can be subtracted 
+	    if (r->child(0)->getID() == AST::V_RoseAST && r->child(1)->getID() == AST::V_ConstantAST) {
+	        RoseAST::Ptr lc = boost::static_pointer_cast<RoseAST>(r->child(0));
+		ConstantAST::Ptr rc = boost::static_pointer_cast<ConstantAST>(r->child(1));
+		if (lc->val().op == ROSEOperation::invertOp && rc->val().val == 1) {
+		    return PotentialIndexing(lc->child(0));
+		}
+	    }
 	}
-	return RoseAST::create(ROSEOperation(roseAST->val()), kids);
-    } else if (ast->getID() == AST::V_VariableAST) {
-        VariableAST::Ptr varAST = boost::static_pointer_cast<VariableAST>(ast);
-	return VariableAST::create(Variable(varAST->val()));
-    } else if (ast->getID() == AST::V_ConstantAST) {
-        ConstantAST::Ptr constAST = boost::static_pointer_cast<ConstantAST>(ast);
-	return ConstantAST::create(Constant(constAST->val()));
-    } else if (ast->getID() == AST::V_BottomAST) {
-        BottomAST::Ptr bottomAST = boost::static_pointer_cast<BottomAST>(ast);
-	return BottomAST::create(bottomAST->val());
     }
-    fprintf(stderr, "ast type %d, %s\n", ast->getID(), ast->format().c_str());
-    assert(0);
-	return AST::Ptr();
+    return false;
 }
 
-AST::Ptr JumpTableFormatVisitor::visit(DataflowAPI::RoseAST *ast) {
+JumpTableReadVisitor::JumpTableReadVisitor(AbsRegion i, int v, CodeSource *c, bool ze, int m) {
+    index = i;
+    indexValue = v;
+    cs = c;
+    isZeroExtend = ze;
+    valid = true;
+    memoryReadSize = m;
+}
 
-    bool findIncorrectFormat = false;
-    if (ast->val().op == ROSEOperation::derefOp) {
-        // We only check the first memory read
-	if (ast->child(0)->getID() == AST::V_RoseAST) {
-	    RoseAST::Ptr roseAST = boost::static_pointer_cast<RoseAST>(ast->child(0));
-	    if (roseAST->val().op == ROSEOperation::derefOp) {
-	        // Two directly nested memory accesses cannot be jump tables
-		parsing_printf("Two directly nested memory access, not jump table format\n");
-	        findIncorrectFormat = true;
-	    } else if (roseAST->val().op == ROSEOperation::addOp) {
-	        Address tableBase = 0;
-		if (roseAST->child(0)->getID() == AST::V_ConstantAST && roseAST->child(1)->getID() == AST::V_VariableAST) {
-		    ConstantAST::Ptr constAST = boost::static_pointer_cast<ConstantAST>(roseAST->child(0));
-		    tableBase = (Address)constAST->val().val;
-		}
-		if (roseAST->child(1)->getID() == AST::V_ConstantAST && roseAST->child(0)->getID() == AST::V_VariableAST) {
-		    ConstantAST::Ptr constAST = boost::static_pointer_cast<ConstantAST>(roseAST->child(1));
-		    tableBase = (Address)constAST->val().val;
+AST::Ptr JumpTableReadVisitor::visit(DataflowAPI::RoseAST *ast) {
+    unsigned totalChildren = ast->numChildren();
+    for (unsigned i = 0 ; i < totalChildren; ++i) {
+        ast->child(i)->accept(this);
+	if (!valid) return AST::Ptr();
+    }
+
+    // As soon as we do not know the value of one child, we will return.
+    // So, we will always have good values for each child at this point.
+    switch (ast->val().op) {
+        case ROSEOperation::addOp:
+	    results.insert(make_pair(ast, results[ast->child(0).get()] + results[ast->child(1).get()]));
+	    break;
+	case ROSEOperation::invertOp:
+	    results.insert(make_pair(ast, ~results[ast->child(0).get()]));
+	    break;
+	case ROSEOperation::andOp: 
+	    results.insert(make_pair(ast, results[ast->child(0).get()] & results[ast->child(1).get()]));
+	    break;
+	case ROSEOperation::sMultOp:
+	case ROSEOperation::uMultOp:
+	    results.insert(make_pair(ast, results[ast->child(0).get()] * results[ast->child(1).get()]));
+	    break;
+	case ROSEOperation::shiftLOp:
+	    results.insert(make_pair(ast, results[ast->child(0).get()] << results[ast->child(1).get()]));
+	    break;
+	case ROSEOperation::shiftROp:
+	    results.insert(make_pair(ast, results[ast->child(0).get()] >> results[ast->child(1).get()]));
+	    break;
+	case ROSEOperation::derefOp: {
+	        int64_t v;
+	        bool validRead = PerformMemoryRead(results[ast->child(0).get()], v);
+		if (!validRead) {
+		    valid = false;
+		    // We encounter an invalid table entry
+		    parsing_printf("WARNING: invalid table entry for index value %ld\n", indexValue);
+		    return AST::Ptr();
 		}
-		if (tableBase) {
-		    Architecture arch = b->obj()->cs()->getArch();
-		    if (arch == Arch_x86) {
-		        tableBase &= 0xffffffff;
-		    }
+		results.insert(make_pair(ast, v));
+	    }
+	    break;
+	case ROSEOperation::orOp: 
+	    results.insert(make_pair(ast, results[ast->child(0).get()] | results[ast->child(1).get()]));
+	    break;
+	default:
+	    parsing_printf("WARNING: unhandled operation in the jump table format AST!\n");
+	    valid = false;
+	    break;
+    }
+    targetAddress = results[ast];
+    if (cs->getAddressWidth() == 4) {
+        targetAddress &= 0xffffffff;
+    }
 #if defined(os_windows)
-                    tableBase -= b->obj()->cs()->loadAddress();
+    targetAddress -= cs->loadAddress();
 #endif
-                    if (!b->obj()->cs()->isValidAddress(tableBase)) {
-		        parsing_printf("\ttableBase 0x%lx invalid, not jump table format\n", tableBase);
-			findIncorrectFormat = true;
-		    }
-                    if (!b->obj()->cs()->isReadOnly(tableBase)) {
-		        parsing_printf("\ttableBase 0x%lx not read only, not jump table format\n", tableBase);
-			findIncorrectFormat = true;
-		    }
 
-		}
-	    }
-	}
-	if (findIncorrectFormat) {
-	    format = false;
-	}
-	return AST::Ptr();
+    return AST::Ptr();
+   
+}
+
+AST::Ptr JumpTableReadVisitor::visit(DataflowAPI::ConstantAST *ast) {
+    const Constant &v = ast->val();
+    int64_t value = v.val;
+    if (v.size != 1 && v.size != 64 && (value & (1ULL << (v.size - 1)))) {
+        // Compute the two complements in bits of v.size
+	// and change it to a negative number
+        value = -(((~value) & ((1ULL << v.size) - 1)) + 1);
     }
-    if (!findIncorrectFormat) {
-        unsigned totalChildren = ast->numChildren();
-	for (unsigned i = 0 ; i < totalChildren; ++i) {
-	    ast->child(i)->accept(this);
-	}
-    } 
+    results.insert(make_pair(ast, value));
     return AST::Ptr();
 }
 
-bool PerformTableRead(BoundValue &target, set<int64_t> & jumpTargets, CodeSource *cs) {
-    if (target.tableReadSize > 0 && target.interval.stride == 0) {
-        // This is a PC-relative read to variable, not a table read
-        return false;
+
+AST::Ptr JumpTableReadVisitor::visit(DataflowAPI::VariableAST * var) {
+    if (var->val().reg != index) {
+        // The only variable in the jump table format AST should the index.
+	// If it is not the case, something is wrong
+	parsing_printf("WARNING: the jump table format AST contains a variable that is not the index\n");
+        valid = false;
     }
-    Address tableBase = (Address)target.interval.low;
-    Address tableLastEntry = (Address)target.interval.high;
+    results.insert(make_pair(var, indexValue));
+    return AST::Ptr();
+}
+
+
+bool JumpTableReadVisitor::PerformMemoryRead(Address addr, int64_t &v) {
     int addressWidth = cs->getAddressWidth();
     if (addressWidth == 4) {
-        tableBase &= 0xffffffff;
-	tableLastEntry &= 0xffffffff;
+        addr &= 0xffffffff;
     }
 
 #if defined(os_windows)
-    tableBase -= cs->loadAddress();
-    tableLastEntry -= cs->loadAddress();
+    addr -= cs->loadAddress();
 #endif
-
-    if (!cs->isCode(tableBase) && !cs->isData(tableBase)) {
-        parsing_printf("\ttableBase 0x%lx invalid, returning false\n", tableBase);
-	parsing_printf("Not jump table format!\n");
-	return false;
-    }
-    if (!cs->isReadOnly(tableBase)) {
-        parsing_printf("\ttableBase 0x%lx not read only, returning false\n", tableBase);
-	parsing_printf("Not jump table format!\n");
-        return false;
-    }
-
-
-    for (Address tableEntry = tableBase; tableEntry <= tableLastEntry; tableEntry += target.interval.stride) {
-	if (!cs->isCode(tableEntry) && !cs->isData(tableEntry)) continue;
-	if (!cs->isReadOnly(tableEntry)) continue;
-	int64_t targetAddress = 0;
-	if (target.tableReadSize > 0) {
-	    switch (target.tableReadSize) {
-	        case 8:
-		    targetAddress = *(const uint64_t *) cs->getPtrToInstruction(tableEntry);
-		    break;
-		case 4:
-		    targetAddress = *(const uint32_t *) cs->getPtrToInstruction(tableEntry);
-		    if (target.isZeroExtend) break;
-		    if ((addressWidth == 8) && (targetAddress & 0x80000000)) {
-		        targetAddress |= SIGNEX_64_32;
-		    }
-		    break;
-		case 2:
-		    targetAddress = *(const uint16_t *) cs->getPtrToInstruction(tableEntry);
-		    if (target.isZeroExtend) break;
-		    if ((addressWidth == 8) && (targetAddress & 0x8000)) {
-		        targetAddress |= SIGNEX_64_16;
-		    }
-		    if ((addressWidth == 4) && (targetAddress & 0x8000)) {
-		        targetAddress |= SIGNEX_32_16;
-		    }
-
-		    break;
-		case 1:
-		    targetAddress = *(const uint8_t *) cs->getPtrToInstruction(tableEntry);
-		    if (target.isZeroExtend) break;
-		    if ((addressWidth == 8) && (targetAddress & 0x80)) {
-		        targetAddress |= SIGNEX_64_8;
-		    }
-		    if ((addressWidth == 4) && (targetAddress & 0x80)) {
-		        targetAddress |= SIGNEX_32_8;
-		    }
-
-		    break;
-
-		default:
-		    parsing_printf("Invalid memory read size %d\n", target.tableReadSize);
-		    return false;
+    if (!cs->isCode(addr) && !cs->isData(addr)) return false;
+//    if (!cs->isReadOnly(addr)) return false;
+    switch (memoryReadSize) {
+        case 8:
+	    v = *(const uint64_t *) cs->getPtrToInstruction(addr);
+	    break;
+	case 4:
+	    v = *(const uint32_t *) cs->getPtrToInstruction(addr);
+	    if (isZeroExtend) break;
+	    if ((addressWidth == 8) && (v & 0x80000000)) {
+	        v |= SIGNEX_64_32;
 	    }
-	    targetAddress *= target.multiply;
-	    if (target.targetBase != 0) {
-	        if (target.isSubReadContent) 
-		    targetAddress = target.targetBase - targetAddress;
-		else 
-		    targetAddress += target.targetBase; 
-
+	    break;
+	case 2:
+	    v = *(const uint16_t *) cs->getPtrToInstruction(addr);
+	    if (isZeroExtend) break;
+	    if ((addressWidth == 8) && (v & 0x8000)) {
+	        v |= SIGNEX_64_16;
 	    }
-#if defined(os_windows)
-            targetAddress -= cs->loadAddress();
-#endif
-	} else targetAddress = tableEntry;
-
-	if (addressWidth == 4) targetAddress &= 0xffffffff;
-	parsing_printf("Jumping to target %lx,", targetAddress);
-	if (cs->isCode(targetAddress)) {
-	    // Jump tables may contain may repetitious entries.
-	    // We only want to create one edge for disctinct each jump target.
-	    jumpTargets.insert(targetAddress);
-	}
-	// If the jump target is resolved to be a constant, 
-	if (target.interval.stride == 0) break;
+	    if ((addressWidth == 4) && (v & 0x8000)) {
+	        v |= SIGNEX_32_16;
+	    }
+	    break;
+	case 1:
+	    v = *(const uint8_t *) cs->getPtrToInstruction(addr);
+	    if (isZeroExtend) break;
+	    if ((addressWidth == 8) && (v & 0x80)) {
+	        v |= SIGNEX_64_8;
+	    }
+	    if ((addressWidth == 4) && (v & 0x80)) {
+	        v |= SIGNEX_32_8;
+	    }
+	    break;	    
+	default:
+	    parsing_printf("Invalid memory read size %d\n", memoryReadSize);
+	    return false;
     }
     return true;
 }
diff --git a/parseAPI/src/IndirectASTVisitor.h b/parseAPI/src/IndirectASTVisitor.h
index d07a209..81439ec 100644
--- a/parseAPI/src/IndirectASTVisitor.h
+++ b/parseAPI/src/IndirectASTVisitor.h
@@ -12,19 +12,9 @@ using namespace std;
 using namespace Dyninst;
 using namespace Dyninst::DataflowAPI;
 
-AST::Ptr SimplifyRoot(AST::Ptr ast, Address addr);
-AST::Ptr SimplifyAnAST(AST::Ptr ast, Address addr);
-AST::Ptr SubstituteAnAST(AST::Ptr ast, const BoundFact::AliasMap &aliasMap);
-AST::Ptr DeepCopyAnAST(AST::Ptr ast);
-bool ContainAnAST(AST::Ptr root, AST::Ptr check);
-bool PerformTableRead(BoundValue &target, set<int64_t> & jumpTargets, CodeSource*);
+//bool PerformTableRead(StridedInterval &target, set<int64_t> & jumpTargets, CodeSource*);
 
 
-// On x86 and x86-64, the value of PC is post-instruction, 
-// which is the current address plus the length of the instruction.
-// On ARMv8, the value of PC is pre-instruction,
-// which is the current address
-Address PCValue(Address cur, size_t insnSize, Architecture a);
 
 class SimplifyVisitor: public ASTVisitor {
     Address addr;
@@ -35,12 +25,11 @@ public:
 };
 
 
-
 class BoundCalcVisitor: public ASTVisitor {
      
 public:
     using ASTVisitor::visit;
-    map<AST*, BoundValue*> bound;
+    map<AST*, StridedInterval*> bound;
     BoundFact &boundFact;
     ParseAPI::Block *block;
     bool handleOneByteRead;
@@ -55,7 +44,7 @@ public:
     bool IsResultBounded(AST::Ptr ast) {
         return bound.find(ast.get()) != bound.end();
     }
-    BoundValue* GetResultBound(AST::Ptr ast); 
+    StridedInterval* GetResultBound(AST::Ptr ast); 
 };
 
 class JumpCondVisitor: public ASTVisitor {
@@ -79,11 +68,40 @@ public:
 
 class JumpTableFormatVisitor: public ASTVisitor {
 
+    bool PotentialIndexing(AST::Ptr);
 public:
     using ASTVisitor::visit;
+    AbsRegion index;
+    int numOfVar;
+    int memoryReadLayer;
     ParseAPI::Block *b;
-    bool format;
+    bool findIncorrectFormat;
+    bool findTableBase;    
+    bool findIndex;
+    bool firstAdd;
     virtual ASTPtr visit(DataflowAPI::RoseAST *ast);
-    JumpTableFormatVisitor(ParseAPI::Block *bl): b(bl), format(true) {}
+    virtual ASTPtr visit(DataflowAPI::VariableAST *ast);
+    JumpTableFormatVisitor(ParseAPI::Block *bl);
+};
+
+class JumpTableReadVisitor: public ASTVisitor {
+public:
+    using ASTVisitor::visit;
+    AbsRegion index;
+    int64_t indexValue;
+    CodeSource* cs;
+    Address targetAddress;
+    int memoryReadSize;
+    bool valid;
+    bool isZeroExtend;
+
+
+    // This tracks the results of computation for each sub AST
+    map<AST*, int64_t> results;
+    JumpTableReadVisitor(AbsRegion i, int v, CodeSource *c, bool ze, int m);
+    virtual ASTPtr visit(DataflowAPI::RoseAST *ast);
+    virtual ASTPtr visit(DataflowAPI::ConstantAST *ast);
+    virtual ASTPtr visit(DataflowAPI::VariableAST *ast);
+    bool PerformMemoryRead(Address addr, int64_t &v);
 };
 #endif
diff --git a/parseAPI/src/IndirectAnalyzer.C b/parseAPI/src/IndirectAnalyzer.C
index 501a047..139d6f4 100644
--- a/parseAPI/src/IndirectAnalyzer.C
+++ b/parseAPI/src/IndirectAnalyzer.C
@@ -1,7 +1,10 @@
 #include "dyntypes.h"
 #include "IndirectAnalyzer.h"
 #include "BoundFactCalculator.h"
-#include "JumpTablePred.h"
+#include "JumpTableFormatPred.h"
+#include "JumpTableIndexPred.h"
+#include "SymbolicExpression.h"
+#include "IndirectASTVisitor.h"
 #include "IA_IAPI.h"
 #include "debug_parse.h"
 
@@ -15,11 +18,49 @@
 using namespace Dyninst::ParseAPI;
 using namespace Dyninst::InstructionAPI;
 
+static bool IsIndexing(AST::Ptr node, AbsRegion &index) {
+    RoseAST::Ptr n = boost::static_pointer_cast<RoseAST>(node);
+    if (n->val().op != ROSEOperation::sMultOp &&
+        n->val().op != ROSEOperation::uMultOp &&
+	n->val().op != ROSEOperation::shiftLOp) return false;
+    if (n->child(0)->getID() != AST::V_VariableAST) return false;
+    if (n->child(1)->getID() != AST::V_ConstantAST) return false;
+    VariableAST::Ptr var = boost::static_pointer_cast<VariableAST>(n->child(0));
+    index = var->val().reg;
+    return true;
+}
+
+static bool IsVariableArgumentFormat(AST::Ptr t, AbsRegion &index) {
+    if (t->getID() != AST::V_RoseAST) {
+        return false;
+    }
+    RoseAST::Ptr rt = boost::static_pointer_cast<RoseAST>(t);
+    if (rt->val().op != ROSEOperation::addOp) {
+        return false;
+    }
+    if (rt->child(0)->getID() != AST::V_ConstantAST || rt->child(1)->getID() != AST::V_RoseAST) {
+        return false;
+    }
+    RoseAST::Ptr c1 = boost::static_pointer_cast<RoseAST>(rt->child(1));
+    if (c1->val().op == ROSEOperation::addOp) {
+        if (c1->child(0)->getID() == AST::V_RoseAST && c1->child(1)->getID() == AST::V_ConstantAST) {
+	    RoseAST::Ptr lc = boost::static_pointer_cast<RoseAST>(c1->child(0));
+	    ConstantAST::Ptr rc = boost::static_pointer_cast<ConstantAST>(c1->child(1));
+	    if (lc->val().op == ROSEOperation::invertOp && rc->val().val == 1) {
+	        return IsIndexing(lc->child(0), index);
+	    }
+	}
+	return false;
+    }
+    return IsIndexing(rt->child(1), index);
+
+}
 
 bool IndirectControlFlowAnalyzer::NewJumpTableAnalysis(std::vector<std::pair< Address, Dyninst::ParseAPI::EdgeTypeEnum > >& outEdges) {
-//    if (block->last() == 0x3ed4f33e9e) dyn_debug_parsing=1; else dyn_debug_parsing=0;
     parsing_printf("Apply indirect control flow analysis at %lx\n", block->last());
     parsing_printf("Looking for thunk\n");
+    
+//    if (block->last() == 0xa8d7c9) dyn_debug_parsing=1; else dyn_debug_parsing=0;
 
 //  Find all blocks that reach the block containing the indirect jump
 //  This is a prerequisit for finding thunks
@@ -30,35 +71,73 @@ bool IndirectControlFlowAnalyzer::NewJumpTableAnalysis(std::vector<std::pair< Ad
 //  Calculates all blocks that can reach
 //  and be reachable from thunk blocks
     ReachFact rf(thunks);
- 
+
+    // Now we start with the indirect jump instruction,
+    // to determine the format of the (potential) jump table
     const unsigned char * buf = (const unsigned char*) block->obj()->cs()->getPtrToInstruction(block->last());
     InstructionDecoder dec(buf, InstructionDecoder::maxInstructionLength, block->obj()->cs()->getArch());
     Instruction::Ptr insn = dec.decode();
     AssignmentConverter ac(true, false);
     vector<Assignment::Ptr> assignments;
     ac.convert(insn, block->last(), func, block, assignments);
-    Slicer s(assignments[0], block, func, false, false);
+    Slicer formatSlicer(assignments[0], block, func, false, false);
 
-    std::vector<std::pair< Address, Dyninst::ParseAPI::EdgeTypeEnum > > jumpTableOutEdges;
+    SymbolicExpression se;
+    JumpTableFormatPred jtfp(func, block, rf, thunks, se);
+    GraphPtr slice = formatSlicer.backwardSlice(jtfp);
+    //parsing_printf("\tJump table format: %s\n", jtfp.format().c_str());
+    // If the jump target expression is not in a form we recognize,
+    // we do not try to resolve it
+    parsing_printf("In function %s, Address %lx, jump target format %s, index loc %s, index variable %s", func->name().c_str(), block->last(), jtfp.format().c_str(), jtfp.indexLoc ? jtfp.indexLoc->format().c_str() : "" , jtfp.index.format().c_str() );
 
-    JumpTablePred jtp(func, block, rf, thunks, jumpTableOutEdges);
-    jtp.setSearchForControlFlowDep(true);
-    GraphPtr slice = s.backwardSlice(jtp);
-    // After the slicing is done, we do one last check to 
-    // see if we can resolve the indirect jump by assuming 
-    // one byte read is in bound [0,255]
-    if (jumpTableOutEdges.empty() && jtp.jumpTableFormat && block->obj()->cs()->getArch() != Arch_aarch64) {
-        GraphPtr g = jtp.BuildAnalysisGraph(s.visitedEdges);
-	
-	BoundFactsCalculator bfc(func, g, func->entry() == block, rf, thunks, true, jtp.expandCache);
-	bfc.CalculateBoundedFacts();
-	
-	BoundValue target;
-	bool ijt = jtp.IsJumpTable(g, bfc, target);
-	if (ijt) jtp.FillInOutEdges(target, jumpTableOutEdges);
+    bool variableArguFormat = false;
+    if (!jtfp.isJumpTableFormat()) {
+        parsing_printf(" not jump table\n");
+	if (jtfp.jumpTargetExpr && func->entry() == block && IsVariableArgumentFormat(jtfp.jumpTargetExpr, jtfp.index)) {
+	    parsing_printf("\tVariable number of arguments format, index %s\n", jtfp.index.format().c_str());
+	    variableArguFormat = true;
+	} else {
+            return false;
+	}
     }
-   // fprintf(stderr, "indirect jump at %lx with %d assignments and %d edges\n", block->last(), jtp.currentAssigns.size(), jumpTableOutEdges.size()); 
 
+    StridedInterval b;
+    if (!variableArguFormat) {
+        Slicer indexSlicer(jtfp.indexLoc, jtfp.indexLoc->block(), func, false, false); 
+	JumpTableIndexPred jtip(func, block, jtfp.index, se);
+	jtip.setSearchForControlFlowDep(true);
+	slice = indexSlicer.backwardSlice(jtip);
+    
+        if (!jtip.findBound && block->obj()->cs()->getArch() != Arch_aarch64) {
+
+            // After the slicing is done, we do one last check to 
+            // see if we can resolve the indirect jump by assuming 
+            // one byte read is in bound [0,255]
+            GraphPtr g = jtip.BuildAnalysisGraph(indexSlicer.visitedEdges);
+	    BoundFactsCalculator bfc(func, g, func->entry() == block,  true, se);
+	    bfc.CalculateBoundedFacts();
+	
+	    StridedInterval target;
+	    jtip.IsIndexBounded(g, bfc, target);
+        }
+        if (jtip.findBound) {
+            parsing_printf(" bound %s", jtip.bound.format().c_str());
+	    b = jtip.bound;
+        } else {
+            parsing_printf(" Cannot find bound, assume there are at most 256 entries and scan the table\n");
+	    b = StridedInterval(1, 0, 255);
+        }
+    } else {
+        b = StridedInterval(1, 0, 8);
+    }
+    std::vector<std::pair< Address, Dyninst::ParseAPI::EdgeTypeEnum > > jumpTableOutEdges;
+    ReadTable(jtfp.jumpTargetExpr, 
+              jtfp.index, 
+	      b, 
+	      GetMemoryReadSize(jtfp.memLoc), 
+	      jtfp.constAddr,
+	      jumpTableOutEdges);
+    parsing_printf(", find %d edges\n", jumpTableOutEdges.size());	      
     outEdges.insert(outEdges.end(), jumpTableOutEdges.begin(), jumpTableOutEdges.end());
     return !jumpTableOutEdges.empty();
 }						       
@@ -149,4 +228,72 @@ void IndirectControlFlowAnalyzer::FindAllThunks() {
     }
 }
 
+void IndirectControlFlowAnalyzer::ReadTable(AST::Ptr jumpTargetExpr, 
+                                            AbsRegion index,
+					    StridedInterval &indexBound,   
+					    int memoryReadSize,
+					    set<Address> &constAddr,
+					    std::vector<std::pair<Address, Dyninst::ParseAPI::EdgeTypeEnum> > &targetEdges) {
+    CodeSource *cs = block->obj()->cs();					    
+    set<Address> jumpTargets;
+    for (int v = indexBound.low; v <= indexBound.high; v += indexBound.stride) {
+        // TODO: need to detect whether the memory is a zero extend or a sign extend
+        JumpTableReadVisitor jtrv(index, v, cs, false, memoryReadSize);
+	jumpTargetExpr->accept(&jtrv);
+	if (jtrv.valid && cs->isCode(jtrv.targetAddress)) {
+	    bool overlap = false;
+	    set<Block*> blocks;
+	    block->obj()->findCurrentBlocks(block->region(), jtrv.targetAddress, blocks);
+	    for (auto bit = blocks.begin(); bit != blocks.end(); ++bit) {
+	        if ((*bit)->start() < jtrv.targetAddress && jtrv.targetAddress <= (*bit)->end()) {
+		    Block::Insns insns;
+		    (*bit)->getInsns(insns);
+		    if (insns.find(jtrv.targetAddress) == insns.end()) {
+		        overlap = true;
+			parsing_printf("WARNING: resolving jump tables leads to address %lx, which causes overlapping instructions in basic blocks [%lx,%lx)\n", jtrv.targetAddress, (*bit)->start(), (*bit)->end());
+			break;
+		    }
+		}
+	    }
+	    set<Function*> funcs;
+	    block->obj()->findCurrentFuncs(block->region(), jtrv.targetAddress, funcs);
+	    for (auto fit = funcs.begin(); fit != funcs.end(); ++fit) {
+	        if (*fit != func) {
+		    overlap = true;
+		    parsing_printf("WARNING: resolving jump tables leads to address %lx in another function at %lx\n", jtrv.targetAddress, (*fit)->addr());
+		}
+	    }
+	    if (overlap) break;
+	    jumpTargets.insert(jtrv.targetAddress);
+	} else {
+	    // We have a bad entry. We stop here, as we have wrong information
+	    // In this case, we keep the good entries
+	    parsing_printf("WARNING: resolving jump tables leads to a bad address %lx\n", jtrv.targetAddress);
+	    break;
+	}
+	if (indexBound.stride == 0) break;
+    }
+    for (auto ait = constAddr.begin(); ait != constAddr.end(); ++ait) {
+        if (cs->isCode(*ait)) {
+	    jumpTargets.insert(*ait);
+	}
+    }
+    for (auto tit = jumpTargets.begin(); tit != jumpTargets.end(); ++tit) {
+        targetEdges.push_back(make_pair(*tit, INDIRECT));
+    }
+}					    
 
+int IndirectControlFlowAnalyzer::GetMemoryReadSize(Assignment::Ptr memLoc) {
+    if (!memLoc) return 0;
+    Instruction::Ptr i = memLoc->insn();
+    std::vector<Operand> ops;
+    i->getOperands(ops);
+    for (auto oit = ops.begin(); oit != ops.end(); ++oit) {
+        Operand o = *oit;
+	if (o.readsMemory()) {
+	    Expression::Ptr exp = o.getValue();
+	    return exp->size();
+	}
+    }
+    return 0;
+}
diff --git a/parseAPI/src/IndirectAnalyzer.h b/parseAPI/src/IndirectAnalyzer.h
index af5e4b9..d2a6c7f 100644
--- a/parseAPI/src/IndirectAnalyzer.h
+++ b/parseAPI/src/IndirectAnalyzer.h
@@ -17,11 +17,13 @@ class IndirectControlFlowAnalyzer {
 
     void GetAllReachableBlock();  
     void FindAllThunks();
-    bool IsJumpTable(GraphPtr slice, BoundFactsCalculator &bfc, BoundValue &target);
-    bool FillInOutEdges(BoundValue &target, std::vector<std::pair< Address, Dyninst::ParseAPI::EdgeTypeEnum > >& outEdges);
-    GraphPtr CalcBackwardSlice(ParseAPI::Block *b, 
-                               Address addr,
-			       string filename);
+    void ReadTable(AST::Ptr, 
+                   AbsRegion, 
+		   StridedInterval &,  
+		   int ,
+		   std::set<Address> &, 
+		   std::vector<std::pair<Address, Dyninst::ParseAPI::EdgeTypeEnum> > &);
+    int GetMemoryReadSize(Assignment::Ptr loc);
 
 
 public:
diff --git a/parseAPI/src/JumpTableFormatPred.C b/parseAPI/src/JumpTableFormatPred.C
new file mode 100644
index 0000000..608d91b
--- /dev/null
+++ b/parseAPI/src/JumpTableFormatPred.C
@@ -0,0 +1,391 @@
+#include "JumpTableFormatPred.h"
+#include "SymbolicExpression.h"
+#include "IndirectASTVisitor.h"
+#include "SymEval.h"
+#include "debug_parse.h"
+using namespace Dyninst;
+using namespace Dyninst::DataflowAPI;
+using namespace Dyninst::ParseAPI;
+using namespace Dyninst::InstructionAPI;
+
+static int CountInDegree(SliceNode::Ptr n) {
+    NodeIterator nbegin, nend; 
+    int count = 0;
+    n->ins(nbegin, nend);
+    for (; nbegin != nend; ++count, ++nbegin);
+    return count;
+}
+
+bool JumpTableFormatPred::modifyCurrentFrame(Slicer::SliceFrame &frame, Graph::Ptr g, Slicer* s) {
+    if (!jumpTableFormat) return false;
+    if (unknownInstruction) return false;
+
+    /* We start to inspect the current slice graph.
+     * 1. If we have determined the jump table format, we can stop this slice.
+     * 2. If we have determined the index variable, we can remove the variable 
+     *    from the current slice and only keep slicing on other variables.
+     * 3. If we have determined that this is not a known jump table, 
+     *    we also stop slicing.
+     */
+
+    queue<SliceNode::Ptr> working_list;
+    unordered_set<Assignment::Ptr, Assignment::AssignmentPtrHasher> inQueue;
+    NodeIterator nbegin, nend; 
+
+    g->adjustEntryAndExitNodes();
+    // We do not try to slice on the heap absregion,
+    // as it will not help us determine the jump table format.
+    // But we record this memory read, so that later we can determine
+    // whether the size of the read and whether it is zero extended or sign extended
+    for (auto rit = frame.active.begin(); rit != frame.active.end(); ++rit)
+        if (rit->first.type() == Absloc::Heap || rit->first.type() == Absloc::Stack) {
+	    // If this is the first memory read we encoutered,
+	    // this is likely to be a jump table read and we need to keep
+	    // slice on its address.
+	    if (firstMemoryRead) {
+	        memLoc = rit->second[0].ptr;
+		firstMemoryRead = false;
+		frame.active.erase(rit);
+	    } else {
+	        // For a later memory read, if we have not disqualified this indirect jump,
+		// it is likely to be a jump table. This memory read is assumed 
+		// and likely to be a spill for a certain register. We syntactically find the location
+		// where the memory is written and keep slicing on the source register
+		SliceNode::Ptr readNode;
+		parsing_printf("\t\tfind another memory read %s %s\n", rit->first.format().c_str(), rit->second[0].ptr->format().c_str());
+		if (!findSpillRead(g, readNode)) {
+		    parsing_printf("\tWARNING: a potential memory spill cannot be handled.\n");
+		    jumpTableFormat = false;
+		    return false;
+		}
+		// We then do the following things
+		// 1. delete all absregions introduced by this read node from the active map
+		// 2. search for the closest instruction that writes the same memory location,
+		//    through memoery operand ast matching
+		// 3. change the slicing location and add back the source
+		if (!adjustSliceFrame(frame, readNode, s)) {
+		    parsing_printf("Cannot track through the memory read\n");
+		    jumpTableFormat = false;
+		    return false;
+		}
+		g->deleteNode(readNode);
+		return true;
+
+	    }
+	    break;
+	}
+
+
+    g->entryNodes(nbegin, nend);
+
+    // This map trakcs the expanded and substituted ASTs for each assignment in the current slice
+    std::unordered_map<Assignment::Ptr, AST::Ptr, Assignment::AssignmentPtrHasher> exprs;
+    std::unordered_map<Assignment::Ptr, int, Assignment::AssignmentPtrHasher> inDegree;
+    for (; nbegin != nend; ++nbegin) {
+        SliceNode::Ptr n = boost::static_pointer_cast<SliceNode>(*nbegin);
+	working_list.push(n);
+	inQueue.insert(n->assign());
+    }
+    
+    g->allNodes(nbegin, nend);
+    for (; nbegin != nend; ++nbegin) {
+        SliceNode::Ptr n = boost::static_pointer_cast<SliceNode>(*nbegin);
+	inDegree[n->assign()] = CountInDegree(n);
+    }
+    AST::Ptr jumpTarget;
+    while (!working_list.empty()) {
+        SliceNode::Ptr n = working_list.front();
+	working_list.pop();
+	if (!n->assign()) {
+	    parsing_printf("\tWARNING: Encountering a slice node with no assignment!\n");
+	    continue;
+	}
+	if (exprs.find(n->assign()) != exprs.end()) {
+	    parsing_printf("\tWARNING: Jump table format slice contains cycle!\n");
+	    jumpTableFormat = false;
+	    return false;
+	}
+
+	/* We expand this assignment.
+	 * The jump table format should only involve basic instructions
+	 * such as mov, arithmetic, loading addresses.
+	 * If we encounter an instruction that we do not have semantics,
+	 * we should inspect this case.
+	 */
+	pair<AST::Ptr, bool> expandRet = se.ExpandAssignment(n->assign());
+	if (!expandRet.second || expandRet.first == NULL) {
+	    parsing_printf("\tWARNING: Jump table format slice contains unknown instructions: %s\n", n->assign()->insn()->format().c_str());
+	    unknownInstruction = true;
+	    jumpTableFormat = false;
+	    return false;
+	}
+	if (n->assign()->out().generator() != NULL) {
+	    parsing_printf("\tWARNING: Jump table format slice contains writes to memory\n");
+	    jumpTableFormat = false;
+	    return false;
+	}
+
+	// We make a deep copy of the AST because the AST from ExpandAssignment 
+	// may be used later. So, we do not want to destroy the AST of the assignment
+	AST::Ptr exp = SymbolicExpression::DeepCopyAnAST(expandRet.first);
+	// We start plug in ASTs from predecessors
+	n->ins(nbegin, nend);
+	map<AST::Ptr, AST::Ptr> inputs;
+	if (aliases.find(n->assign()) != aliases.end()) {
+	    inputs.insert(aliases[n->assign()]);
+	    parsing_printf("\t Replacing %s with %s\n", aliases[n->assign()].first->format().c_str(),aliases[n->assign()].second->format().c_str());
+	    exp = SymbolicExpression::SubstituteAnAST(exp, inputs);
+	    inputs.clear();
+	}
+	for (; nbegin != nend; ++nbegin) {
+	    SliceNode::Ptr p = boost::static_pointer_cast<SliceNode>(*nbegin);
+	    if (exprs.find(p->assign()) == exprs.end()) {
+	        parsing_printf("\tWARNING: For %s, its predecessor %s does not have an expression\n", n->assign()->format().c_str(), p->assign()->format().c_str());
+		jumpTableFormat = false;
+		return false;
+	    }
+	    AST::Ptr rhs = exprs[p->assign()];	    
+	    AST::Ptr lhs = VariableAST::create(Variable(p->assign()->out())); 
+	    // TODO: there may be more than one expression for a single variable
+	    inputs.insert(make_pair(lhs,  rhs));
+	}
+	if (g->isExitNode(n)) {
+	    // Here we try to detect the case where there are multiple
+	    // paths to the indirect jump, and on some of the paths, the jump
+	    // target has constnt values, and on some other path, the jump target
+	    // may have a jump table format
+	    int nonConstant = 0;
+	    int match = 0;
+	    for (auto iit = inputs.begin(); iit != inputs.end(); ++iit) {
+	        AST::Ptr lhs = iit->first;
+		AST::Ptr rhs = iit->second;
+	        if (*lhs == *exp) {
+		    match++;
+		    if (rhs->getID() == AST::V_ConstantAST) {
+		        ConstantAST::Ptr c = boost::static_pointer_cast<ConstantAST>(rhs);
+			constAddr.insert(c->val().val);
+		    } else {
+		        nonConstant++;
+			jumpTarget = rhs;
+		    }
+		}
+	    }
+	    if (match == 0) {
+	        // Thiw will happen when the indirect jump directly reads from memory,
+		// instead of jumping to the value of a register.
+		exp = SymbolicExpression::SubstituteAnAST(exp, inputs);
+	        jumpTarget = exp;
+		break;
+	    }
+	    if (nonConstant > 1) {
+	        parsing_printf("Find %d different jump target formats\n", nonConstant);
+		jumpTableFormat = false;
+		return false;
+	    } else if (nonConstant == 0) {
+	        parsing_printf("Only constant target values found so far, no need to check jump target format\n");
+		return true;
+	    }
+	    break;
+	}
+	// TODO: need to consider thunk
+	exp = SymbolicExpression::SubstituteAnAST(exp, inputs);
+	exprs[n->assign()] = exp;
+        // Enumerate every successor and add them to the working list
+	n->outs(nbegin, nend);
+	for (; nbegin != nend; ++nbegin) {
+	    SliceNode::Ptr p = boost::static_pointer_cast<SliceNode>(*nbegin);
+	    inDegree[p->assign()] --;
+	    if (inDegree[p->assign()] == 0 && inQueue.find(p->assign()) == inQueue.end()) {
+	        inQueue.insert(p->assign());
+		working_list.push(p);
+	    }
+	}
+    }
+    if (!jumpTarget) {
+        parsing_printf("\t Do not find a potential jump target expression\n");
+	jumpTableFormat = false;
+	return false;
+
+    }
+    JumpTableFormatVisitor jtfv(block);
+    assert(jumpTarget);
+    jumpTarget = SymbolicExpression::SimplifyAnAST(jumpTarget, 0);
+    parsing_printf("Check expression %s\n", jumpTarget->format().c_str());    
+    jumpTarget->accept(&jtfv);
+    if (jtfv.findIncorrectFormat) {
+        jumpTableFormat = false;
+	return false;
+    }
+    
+    if (!findIndex && jtfv.findIndex) {
+	if (frame.active.find(jtfv.index) == frame.active.end()) {
+	    parsing_printf("\tWARNING: found index variable %s, but it is not in the active map of the slice frame!\n", index.format().c_str());
+	    jumpTableFormat = false;
+	    return false;
+	}
+	if (frame.active[jtfv.index].size() > 1) {
+	    parsing_printf("\tWARNING: index variable has more than one slicing element!\n");
+	}
+	indexLoc = frame.active[jtfv.index][0].ptr;
+	// We have found the index variable.
+	// Now we leave it alone and let the jump table index slice to find its bound
+	frame.active.erase(jtfv.index);
+	index = jtfv.index;
+	findIndex = true;
+    }
+    jumpTargetExpr = jumpTarget;
+    if (jtfv.findIndex && jtfv.findTableBase) { 
+        findTableBase = true;
+        parsing_printf("\tFind both table index and table base, current jump target %s\n", jumpTargetExpr->format().c_str());
+        return false;
+    }
+
+    // We have not found all elements of the jump table,
+    // and we have not rejected this indirect jump as a jump table.
+    // Let's continue slicing.
+    return true;
+}
+
+string JumpTableFormatPred::format() {
+    if (jumpTargetExpr) return jumpTargetExpr->format();
+    return string("");
+}
+
+bool JumpTableFormatPred::findSpillRead(Graph::Ptr g, SliceNode::Ptr &readNode) {
+    NodeIterator gbegin, gend;
+    g->allNodes(gbegin, gend);
+    for (; gbegin != gend; ++gbegin) {
+        SliceNode::Ptr n = boost::static_pointer_cast<SliceNode>(*gbegin);
+	if (n->assign() == memLoc) {
+	    continue;
+	}
+	if (n->assign()->insn()->readsMemory()) {
+	    readNode = n;
+	    return true;
+	}
+    }
+    return false;
+}
+
+static Assignment::Ptr SearchForWrite(SliceNode::Ptr n, AbsRegion &src, Slicer::Location &loc, Slicer *s) {
+    
+
+    queue<Block*> workingList;
+    set<Block*> inQueue;
+    workingList.push(n->block());
+    inQueue.insert(n->block());
+
+    set<Expression::Ptr> memReads;
+    n->assign()->insn()->getMemoryReadOperands(memReads);
+    if (memReads.size() != 1) {
+        parsing_printf("\tThe instruction has %d memory read operands, Should have only one\n", memReads.size());
+	return Assignment::Ptr();
+    }
+    Expression::Ptr memRead = *memReads.begin();
+    parsing_printf("\tsearch for memory operand %s\n", memRead->format().c_str());
+    Block* targetBlock = NULL;
+    Instruction::Ptr targetInsn;
+    Address targetAddr;
+
+    while (!workingList.empty() && targetBlock == NULL) {
+        Block* curBlock = workingList.front();
+	workingList.pop();
+	// If the current block is the starting block,
+	// we need to make sure we only inspect instructions before the starting instruction
+	Address addr = 0;
+	if (curBlock == n->block()) {
+	    addr = n->addr();
+	}
+
+	Block::Insns insns;
+	curBlock->getInsns(insns);
+
+	for (auto iit = insns.rbegin(); iit != insns.rend(); ++iit) {
+	    if (addr > 0 && iit->first > addr) continue;
+	    Instruction::Ptr i = iit->second;
+	    // We find an the first instruction that only writes to memory
+	    // and the memory operand has the exact AST as the memory read.
+	    // Ideally, we need an architecture independent way to check whether this is a move instruction.
+	    // Category c_NoCategory excludes lots of non-move instructions
+	    if (!i->readsMemory() && i->writesMemory() && i->getCategory() == c_NoCategory) {
+	        set<Expression::Ptr> memWrites;
+		i->getMemoryWriteOperands(memWrites);
+		if (memWrites.size() == 1 && *memRead == *(*memWrites.begin())) {
+		    targetBlock = curBlock;
+		    targetInsn = i;
+		    targetAddr = iit->first;
+		    parsing_printf("\t\tFind matching at %lx\n", targetAddr);
+
+                    // Now we try to identify the source register
+		    std::vector<Operand> ops;
+		    i->getOperands(ops);
+		    for (auto oit = ops.begin(); oit != ops.end(); ++oit) {
+		        if (!(*oit).writesMemory() && !(*oit).readsMemory()) {
+			    std::set<RegisterAST::Ptr> regsRead;
+			    oit->getReadSet(regsRead);
+			    src = AbsRegion(Absloc( (*regsRead.begin())->getID() ));
+			    parsing_printf("\t\tContinue to slice on %s\n", src.format().c_str());
+			    break;
+			}
+		    }
+
+		    loc.block = curBlock;
+		    s->getInsnsBackward(loc);
+		    while (loc.addr() > targetAddr) {
+		        loc.rcurrent++;
+		    }
+		    break;
+		}
+	    }
+	}
+
+	for (auto eit = curBlock->sources().begin(); eit != curBlock->sources().end(); ++eit) {
+	    ParseAPI::Edge *e = *eit;
+	    if (e->interproc()) continue;
+	    if (e->type() == CATCH) continue;
+	    if (inQueue.find(e->src()) != inQueue.end()) continue;
+	    inQueue.insert(e->src());
+	    workingList.push(e->src());	    
+	}
+    }
+    
+    if (targetBlock == NULL) {
+        parsing_printf("\t\t Cannot find match\n");
+        return Assignment::Ptr();
+    }
+
+    AssignmentConverter ac(true, false);
+    vector<Assignment::Ptr> assignments;
+    ac.convert(targetInsn, targetAddr, n->func(), targetBlock, assignments);    
+    return assignments[0];
+}
+
+bool JumpTableFormatPred::adjustSliceFrame(Slicer::SliceFrame &frame, SliceNode::Ptr n, Slicer* s) {
+    // Delete all active regions introduce by this memory read,
+    // such as memory region, stack pointer, frame pointer
+    std::vector<AbsRegion>& inputs = n->assign()->inputs();
+    for (auto iit = inputs.begin(); iit != inputs.end(); ++iit) {
+        parsing_printf("\tdelete %s from active map\n", iit->format().c_str());
+        frame.active.erase(*iit);
+    }
+
+    // Search backward for the instruction that writes to the memory location
+    AbsRegion src;
+    Assignment::Ptr assign = SearchForWrite(n, src, frame.loc, s);
+    if (!assign) return false;
+    
+    NodeIterator nbegin, nend;
+    n->outs(nbegin, nend);
+    parsing_printf("\tadd %s to active map\n", src.format().c_str());
+    for (; nbegin != nend; ++nbegin) {
+        SliceNode::Ptr next = boost::static_pointer_cast<SliceNode>(*nbegin);
+	frame.active[src].push_back(Slicer::Element(next->block(), next->func(), src, next->assign()));
+	if (n->assign()->out() != src) {
+	    aliases[next->assign()] = make_pair(VariableAST::create(Variable(n->assign()->out())), VariableAST::create(Variable(src)));
+	}   
+
+    }
+    return true;
+}
+
+
diff --git a/parseAPI/src/JumpTableFormatPred.h b/parseAPI/src/JumpTableFormatPred.h
new file mode 100644
index 0000000..ef4b4da
--- /dev/null
+++ b/parseAPI/src/JumpTableFormatPred.h
@@ -0,0 +1,55 @@
+#ifndef JUMP_TABLE_FORMAT_PRED_H
+#define JUMP_TABLE_FORMAT_PRED_H
+
+#include "CFG.h"
+#include "slicing.h"
+#include "Edge.h"
+#include "ThunkData.h"
+#include "Graph.h"
+#include "SymbolicExpression.h"
+//#include "BoundFactCalculator.h"
+using namespace Dyninst;
+
+class JumpTableFormatPred : public Slicer::Predicates {
+public:
+    ParseAPI::Function *func;
+    ParseAPI::Block *block;
+    ReachFact &rf;
+    ThunkData &thunks;
+    SymbolicExpression &se;
+
+    bool jumpTableFormat;
+    bool unknownInstruction;
+    bool findIndex;
+    bool findTableBase;
+
+    AbsRegion index;
+    Assignment::Ptr indexLoc;
+    bool firstMemoryRead;
+    Assignment::Ptr memLoc;
+    AST::Ptr jumpTargetExpr;
+
+    set<Address> constAddr;
+    dyn_hash_map<Assignment::Ptr, std::pair<AST::Ptr, AST::Ptr>, Assignment::AssignmentPtrHasher> aliases;
+
+    JumpTableFormatPred(ParseAPI::Function *f,
+                        ParseAPI::Block *b,
+			ReachFact &r,
+			ThunkData &t,
+			SymbolicExpression &sym):
+            func(f), block(b), rf(r), thunks(t), se(sym) {
+	        jumpTableFormat = true;
+		unknownInstruction = false;
+		findIndex = false;
+		findTableBase = false;
+		firstMemoryRead = true;
+	    }
+
+    virtual bool modifyCurrentFrame(Slicer::SliceFrame &frame, Graph::Ptr g, Slicer*);
+    std::string format();
+    bool isJumpTableFormat() { return jumpTableFormat && findIndex && findTableBase;}
+    bool findSpillRead(Graph::Ptr g, SliceNode::Ptr &);
+    bool adjustSliceFrame(Slicer::SliceFrame &frame, SliceNode::Ptr, Slicer*);
+};
+
+#endif
diff --git a/parseAPI/src/JumpTableIndexPred.C b/parseAPI/src/JumpTableIndexPred.C
new file mode 100644
index 0000000..19126b9
--- /dev/null
+++ b/parseAPI/src/JumpTableIndexPred.C
@@ -0,0 +1,319 @@
+#include "dyntypes.h"
+#include "Node.h"
+#include "Graph.h"
+
+#include "debug_parse.h"
+#include "CodeObject.h"
+#include "JumpTableIndexPred.h"
+#include "IndirectASTVisitor.h"
+
+#include "Instruction.h"
+#include "InstructionDecoder.h"
+
+#include "AbslocInterface.h"
+#include "SymEval.h"
+
+using namespace Dyninst;
+using namespace Dyninst::DataflowAPI;
+using namespace Dyninst::ParseAPI;
+using namespace Dyninst::InstructionAPI;
+// Assume the table contain less than this many entries.
+#define MAX_TABLE_ENTRY 1000000
+
+
+static void BuildEdgesAux(SliceNode::Ptr srcNode,
+                          ParseAPI::Block* curBlock,
+			  map<ParseAPI::Block*, map<AssignmentPtr, SliceNode::Ptr> > &targetMap,
+			  GraphPtr newG,
+			  set<ParseAPI::Block*> &visit,
+			  EdgeTypeEnum t,
+			  set<ParseAPI::Edge*> allowedEdges) {			 
+    if (targetMap.find(curBlock) != targetMap.end()) {
+        // This block contains at least one silce node 
+	// that is reachable from the source DFS node
+        map<AssignmentPtr, SliceNode::Ptr> &candNodes = targetMap[curBlock];
+	Address addr = 0;
+	for (auto cit = candNodes.begin(); cit != candNodes.end(); ++cit)
+	    // The node has to be either in a different block from the source node
+	    // or in the same block but has a larger address to be considered 
+	    // reachable from the source node
+	    if (cit->first->addr() > srcNode->addr() || curBlock != srcNode->block())
+	        if (addr == 0 || addr > cit->first->addr()) {
+		    addr = cit->first->addr();
+		}
+	if (addr != 0) {
+	    // There may be several assignments locating 
+	    // at the same address. Need to connecting all.
+	    if (t == _edgetype_end_) t = FALLTHROUGH;
+	    for (auto cit = candNodes.begin(); cit != candNodes.end(); ++cit)
+	        if (cit->first->addr() > srcNode->addr() || curBlock != srcNode->block())
+		    if (addr == cit->first->addr()) {
+		        newG->insertPair(srcNode, cit->second, TypedSliceEdge::create(srcNode, cit->second, t));
+		    }
+	    return;
+	}
+    }
+
+    if (visit.find(curBlock) != visit.end()) return;
+    visit.insert(curBlock);
+    for (auto eit = curBlock->targets().begin(); eit != curBlock->targets().end(); ++eit) {
+	// Xiaozhu:
+	// Our current slicing code ignores tail calls 
+	// (the slice code only checks if an edge type is CALL or not)
+ 	// so, I should be consistent here.
+	// If the slice code considers tail calls, need to change
+	// the predicate to (*eit)->interproc()
+        if ((*eit)->type() != CALL && (*eit)->type() != RET && allowedEdges.find(*eit) != allowedEdges.end()) {
+	    EdgeTypeEnum newT = t; 
+	    if (t == _edgetype_end_) {
+	        if ((*eit)->type() == COND_TAKEN || (*eit)->type() == COND_NOT_TAKEN) 
+		    newT = (*eit)->type();
+		else 
+		    newT = FALLTHROUGH;
+	    } 
+	    BuildEdgesAux(srcNode, (*eit)->trg(), targetMap, newG, visit, newT, allowedEdges);	   
+	}
+    }
+}			  
+
+
+static void BuildEdges(SliceNode::Ptr curNode,
+		       map<ParseAPI::Block*, map<AssignmentPtr, SliceNode::Ptr> > &targetMap,
+		       GraphPtr newG,
+		       set<ParseAPI::Edge*> &allowedEdges) {
+    set<ParseAPI::Block*> visit;		     
+    BuildEdgesAux(curNode, curNode->block(), targetMap, newG, visit, _edgetype_end_, allowedEdges);
+}		       
+
+static bool AssignIsZF(Assignment::Ptr a) {
+    return a->out().absloc().type() == Absloc::Register &&
+	   (a->out().absloc().reg() == MachRegister::getZeroFlag(a->out().absloc().reg().getArchitecture()));
+}
+
+static bool IsPushAndChangeSP(Assignment::Ptr a) {
+    entryID id = a->insn()->getOperation().getID();
+    if (id != e_push) return false;
+    Absloc aloc = a->out().absloc();
+    if (aloc.type() == Absloc::Register && aloc.reg().isStackPointer()) return true;
+    return false;;
+
+}
+
+GraphPtr JumpTableIndexPred::BuildAnalysisGraph(set<ParseAPI::Edge*> &visitedEdges) {
+    GraphPtr newG = Graph::createGraph();
+    
+    NodeIterator gbegin, gend;
+    parsing_printf("\t\t start to build analysis graph\n");
+
+    // Create a map to help find whether we have reached a node
+    map<ParseAPI::Block*, map<AssignmentPtr, SliceNode::Ptr> > targetMap;
+
+    // Assignments that are at these addresses have flag assignment colocated
+    set<Address> shouldSkip;
+    for (auto ait = currentAssigns.begin(); ait != currentAssigns.end(); ++ait) {
+	if (AssignIsZF(*ait))
+	    shouldSkip.insert((*ait)->addr());
+    }
+    parsing_printf("\t\t calculate skipped nodes\n");
+
+    // We only need one assignment from xchg instruction at each address
+    set<Address> xchgCount;
+    set<Assignment::Ptr> xchgAssign;
+    for (auto ait = currentAssigns.begin(); ait != currentAssigns.end(); ++ait) {
+        if ((*ait)->insn()->getOperation().getID() == e_xchg) {
+	    if (xchgCount.find( (*ait)->addr() ) != xchgCount.end() ) continue;
+	    xchgCount.insert((*ait)->addr());
+	    xchgAssign.insert(*ait);
+	}
+    }
+    parsing_printf("\t\t calculate xchg assignments\n");
+   
+    for (auto ait = currentAssigns.begin(); ait != currentAssigns.end(); ++ait) {
+        Assignment::Ptr a = *ait;
+	if (   (AssignIsZF(a) || shouldSkip.find(a->addr()) == shouldSkip.end()) 
+	    && !IsPushAndChangeSP(a)
+	    && (!a->insn()->writesMemory() || MatchReadAST(a))) {
+	    if (a->insn()->getOperation().getID() == e_xchg && xchgAssign.find(a) == xchgAssign.end()) continue;
+	    SliceNode::Ptr newNode = SliceNode::create(a, a->block(), a->func());
+	    targetMap[a->block()][a] = newNode;
+	    newG->addNode(newNode);
+	}
+    }
+    parsing_printf("\t\t calculate nodes in the new graph\n");
+    // Start from each node to do DFS and build edges
+    newG->allNodes(gbegin, gend);
+    for (; gbegin != gend; ++gbegin) {
+        SliceNode::Ptr node = boost::static_pointer_cast<SliceNode>(*gbegin);
+	BuildEdges(node, targetMap, newG, visitedEdges);
+    }
+    parsing_printf("\t\t calculate edges in the new graph\n");
+/*
+    // Build a virtual exit node
+    SliceNode::Ptr virtualExit = SliceNode::create(Assignment::Ptr(), NULL, NULL);
+    newG->addNode(virtualExit);
+    newG->allNodes(gbegin, gend);
+    for (; gbegin != gend; ++gbegin) {
+        SliceNode::Ptr cur = boost::static_pointer_cast<SliceNode>(*gbegin);
+	if (!cur->hasOutEdges() && cur != virtualExit) {
+	    newG->insertPair(cur, virtualExit, TypedSliceEdge::create(cur, virtualExit, FALLTHROUGH));
+	}
+    }
+    parsing_printf("\t\t calculate virtual nodes in the new graph\n");
+*/
+    newG->adjustEntryAndExitNodes();
+
+    return newG;
+
+}
+
+
+bool JumpTableIndexPred::addNodeCallback(AssignmentPtr ap, set<ParseAPI::Edge*> &visitedEdges) {
+    if (unknownInstruction) return false;
+    if (currentAssigns.find(ap) != currentAssigns.end()) return true;
+    if (currentAssigns.size() > 50) return false; 
+    // For flags, we only analyze zf
+    if (ap->out().absloc().type() == Absloc::Register) {
+        MachRegister reg = ap->out().absloc().reg();
+	if (reg.isFlag() && reg != MachRegister::getZeroFlag(reg.getArchitecture())) {
+	    return true;
+	}
+    }
+    pair<AST::Ptr, bool> expandRet = se.ExpandAssignment(ap);
+
+    currentAssigns.insert(ap);
+
+    parsing_printf("Adding assignment %s in instruction %s at %lx, total %d\n", ap->format().c_str(), ap->insn()->format().c_str(), ap->addr(), currentAssigns.size());
+/*
+    if (ap->insn() && ap->insn()->readsMemory() && firstMemoryRead) {
+        firstMemoryRead = false;
+	parsing_printf("\tThe first memory read, check if format is correct\n");
+	if 
+    }
+*/
+
+    if (!expandRet.second || expandRet.first == NULL) {
+        if (ap && ap->block() && ap->block()->obj()->cs()->getArch() == Arch_aarch64) {
+            unknownInstruction = true;
+        }
+        return true;
+    }
+
+    // If this assignment writes memory,
+    // we only want to analyze it when it writes to 
+    // an AST we have seen before and potentially
+    // can used for aliasing
+    if (ap->insn()->writesMemory()) {
+        if (!MatchReadAST(ap)) return true;
+    }
+
+    // If this assignment reads memory,
+    // we record the AST of the read so
+    // that in the future we can match a
+    // corresponding write to identify aliasing
+    if (ap->insn()->readsMemory() && expandRet.first->getID() == AST::V_RoseAST) {
+        RoseAST::Ptr roseAST = boost::static_pointer_cast<RoseAST>(expandRet.first);
+	if (roseAST->val().op == ROSEOperation::derefOp) {
+	    readAST.push_back(expandRet.first);
+	}
+    }
+    // I really do not want to redo the analysis from scratch,
+    // but it seems like with newly added edges and nodes,
+    // it is necessary to redo.
+
+    // We create the CFG based on the found nodes
+    GraphPtr g = BuildAnalysisGraph(visitedEdges);
+    BoundFactsCalculator bfc(func, g, func->entry() == block, false, se);
+    bfc.CalculateBoundedFacts();
+
+    StridedInterval target;
+    bool ijt = IsIndexBounded(g, bfc, target);
+    if (ijt) {
+	// Now we have stopped slicing, so the cache contents may not be complete any more.
+	setClearCache(true);
+        return false;
+    } else {
+        return true;
+    }	
+
+
+
+}
+bool JumpTableIndexPred::FillInOutEdges(StridedInterval &target, 
+                                                 vector<pair< Address, Dyninst::ParseAPI::EdgeTypeEnum > >& outEdges) {
+/*
+    set<int64_t> jumpTargets;						 
+    if (!PerformTableRead(target, jumpTargets, block->obj()->cs())) {
+        jumpTableFormat = false;
+	return false;
+    }
+    outEdges.clear();
+    for (auto tit = jumpTargets.begin(); tit != jumpTargets.end(); ++tit) {
+        outEdges.push_back(make_pair(*tit, INDIRECT));
+    }
+*/
+    return true;
+}
+bool JumpTableIndexPred::IsIndexBounded(GraphPtr slice,
+                                       BoundFactsCalculator &bfc,
+                                       StridedInterval &target) {
+    NodeIterator exitBegin, exitEnd, srcBegin, srcEnd;
+    slice->exitNodes(exitBegin, exitEnd);
+    SliceNode::Ptr virtualExit = boost::static_pointer_cast<SliceNode>(*exitBegin);
+    virtualExit->ins(srcBegin, srcEnd);
+    SliceNode::Ptr jumpNode = boost::static_pointer_cast<SliceNode>(*srcBegin);
+    
+    BoundFact *bf = bfc.GetBoundFactOut(virtualExit);
+    VariableAST::Ptr i = VariableAST::create(Variable(index));
+    StridedInterval *tarBoundValue = bf->GetBound(i);
+    if (tarBoundValue != NULL) {
+        target = *(tarBoundValue);
+	uint64_t s = target.size();
+	if (s > 0 && s <= MAX_TABLE_ENTRY) {
+	    findBound = true;
+	    bound = target;
+	    return true;
+	}
+    }
+    return false;
+}
+
+bool JumpTableIndexPred::MatchReadAST(Assignment::Ptr a) {
+    pair<AST::Ptr, bool> expandRet = se.ExpandAssignment(a);
+    if (!expandRet.second || expandRet.first == NULL) return false;
+    if (a->out().generator() == NULL) return false;
+    AST::Ptr write = SymbolicExpression::SimplifyAnAST(RoseAST::create(ROSEOperation(ROSEOperation::derefOp, a->out().size()), a->out().generator()), 
+                                   SymbolicExpression::PCValue(a->addr(),
+				           a->insn()->size(),
+					   a->block()->obj()->cs()->getArch()));
+
+    if (write == NULL) return false;
+    for (auto ait = readAST.begin(); ait != readAST.end(); ++ait) 
+        if (*write == **ait) return true;
+    return false;
+}
+
+bool JumpTableIndexPred::modifyCurrentFrame(Slicer::SliceFrame &frame, Graph::Ptr g, Slicer *) {
+    parsing_printf("\tIn JumpTableIndexPred::modifyCurrentFrame, size %d\n", g->size());
+
+    if (g->size() == 1) {
+        /* This is the start of the jump table index slice.
+	 * As the slicing interface only works with an assignment, 
+	 * we wants to only keep the index AbsRegion in the current active map
+	 */
+	Slicer::SliceFrame::ActiveMap::iterator it1, it2;
+	it1 = frame.active.begin();
+	while (it1 != frame.active.end()) {
+	    parsing_printf("\t\tactive region %s\n", it1->first.format().c_str());
+	    if (it1->first != index) {
+	        it2 = it1;
+		++it2;
+		frame.active.erase(it1);
+		it1 = it2;
+	    } else {
+	        it1++;
+	    }
+	}
+    }
+    return true;
+}
+
diff --git a/parseAPI/src/JumpTableIndexPred.h b/parseAPI/src/JumpTableIndexPred.h
new file mode 100644
index 0000000..fd241c0
--- /dev/null
+++ b/parseAPI/src/JumpTableIndexPred.h
@@ -0,0 +1,70 @@
+#ifndef JUMP_TABLE_INDEX_PRED_H
+#define JUMP_TABLE_INDEX_PRED_H
+
+#include "CFG.h"
+#include "slicing.h"
+#include "Edge.h"
+#include "ThunkData.h"
+#include "Graph.h"
+#include "BoundFactCalculator.h"
+#include "Absloc.h"
+using namespace Dyninst;
+
+class JumpTableIndexPred : public Slicer::Predicates {
+
+    ParseAPI::Function *func;
+    ParseAPI::Block *block;
+    AbsRegion index;
+    SymbolicExpression &se;
+    std::vector<AST::Ptr> readAST;
+    
+    bool MatchReadAST(Assignment::Ptr a);
+
+
+public:
+    bool unknownInstruction;
+    bool findBound;
+    StridedInterval bound;
+    std::set<Assignment::Ptr> currentAssigns;
+    virtual bool addNodeCallback(AssignmentPtr ap, std::set<ParseAPI::Edge*> &visitedEdges);
+    virtual bool modifyCurrentFrame(Slicer::SliceFrame &frame, Graph::Ptr g, Slicer*);
+    GraphPtr BuildAnalysisGraph(std::set<ParseAPI::Edge*> &visitedEdges);
+    bool IsIndexBounded(GraphPtr slice, BoundFactsCalculator &bfc, StridedInterval &target);
+    bool FillInOutEdges(StridedInterval &target, std::vector<std::pair< Address, Dyninst::ParseAPI::EdgeTypeEnum > >& outEdges);
+
+
+    JumpTableIndexPred(ParseAPI::Function *f,
+                       ParseAPI::Block *b,
+		       AbsRegion i,
+		       SymbolicExpression &sym)
+		          : func(f), 
+			    block(b),
+			    index(i),
+			    se(sym) {
+			       unknownInstruction = false;
+			       findBound = false;
+		      }
+};
+
+
+class TypedSliceEdge: public Dyninst::Edge {
+    ParseAPI::EdgeTypeEnum type_; 
+    
+    TypedSliceEdge(const SliceNode::Ptr source,
+              const SliceNode::Ptr target,
+	      ParseAPI::EdgeTypeEnum t) 
+	      : Dyninst::Edge(source, target), type_(t) {};
+  public:	      
+   typedef boost::shared_ptr<TypedSliceEdge> Ptr; 
+   static TypedSliceEdge::Ptr create(SliceNode::Ptr source,
+                                     SliceNode::Ptr target,
+				     ParseAPI::EdgeTypeEnum t) {
+	return Ptr(new TypedSliceEdge(source, target, t));       
+   }                                                
+
+  public:
+    ParseAPI::EdgeTypeEnum type() { return type_;}
+
+};
+
+#endif
diff --git a/parseAPI/src/JumpTablePred.C b/parseAPI/src/JumpTablePred.C
deleted file mode 100644
index 54e4d27..0000000
--- a/parseAPI/src/JumpTablePred.C
+++ /dev/null
@@ -1,351 +0,0 @@
-#include "dyntypes.h"
-#include "Node.h"
-#include "Graph.h"
-
-#include "debug_parse.h"
-#include "CodeObject.h"
-#include "JumpTablePred.h"
-#include "IndirectASTVisitor.h"
-
-#include "Instruction.h"
-#include "InstructionDecoder.h"
-
-#include "AbslocInterface.h"
-#include "SymEval.h"
-
-using namespace Dyninst;
-using namespace Dyninst::DataflowAPI;
-using namespace Dyninst::ParseAPI;
-using namespace Dyninst::InstructionAPI;
-// Assume the table contain less than this many entries.
-#define MAX_TABLE_ENTRY 1000000
-
-
-static void BuildEdgesAux(SliceNode::Ptr srcNode,
-                          ParseAPI::Block* curBlock,
-			  map<ParseAPI::Block*, map<AssignmentPtr, SliceNode::Ptr> > &targetMap,
-			  GraphPtr newG,
-			  set<ParseAPI::Block*> &visit,
-			  EdgeTypeEnum t,
-			  set<ParseAPI::Edge*> allowedEdges) {			 
-    if (targetMap.find(curBlock) != targetMap.end()) {
-        // This block contains at least one silce node 
-	// that is reachable from the source DFS node
-        map<AssignmentPtr, SliceNode::Ptr> &candNodes = targetMap[curBlock];
-	Address addr = 0;
-	for (auto cit = candNodes.begin(); cit != candNodes.end(); ++cit)
-	    // The node has to be either in a different block from the source node
-	    // or in the same block but has a larger address to be considered 
-	    // reachable from the source node
-	    if (cit->first->addr() > srcNode->addr() || curBlock != srcNode->block())
-	        if (addr == 0 || addr > cit->first->addr()) {
-		    addr = cit->first->addr();
-		}
-	if (addr != 0) {
-	    // There may be several assignments locating 
-	    // at the same address. Need to connecting all.
-	    if (t == _edgetype_end_) t = FALLTHROUGH;
-	    for (auto cit = candNodes.begin(); cit != candNodes.end(); ++cit)
-	        if (cit->first->addr() > srcNode->addr() || curBlock != srcNode->block())
-		    if (addr == cit->first->addr()) {
-		        newG->insertPair(srcNode, cit->second, TypedSliceEdge::create(srcNode, cit->second, t));
-		    }
-	    return;
-	}
-    }
-
-    if (visit.find(curBlock) != visit.end()) return;
-    visit.insert(curBlock);
-    for (auto eit = curBlock->targets().begin(); eit != curBlock->targets().end(); ++eit) {
-	// Xiaozhu:
-	// Our current slicing code ignores tail calls 
-	// (the slice code only checks if an edge type is CALL or not)
- 	// so, I should be consistent here.
-	// If the slice code considers tail calls, need to change
-	// the predicate to (*eit)->interproc()
-        if ((*eit)->type() != CALL && (*eit)->type() != RET && allowedEdges.find(*eit) != allowedEdges.end()) {
-	    EdgeTypeEnum newT = t; 
-	    if (t == _edgetype_end_) {
-	        if ((*eit)->type() == COND_TAKEN || (*eit)->type() == COND_NOT_TAKEN) 
-		    newT = (*eit)->type();
-		else 
-		    newT = FALLTHROUGH;
-	    } 
-	    BuildEdgesAux(srcNode, (*eit)->trg(), targetMap, newG, visit, newT, allowedEdges);	   
-	}
-    }
-}			  
-
-
-static void BuildEdges(SliceNode::Ptr curNode,
-		       map<ParseAPI::Block*, map<AssignmentPtr, SliceNode::Ptr> > &targetMap,
-		       GraphPtr newG,
-		       set<ParseAPI::Edge*> &allowedEdges) {
-    set<ParseAPI::Block*> visit;		     
-    BuildEdgesAux(curNode, curNode->block(), targetMap, newG, visit, _edgetype_end_, allowedEdges);
-}		       
-
-static bool AssignIsZF(Assignment::Ptr a) {
-    return a->out().absloc().type() == Absloc::Register &&
-	   (a->out().absloc().reg() == MachRegister::getZeroFlag(a->out().absloc().reg().getArchitecture()));
-}
-
-static bool IsPushAndChangeSP(Assignment::Ptr a) {
-    entryID id = a->insn()->getOperation().getID();
-    if (id != e_push) return false;
-    Absloc aloc = a->out().absloc();
-    if (aloc.type() == Absloc::Register && aloc.reg().isStackPointer()) return true;
-    return false;;
-
-}
-
-static int AdjustGraphEntryAndExit(GraphPtr gp) {
-    int nodeCount = 0;
-    NodeIterator gbegin, gend;
-    gp->allNodes(gbegin, gend);
-    for (; gbegin != gend; ++gbegin) {
-        ++nodeCount;
-        Node::Ptr ptr = *gbegin;
-	if (!ptr->hasInEdges()) gp->insertEntryNode(ptr);
-	if (!ptr->hasOutEdges()) gp->insertExitNode(ptr);
-    }
-    return nodeCount;
-}
-
-GraphPtr JumpTablePred::BuildAnalysisGraph(set<ParseAPI::Edge*> &visitedEdges) {
-    GraphPtr newG = Graph::createGraph();
-    
-    NodeIterator gbegin, gend;
-    parsing_printf("\t\t start to build analysis graph\n");
-
-    // Create a map to help find whether we have reached a node
-    map<ParseAPI::Block*, map<AssignmentPtr, SliceNode::Ptr> > targetMap;
-
-    // Assignments that are at these addresses have flag assignment colocated
-    set<Address> shouldSkip;
-    for (auto ait = currentAssigns.begin(); ait != currentAssigns.end(); ++ait) {
-	if (AssignIsZF(*ait))
-	    shouldSkip.insert((*ait)->addr());
-    }
-    parsing_printf("\t\t calculate skipped nodes\n");
-
-    // We only need one assignment from xchg instruction at each address
-    set<Address> xchgCount;
-    set<Assignment::Ptr> xchgAssign;
-    for (auto ait = currentAssigns.begin(); ait != currentAssigns.end(); ++ait) {
-        if ((*ait)->insn()->getOperation().getID() == e_xchg) {
-	    if (xchgCount.find( (*ait)->addr() ) != xchgCount.end() ) continue;
-	    xchgCount.insert((*ait)->addr());
-	    xchgAssign.insert(*ait);
-	}
-    }
-    parsing_printf("\t\t calculate xchg assignments\n");
-   
-    for (auto ait = currentAssigns.begin(); ait != currentAssigns.end(); ++ait) {
-        Assignment::Ptr a = *ait;
-	if (   (AssignIsZF(a) || shouldSkip.find(a->addr()) == shouldSkip.end()) 
-	    && !IsPushAndChangeSP(a)
-	    && (!a->insn()->writesMemory() || MatchReadAST(a))) {
-	    if (a->insn()->getOperation().getID() == e_xchg && xchgAssign.find(a) == xchgAssign.end()) continue;
-	    SliceNode::Ptr newNode = SliceNode::create(a, a->block(), a->func());
-	    targetMap[a->block()][a] = newNode;
-	    newG->addNode(newNode);
-	}
-    }
-    parsing_printf("\t\t calculate nodes in the new graph\n");
-    // Start from each node to do DFS and build edges
-    newG->allNodes(gbegin, gend);
-    for (; gbegin != gend; ++gbegin) {
-        SliceNode::Ptr node = boost::static_pointer_cast<SliceNode>(*gbegin);
-	BuildEdges(node, targetMap, newG, visitedEdges);
-    }
-    parsing_printf("\t\t calculate edges in the new graph\n");
-
-    // Build a virtual exit node
-    SliceNode::Ptr virtualExit = SliceNode::create(Assignment::Ptr(), NULL, NULL);
-    newG->addNode(virtualExit);
-    newG->allNodes(gbegin, gend);
-    for (; gbegin != gend; ++gbegin) {
-        SliceNode::Ptr cur = boost::static_pointer_cast<SliceNode>(*gbegin);
-	if (!cur->hasOutEdges() && cur != virtualExit) {
-	    newG->insertPair(cur, virtualExit, TypedSliceEdge::create(cur, virtualExit, FALLTHROUGH));
-	}
-    }
-    parsing_printf("\t\t calculate virtual nodes in the new graph\n");
-
-    AdjustGraphEntryAndExit(newG);
-
-
-    return newG;
-
-}
-
-
-bool JumpTablePred::addNodeCallback(AssignmentPtr ap, set<ParseAPI::Edge*> &visitedEdges) {
-    if (!jumpTableFormat) return false;
-    if (unknownInstruction) return false;
-    if (currentAssigns.find(ap) != currentAssigns.end()) return true;
-    if (currentAssigns.size() > 50) return false; 
-    // For flags, we only analyze zf
-    if (ap->out().absloc().type() == Absloc::Register) {
-        MachRegister reg = ap->out().absloc().reg();
-	if (reg.isFlag() && reg != MachRegister::getZeroFlag(reg.getArchitecture())) {
-	    return true;
-	}
-    }
-    pair<AST::Ptr, bool> expandRet = ExpandAssignment(ap);
-
-    currentAssigns.insert(ap);
-
-    parsing_printf("Adding assignment %s in instruction %s at %lx, total %d\n", ap->format().c_str(), ap->insn()->format().c_str(), ap->addr(), currentAssigns.size());
-/*
-    if (ap->insn() && ap->insn()->readsMemory() && firstMemoryRead) {
-        firstMemoryRead = false;
-	parsing_printf("\tThe first memory read, check if format is correct\n");
-	if 
-    }
-*/
-
-    if (!expandRet.second || expandRet.first == NULL) {
-        if (ap && ap->block() && ap->block()->obj()->cs()->getArch() == Arch_aarch64) {
-            unknownInstruction = true;
-        }
-        return true;
-    }
-
-    // If this assignment writes memory,
-    // we only want to analyze it when it writes to 
-    // an AST we have seen before and potentially
-    // can used for aliasing
-    if (ap->insn()->writesMemory()) {
-        if (!MatchReadAST(ap)) return true;
-    }
-
-    // If this assignment reads memory,
-    // we record the AST of the read so
-    // that in the future we can match a
-    // corresponding write to identify aliasing
-    if (ap->insn()->readsMemory() && expandRet.first->getID() == AST::V_RoseAST) {
-        RoseAST::Ptr roseAST = boost::static_pointer_cast<RoseAST>(expandRet.first);
-	if (roseAST->val().op == ROSEOperation::derefOp) {
-	    readAST.push_back(expandRet.first);
-	}
-    }
-    // I really do not want to redo the analysis from scratch,
-    // but it seems like with newly added edges and nodes,
-    // it is necessary to redo.
-
-    // We create the CFG based on the found nodes
-    GraphPtr g = BuildAnalysisGraph(visitedEdges);
-    BoundFactsCalculator bfc(func, g, func->entry() == block, rf, thunks, false, expandCache);
-    bfc.CalculateBoundedFacts();
-
-    BoundValue target;
-    bool ijt = IsJumpTable(g, bfc, target);
-    if (ijt) {
-        bool ret = !FillInOutEdges(target, outEdges) || outEdges.empty();
-	// Now we have stopped slicing in advance, so the cache contents are not complete any more.
-	if (!ret) setClearCache(true);
-        return ret;
-    } else {
-        return true;
-    }	
-
-
-
-}
-bool JumpTablePred::FillInOutEdges(BoundValue &target, 
-                                                 vector<pair< Address, Dyninst::ParseAPI::EdgeTypeEnum > >& outEdges) {
-    if (target.values != NULL) {
-        outEdges.clear();
-        for (auto tit = target.values->begin(); tit != target.values->end(); ++tit) {
-            outEdges.push_back(make_pair(*tit, INDIRECT));
-        }
-	return true;
-    }
-    set<int64_t> jumpTargets;						 
-    if (!PerformTableRead(target, jumpTargets, block->obj()->cs())) {
-        jumpTableFormat = false;
-	return false;
-    }
-    outEdges.clear();
-    for (auto tit = jumpTargets.begin(); tit != jumpTargets.end(); ++tit) {
-        outEdges.push_back(make_pair(*tit, INDIRECT));
-    }
-    return true;
-}
-bool JumpTablePred::IsJumpTable(GraphPtr slice, 
-					      BoundFactsCalculator &bfc,
-					      BoundValue &target) {
-    NodeIterator exitBegin, exitEnd, srcBegin, srcEnd;
-    slice->exitNodes(exitBegin, exitEnd);
-    SliceNode::Ptr virtualExit = boost::static_pointer_cast<SliceNode>(*exitBegin);
-    virtualExit->ins(srcBegin, srcEnd);
-    SliceNode::Ptr jumpNode = boost::static_pointer_cast<SliceNode>(*srcBegin);
-    
-    const Absloc &loc = jumpNode->assign()->out().absloc();
-    parsing_printf("Checking final bound fact for %s\n",loc.format().c_str()); 
-    BoundFact *bf = bfc.GetBoundFactOut(virtualExit);
-    VariableAST::Ptr ip = VariableAST::create(Variable(loc));
-    BoundValue *tarBoundValue = bf->GetBound(ip);
-    if (tarBoundValue != NULL) {
-        target = *(tarBoundValue);
-	uint64_t s;
-	if (target.values == NULL)
-	    s = target.interval.size();
-	else
-	    s = target.values->size();
-	if (s > 0 && s <= MAX_TABLE_ENTRY) return true;
-    }
-    AST::Ptr ipExp = bf->GetAlias(ip);
-    if (ipExp) {
-        parsing_printf("\t jump target expression %s\n", ipExp->format().c_str());
-	JumpTableFormatVisitor jtfv(block);
-	ipExp->accept(&jtfv);
-	if (!jtfv.format) {
-	    parsing_printf("\t Not jump table format!\n");
-	    jumpTableFormat = false;
-	}
-    }
-
-    return false;
-}
-
-bool JumpTablePred::MatchReadAST(Assignment::Ptr a) {
-    pair<AST::Ptr, bool> expandRet = ExpandAssignment(a);
-    if (!expandRet.second || expandRet.first == NULL) return false;
-    if (a->out().generator() == NULL) return false;
-    AST::Ptr write = SimplifyAnAST(RoseAST::create(ROSEOperation(ROSEOperation::derefOp, a->out().size()), a->out().generator()), 
-                                   PCValue(a->addr(),
-				           a->insn()->size(),
-					   a->block()->obj()->cs()->getArch()));
-
-    if (write == NULL) return false;
-    for (auto ait = readAST.begin(); ait != readAST.end(); ++ait) 
-        if (*write == **ait) return true;
-    return false;
-}
-
-pair<AST::Ptr, bool> JumpTablePred::ExpandAssignment(Assignment::Ptr assign) {
-    if (expandCache.find(assign) != expandCache.end()) {
-        AST::Ptr ast = expandCache[assign];
-        if (ast) return make_pair(ast, true); else return make_pair(ast, false);
-
-    } else {
-		parsing_printf("\t\tExpanding instruction @ %x: %s\n", assign->addr(), assign->insn()->format().c_str());
-        pair<AST::Ptr, bool> expandRet = SymEval::expand(assign, false);
-	if (expandRet.second && expandRet.first) {
-parsing_printf("Original expand: %s\n", expandRet.first->format().c_str());
-
-	    AST::Ptr calculation = SimplifyAnAST(expandRet.first, 
-	                                         PCValue(assign->addr(),
-						         assign->insn()->size(),
-							 assign->block()->obj()->cs()->getArch()));
-	    expandCache[assign] = calculation;
-	} else {
-	    expandCache[assign] = AST::Ptr();
-	}
-	return make_pair( expandCache[assign], expandRet.second );
-    }
-}
-
diff --git a/parseAPI/src/JumpTablePred.h b/parseAPI/src/JumpTablePred.h
deleted file mode 100644
index 5143504..0000000
--- a/parseAPI/src/JumpTablePred.h
+++ /dev/null
@@ -1,67 +0,0 @@
-#ifndef JUMP_TABLE_PRED_H
-#define JUMP_TABLE_PRED_H
-
-#include "CFG.h"
-#include "slicing.h"
-#include "Edge.h"
-#include "ThunkData.h"
-#include "Graph.h"
-#include "BoundFactCalculator.h"
-using namespace Dyninst;
-
-class JumpTablePred : public Slicer::Predicates {
-
-    ParseAPI::Function *func;
-    ParseAPI::Block *block;
-    ReachFact &rf;
-    ThunkData &thunks;
-    std::vector<std::pair< Address, Dyninst::ParseAPI::EdgeTypeEnum > >& outEdges;
-    std::vector<AST::Ptr> readAST;
-
-        bool MatchReadAST(Assignment::Ptr a);
-
-        std::pair<AST::Ptr, bool> ExpandAssignment(Assignment::Ptr);
-
-public:
-    bool jumpTableFormat;
-    bool unknownInstruction;
-    std::set<Assignment::Ptr> currentAssigns;
-
-std::unordered_map<Assignment::Ptr, AST::Ptr, Assignment::AssignmentPtrHasher> expandCache;
-
-    virtual bool addNodeCallback(AssignmentPtr ap, std::set<ParseAPI::Edge*> &visitedEdges);
-GraphPtr BuildAnalysisGraph(std::set<ParseAPI::Edge*> &visitedEdges);
-    bool IsJumpTable(GraphPtr slice, BoundFactsCalculator &bfc, BoundValue &target);
-    bool FillInOutEdges(BoundValue &target, std::vector<std::pair< Address, Dyninst::ParseAPI::EdgeTypeEnum > >& outEdges);
-
-
-    JumpTablePred(ParseAPI::Function *f,
-                  ParseAPI::Block *b,
-		  ReachFact &r,
-		  ThunkData &t,
-		  std::vector<std::pair< Address, Dyninst::ParseAPI::EdgeTypeEnum > >& out):
-            func(f), block(b), rf(r), thunks(t), outEdges(out), jumpTableFormat(true), unknownInstruction(false) {}
-};
-
-
-class TypedSliceEdge: public Dyninst::Edge {
-    ParseAPI::EdgeTypeEnum type_; 
-    
-    TypedSliceEdge(const SliceNode::Ptr source,
-              const SliceNode::Ptr target,
-	      ParseAPI::EdgeTypeEnum t) 
-	      : Dyninst::Edge(source, target), type_(t) {};
-  public:	      
-   typedef boost::shared_ptr<TypedSliceEdge> Ptr; 
-   static TypedSliceEdge::Ptr create(SliceNode::Ptr source,
-                                     SliceNode::Ptr target,
-				     ParseAPI::EdgeTypeEnum t) {
-	return Ptr(new TypedSliceEdge(source, target, t));       
-   }                                                
-
-  public:
-    ParseAPI::EdgeTypeEnum type() { return type_;}
-
-};
-
-#endif
diff --git a/parseAPI/src/Parser.C b/parseAPI/src/Parser.C
index eb753c0..3c2a5d2 100644
--- a/parseAPI/src/Parser.C
+++ b/parseAPI/src/Parser.C
@@ -1813,6 +1813,10 @@ int Parser::findCurrentBlocks(CodeRegion* cr, Address addr,
     return _parse_data->findBlocks(cr, addr, blocks);
 }
 
+int Parser::findCurrentFuncs(CodeRegion * cr, Address addr, std::set<Function*> &funcs) {
+    return _parse_data->findFuncs(cr, addr, funcs);
+}
+
 Edge*
 Parser::link(Block *src, Block *dst, EdgeTypeEnum et, bool sink)
 {
diff --git a/parseAPI/src/Parser.h b/parseAPI/src/Parser.h
index 999b305..9dc65e4 100644
--- a/parseAPI/src/Parser.h
+++ b/parseAPI/src/Parser.h
@@ -126,6 +126,8 @@ class Parser {
     int findBlocks(CodeRegion * cr, Address addr, set<Block*> & blocks);
     // returns current blocks without parsing.
     int findCurrentBlocks(CodeRegion* cr, Address addr, std::set<Block*>& blocks);
+    int findCurrentFuncs(CodeRegion * cr, Address addr, set<Function*> & funcs);
+
     Block * findNextBlock(CodeRegion * cr, Address addr);
 
     void parse();
diff --git a/parseAPI/src/SymbolicExpression.C b/parseAPI/src/SymbolicExpression.C
new file mode 100644
index 0000000..b03d1ea
--- /dev/null
+++ b/parseAPI/src/SymbolicExpression.C
@@ -0,0 +1,256 @@
+#include "SymbolicExpression.h"
+#include "SymEval.h"
+#include "Absloc.h"
+#include "debug_parse.h"
+#include "IndirectASTVisitor.h"
+#include "CFG.h"
+#include "CodeSource.h"
+#include "CodeObject.h"
+using namespace std;
+using namespace Dyninst;
+using namespace Dyninst::ParseAPI;
+using namespace Dyninst::DataflowAPI;
+AST::Ptr SymbolicExpression::SimplifyRoot(AST::Ptr ast, Address addr) {
+    if (ast->getID() == AST::V_RoseAST) {
+        RoseAST::Ptr roseAST = boost::static_pointer_cast<RoseAST>(ast); 
+	
+	switch (roseAST->val().op) {
+	    case ROSEOperation::invertOp:
+	        if (roseAST->child(0)->getID() == AST::V_RoseAST) {
+		    RoseAST::Ptr child = boost::static_pointer_cast<RoseAST>(roseAST->child(0));
+		    if (child->val().op == ROSEOperation::invertOp) return child->child(0);
+		} else if (roseAST->child(0)->getID() == AST::V_ConstantAST) {
+		    ConstantAST::Ptr child = boost::static_pointer_cast<ConstantAST>(roseAST->child(0));
+		    size_t size = child->val().size;
+		    uint64_t val = child->val().val;
+		    if (size < 64) {
+		        uint64_t mask = (1ULL << size) - 1;
+		        val = (~val) & mask;
+		    } else
+		        val = ~val;
+		    return ConstantAST::create(Constant(val, size));
+		}
+		break;
+	    case ROSEOperation::extendMSBOp:
+	    case ROSEOperation::extractOp:
+	    case ROSEOperation::signExtendOp:
+	    case ROSEOperation::concatOp:
+	        return roseAST->child(0);
+
+	    case ROSEOperation::addOp:
+	        // We simplify the addition as much as we can
+		// Case 1: two constants
+	        if (roseAST->child(0)->getID() == AST::V_ConstantAST && roseAST->child(1)->getID() == AST::V_ConstantAST) {
+		    ConstantAST::Ptr child0 = boost::static_pointer_cast<ConstantAST>(roseAST->child(0));
+		    ConstantAST::Ptr child1 = boost::static_pointer_cast<ConstantAST>(roseAST->child(1));
+		    uint64_t val = child0->val().val + child1->val().val;
+		    size_t size;
+		    if (child0->val().size > child1->val().size)
+		        size = child0->val().size;
+		    else
+		        size = child1->val().size;
+		    return ConstantAST::create(Constant(val,size));
+   	        }
+		// Case 2: anything adding zero stays the same
+		if (roseAST->child(0)->getID() == AST::V_ConstantAST) {
+		    ConstantAST::Ptr child = boost::static_pointer_cast<ConstantAST>(roseAST->child(0));
+		    if (child->val().val == 0) return roseAST->child(1);
+		}
+		if (roseAST->child(1)->getID() == AST::V_ConstantAST) {
+		    ConstantAST::Ptr child = boost::static_pointer_cast<ConstantAST>(roseAST->child(1));
+		    if (child->val().val == 0) return roseAST->child(0);
+		}
+		// Case 3: if v + v * c = v * (c+1), where v is a variable and c is a constant
+		if (roseAST->child(0)->getID() == AST::V_VariableAST && roseAST->child(1)->getID() == AST::V_RoseAST) {
+		    RoseAST::Ptr rOp = boost::static_pointer_cast<RoseAST>(roseAST->child(1));
+		    if (rOp->val().op == ROSEOperation::uMultOp || rOp->val().op == ROSEOperation::sMultOp) {
+		        if (rOp->child(0)->getID() == AST::V_VariableAST && rOp->child(1)->getID() == AST::V_ConstantAST) {
+			    VariableAST::Ptr varAST1 = boost::static_pointer_cast<VariableAST>(roseAST->child(0));
+			    VariableAST::Ptr varAST2 = boost::static_pointer_cast<VariableAST>(rOp->child(0));
+			    if (varAST1->val().reg == varAST2->val().reg) {
+			        ConstantAST::Ptr oldC = boost::static_pointer_cast<ConstantAST>(rOp->child(1));
+			        ConstantAST::Ptr newC = ConstantAST::create(Constant(oldC->val().val + 1, oldC->val().size));
+				RoseAST::Ptr newRoot = RoseAST::create(ROSEOperation(rOp->val()), varAST1, newC);
+				return newRoot;
+			    }
+			}
+		    }
+		} 
+		break;
+	    case ROSEOperation::sMultOp:
+	    case ROSEOperation::uMultOp:
+	        if (roseAST->child(0)->getID() == AST::V_ConstantAST) {
+		    ConstantAST::Ptr child0 = boost::static_pointer_cast<ConstantAST>(roseAST->child(0));
+		    if (child0->val().val == 1) return roseAST->child(1);
+		}
+
+	        if (roseAST->child(1)->getID() == AST::V_ConstantAST) {
+		    ConstantAST::Ptr child1 = boost::static_pointer_cast<ConstantAST>(roseAST->child(1));
+		    if (child1->val().val == 1) return roseAST->child(0);
+		}
+	        break;
+
+	    case ROSEOperation::xorOp:
+	        if (roseAST->child(0)->getID() == AST::V_VariableAST && roseAST->child(1)->getID() == AST::V_VariableAST) {
+		    VariableAST::Ptr child0 = boost::static_pointer_cast<VariableAST>(roseAST->child(0)); 
+		    VariableAST::Ptr child1 = boost::static_pointer_cast<VariableAST>(roseAST->child(1)); 
+		    if (child0->val() == child1->val()) {
+		        return ConstantAST::create(Constant(0 , 32));
+		    }
+  	        }
+		break;
+	    case ROSEOperation::derefOp:
+	        // Any 8-bit value is bounded in [0,255].
+		// Need to keep the length of the dereference if it is 8-bit.
+		// However, dereference longer than 8-bit should be regarded the same.
+	        if (roseAST->val().size == 8)
+		    return ast;
+		else
+		    return RoseAST::create(ROSEOperation(ROSEOperation::derefOp), ast->child(0));
+		break;
+	    case ROSEOperation::shiftLOp:
+	        if (roseAST->child(0)->getID() == AST::V_ConstantAST && roseAST->child(1)->getID() == AST::V_ConstantAST) {
+		    ConstantAST::Ptr child0 = boost::static_pointer_cast<ConstantAST>(roseAST->child(0));
+		    ConstantAST::Ptr child1 = boost::static_pointer_cast<ConstantAST>(roseAST->child(1));
+		    return ConstantAST::create(Constant(child0->val().val << child1->val().val, 64));
+		}
+		break;
+	    case ROSEOperation::andOp:
+	        if (roseAST->child(0)->getID() == AST::V_ConstantAST && roseAST->child(1)->getID() == AST::V_ConstantAST) {
+		    ConstantAST::Ptr child0 = boost::static_pointer_cast<ConstantAST>(roseAST->child(0));
+		    ConstantAST::Ptr child1 = boost::static_pointer_cast<ConstantAST>(roseAST->child(1));
+		    return ConstantAST::create(Constant(child0->val().val & child1->val().val, 64));
+		}
+		break;
+	    case ROSEOperation::orOp:
+	        if (roseAST->child(0)->getID() == AST::V_ConstantAST && roseAST->child(1)->getID() == AST::V_ConstantAST) {
+		    ConstantAST::Ptr child0 = boost::static_pointer_cast<ConstantAST>(roseAST->child(0));
+		    ConstantAST::Ptr child1 = boost::static_pointer_cast<ConstantAST>(roseAST->child(1));
+		    return ConstantAST::create(Constant(child0->val().val | child1->val().val, 64));
+		}
+		break;
+
+	    default:
+	        break;
+
+	}
+    } else if (ast->getID() == AST::V_VariableAST) {
+        VariableAST::Ptr varAST = boost::static_pointer_cast<VariableAST>(ast);
+	if (varAST->val().reg.absloc().isPC()) {
+	    MachRegister pc = varAST->val().reg.absloc().reg();	    
+	    return ConstantAST::create(Constant(addr, getArchAddressWidth(pc.getArchitecture()) * 8));
+	}
+	// We do not care about the address of the a-loc
+	// because we will keep tracking the changes of 
+	// each a-loc. Also, this brings a benefit that
+	// we can directly use ast->isStrictEqual() to 
+	// compare two ast.
+	return VariableAST::create(Variable(varAST->val().reg));
+    } else if (ast->getID() == AST::V_ConstantAST) {
+        ConstantAST::Ptr constAST = boost::static_pointer_cast<ConstantAST>(ast);
+	size_t size = constAST->val().size;
+	uint64_t val = constAST->val().val;	
+	if (size == 32)
+	    if (!(val & (1ULL << (size - 1))))
+	        return ConstantAST::create(Constant(val, 64));
+    }
+
+    return ast;
+}
+
+
+AST::Ptr SymbolicExpression::SimplifyAnAST(AST::Ptr ast, Address addr) {
+    SimplifyVisitor sv(addr);
+    ast->accept(&sv);
+    return SimplifyRoot(ast, addr);
+}
+
+bool SymbolicExpression::ContainAnAST(AST::Ptr root, AST::Ptr check) {
+    if (*root == *check) return true;
+    bool ret = false;
+    unsigned totalChildren = root->numChildren();
+    for (unsigned i = 0 ; i < totalChildren && !ret; ++i) {
+        ret |= ContainAnAST(root->child(i), check);
+    }
+    return ret;
+}
+
+
+AST::Ptr SymbolicExpression::DeepCopyAnAST(AST::Ptr ast) {
+    if (ast->getID() == AST::V_RoseAST) {
+        RoseAST::Ptr roseAST = boost::static_pointer_cast<RoseAST>(ast);
+	AST::Children kids;
+        unsigned totalChildren = ast->numChildren();
+	for (unsigned i = 0 ; i < totalChildren; ++i) {
+	    kids.push_back(DeepCopyAnAST(ast->child(i)));
+	}
+	return RoseAST::create(ROSEOperation(roseAST->val()), kids);
+    } else if (ast->getID() == AST::V_VariableAST) {
+        VariableAST::Ptr varAST = boost::static_pointer_cast<VariableAST>(ast);
+	return VariableAST::create(Variable(varAST->val()));
+    } else if (ast->getID() == AST::V_ConstantAST) {
+        ConstantAST::Ptr constAST = boost::static_pointer_cast<ConstantAST>(ast);
+	return ConstantAST::create(Constant(constAST->val()));
+    } else if (ast->getID() == AST::V_BottomAST) {
+        BottomAST::Ptr bottomAST = boost::static_pointer_cast<BottomAST>(ast);
+	return BottomAST::create(bottomAST->val());
+    }
+    fprintf(stderr, "ast type %d, %s\n", ast->getID(), ast->format().c_str());
+    assert(0);
+	return AST::Ptr();
+}
+
+pair<AST::Ptr, bool> SymbolicExpression::ExpandAssignment(Assignment::Ptr assign) {
+    if (expandCache.find(assign) != expandCache.end()) {
+        AST::Ptr ast = expandCache[assign];
+        if (ast) return make_pair(ast, true); else return make_pair(ast, false);
+    } else {
+        parsing_printf("\t\tExpanding instruction @ %x: %s\n", assign->addr(), assign->insn()->format().c_str());
+        pair<AST::Ptr, bool> expandRet = SymEval::expand(assign, false);
+	if (expandRet.second && expandRet.first) {
+	    parsing_printf("Original expand: %s\n", expandRet.first->format().c_str());
+	    AST::Ptr calculation = SimplifyAnAST(expandRet.first, 
+	                                         PCValue(assign->addr(),
+						         assign->insn()->size(),
+							 assign->block()->obj()->cs()->getArch()));
+	    expandCache[assign] = calculation;
+	} else {
+	    expandCache[assign] = AST::Ptr();
+	}
+	return make_pair( expandCache[assign], expandRet.second );
+    }
+}
+
+AST::Ptr SymbolicExpression::SubstituteAnAST(AST::Ptr ast, const map<AST::Ptr, AST::Ptr> &aliasMap) {
+    for (auto ait = aliasMap.begin(); ait != aliasMap.end(); ++ait)
+        if (*ast == *(ait->first)) {
+	    return ait->second;
+	}
+    unsigned totalChildren = ast->numChildren();
+    for (unsigned i = 0 ; i < totalChildren; ++i) {
+        ast->setChild(i, SubstituteAnAST(ast->child(i), aliasMap));
+    }
+    if (ast->getID() == AST::V_VariableAST) {
+        // If this variable is not in the aliasMap yet,
+	// this variable is from the input.
+        VariableAST::Ptr varAST = boost::static_pointer_cast<VariableAST>(ast);
+	return VariableAST::create(Variable(varAST->val().reg, 1));
+    }
+    return ast;
+}
+
+Address SymbolicExpression::PCValue(Address cur, size_t insnSize, Architecture a) {
+    switch (a) {
+        case Arch_x86:
+	case Arch_x86_64:
+	    return cur + insnSize;
+	case Arch_aarch64:
+	    return cur;
+        case Arch_aarch32:
+        case Arch_ppc32:
+        case Arch_ppc64:
+        case Arch_none:
+            assert(0);
+    }    
+    return cur + insnSize;
+}
diff --git a/parseAPI/src/SymbolicExpression.h b/parseAPI/src/SymbolicExpression.h
new file mode 100644
index 0000000..6762105
--- /dev/null
+++ b/parseAPI/src/SymbolicExpression.h
@@ -0,0 +1,34 @@
+#ifndef SYMBOLIC_EXPRESSION_H
+#define SYMBOLIC_EXPRESSION_H
+
+#include "DynAST.h"
+#include "Absloc.h"
+#include <map>
+using Dyninst::AST;
+using namespace Dyninst;
+// This class tracks the expanded assignments,
+// and also provides several helper functions for manipulating ASTs
+class SymbolicExpression {
+
+    dyn_hash_map<Assignment::Ptr, AST::Ptr, Assignment::AssignmentPtrHasher> expandCache;
+
+public:
+
+    static AST::Ptr SimplifyRoot(AST::Ptr ast, Address addr);
+    static AST::Ptr SimplifyAnAST(AST::Ptr ast, Address addr);
+    static AST::Ptr SubstituteAnAST(AST::Ptr ast, const std::map<AST::Ptr, AST::Ptr>& aliasMap);
+    static AST::Ptr DeepCopyAnAST(AST::Ptr ast);
+    static bool ContainAnAST(AST::Ptr root, AST::Ptr check);
+
+    std::pair<AST::Ptr, bool> ExpandAssignment(Assignment::Ptr);
+
+    //On x86 and x86-64, the value of PC is post-instruction, 
+    // which is the current address plus the length of the instruction.
+    // On ARMv8, the value of PC is pre-instruction,
+    // which is the current address
+    static Address PCValue(Address cur, size_t insnSize, Architecture a);
+
+
+};
+
+#endif
